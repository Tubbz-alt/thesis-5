%% -*- mode: LaTeX compile-command: "cd ..; make compile" -*-

%if style == newcode
%include rae.fmt

\begin{code}
-- import Pico.Ott
-- import Pico.Syn
import Prelude hiding ( Either(..), replicate )
import Data.Kind ( Type )
import qualified GHC.TypeLits as TL
import Data.Singletons.TH hiding ( Proxy(..) )
import Data.Singletons.Prelude

type family UU n where
  UU 0 = !Zero
  UU n = !Succ (UU (n TL.- 1))

\end{code}

%endif

\newcommand{\rulesep}{\\[1ex]}

\chapter{\Pico/}
\label{cha:pico}

This chapter presents \pico/, the internal language Dependent Haskell compiles
into. I have proved type safety (via the usual preservation
and progress theorems, \pref{thm:preservation} and \pref{thm:progress})
and type erasure (\pref{thm:type-erasure} and \pref{thm:expr-eval}).
I believe \pico/ would make a strong candidate for the internal language
in a future version of GHC.

\section{Overview}
\label{sec:conv-rule}

\Pico/ (pronounced like ``$\Pi$-co'', never ``peek-o'')
descends directly from the long line of work on System FC~\cite{systemfc}.
It is most closely related to the version of System FC presented in my prior
work~\cite{nokinds} and in Gundry's thesis~\cite{gundry-thesis}.

\Pico/
sits in the $\lambda$-cube~\cite{barendregt-lambda-cube}
 on the same vertex as the Calculus of Constructions~\cite{coquand-cc}, but
with a very different notion of equality. A typical dependently typed
calculus contains a \emph{conversion} rule, something like this:
\[
\ottdrule{\ottpremise{\tau : \kappa_1 \qquad \kappa_1 \equiv \kappa_2}}{\tau : \kappa_2}{\rul{Conv}}
\]
This rule encapsulates the point of type equivalence: if a type $\tau$ is found
to have some kind $\kappa_1$ and $\kappa_1$ is known to be equivalent to
some $\kappa_2$, then we can say that $\tau$ has kind $\kappa_2$.\footnote{I tend
to use the word ``kind'' when referring to the classification of a type. However,
in the languages considered in this dissertation, kinds and types come from the
same grammar; the terms ``type'' and ``kind'' are technically equivalent.
Nevertheless, I find that discerning between these two words can aid intuition
and will continue to do so throughout the dissertation. \rae{Do I discuss elsewhere??}}
This rule is flexible and helps a language to be succinct. It has a major
drawback, however: it is not syntax directed. In general, determining
whether $\kappa_1 \equiv \kappa_2$ might not be easy. Indeed, type equivalence
in \pico/ is undecidable, so we would have a hard time building a type-checker
with a \rul{Conv} rule such as this one. Other dependently typed languages
are forced to restrict expressiveness in order to keep type-checking
decidable; this need for decidable type equivalence is one motivation to design
a dependently typed language to be strongly normalizing.

\Pico/'s approach to type equivalence (and the \rul{Conv} rule) derives from
the \emph{coercions} that provide the ``C'' in ``System FC''. Instead of relying
on a non-syntax-directed equivalence relation, \pico/'s type equivalence
requires evidence of equality in the form of coercions. Here is a simplified
version of \pico/'s take
of the \rul{Conv} rule:
\[
\ottdrule{\ottpremise{[[t]] : [[k1]] \qquad [[g]] : [[k1 [Type{}]~[Type{}] k2]]}}{[[t |> g]] : [[k2]]}{\rul{Ty\_Cast}}
\]
In this rule, the metavariable $[[g]]$ stands for a \emph{coercion}, a proof
of the equality between two types. Here, we see that $[[g]]$ proves that
kinds $[[k1]]$ and $[[k2]]$ are equivalent. Thus, we can type $[[t |> g]]$
at $[[k2]]$ as long as $[[t]]$ can be typed at $[[k1]]$. Note the critical
appearance of $[[g]]$ in the conclusion of the rule: this rule is syntax-directed.
The type-checker simply needs to check the equality proofs against a set of
(also syntax-directed) rules, not to check some more general equivalence relation.

The grammar for coercions (in~\pref{fig:coercions-grammar}) allows for a wide variety
of coercion forms, giving \pico/ a powerful notion of type equivalence.
However, this grammar includes no evaluation or proper $\lambda$-abstractions.\footnote{There is a coercion form that starts with $\lambda$; it is only a
congruence form for $\lambda$-abstractions in types, not a $\lambda$-abstraction
in the coercion language. See \pref{sec:lambda-coercion}.}
Thus, the fact that evaluation in \pico/ might not terminate does not threaten
the type safety of the language. Coercions are held separate from types,
and proving consistency of the coercion language (\pref{sec:consistency})---in
other words, that we cannot prove |Int ~ Bool|---is the heart of the
type safety proof. It does not, naturally, depend on any termination proof,
nor any termination checking of the program being checked. The independence
of \pico/'s type safety result from termination means that \pico/ can avoid
many potential traps that have snagged other dependently typed languages
that rely on intricate termination checks.\footnote{For example, see \url{https://coq.inria.fr/cocorico/CoqTerminationDiscussion}.}

\subsection{Features of \pico/}
\label{sec:unsaturated-match-example}

\Pico/ is a dependently typed $\lambda$-calculus with algebraic datatypes and
a fixpoint operator. Recursion is modeled only via this fixpoint operator;
there is no recursive |let|. Other than the way in which the operational
semantics deals with coercions in the form of \emph{push rules}, the
small-step semantics is what you might expect for a call-by-name
$\lambda$-calculus.

The typing relations, however, have a few features worth mentioning up front;
other unusual features are best explained after the detailed coverage of
\pico/; see \pref{sec:pico-design-decisions}.

\paragraph{Relevance annotations and type erasure}
A key concern when compiling a dependently typed language is type erasure.
Given that terms and types can intermingle, what should be erased during
compilation? And what data is necessary to be retained until runtime.
Dependent Haskell (and, in turn, \pico/) forces the user to specify this
detail at each quantifier (\pref{sec:pico-relevance}). In the formal grammar
of \pico/, we distinguish between $[[PI]] [[a:Rel k]].\, ...$ and
$[[PI]] [[a:Irrel k]].\, ...$. The former is the type of an abstraction
that is retained at runtime, written with a |pi| in Haskell;
the latter abstraction, written with |forall| is fully erased.
In order to back up this claim of full erasure of irrelevant quantification,
evaluation happens under irrelevant abstractions; see \pref{sec:evaluation-under-irrel-abs}.

So that we can be sure a variable's relevance is respected at use sites,
variable contexts $[[G]]$ track the relevance of bound variables. Only
relevant variables may appear in the ``level'' in which they were bound;
when a typing premise refers to a higher ``level'', the context is altered to
mark all variables as relevant. For example, the \ottkw{case} construct
$[[case_k t of alts]]$ includes the return kind of the entire \ottkw{case}
expression as its $[[k]]$ subscript. This kind is type-checked in a context
where all variables are marked as relevant; because the kind is erased
during compilation, the use of an irrelevant variable there is allowed.
As they are also erased, coercions are considered fully irrelevant as well.

My treatment of resetting the context is precisely like what is done
by \citet{erasure-pure-type-systems}.

\paragraph{Matching on partially-applied constants}
\Pico/ does not contain type families. Instead, it uses $\lambda$-abstractions
and \ottkw{case} expressions, as are more familiar to functional programmers.
And yet, I wish for \pico/ to support the variety of ways in which type families
are used in today's Haskell. One curiosity of today's Haskell is that it allows
matching on partially-applied data constructors:
\begin{code}
type family IsLeft a where
  IsLeft !Left   = !True
  IsLeft !Right  = !False
\end{code}
The type family |IsLeft| is inferred to have kind
|forall k. (k -> Either k k) -> Bool|. That is, it matches on the |Left|
and |Right| constructors, even though these are not applied to arguments.
While it may seem that |IsLeft| is matching on a \emph{function}---after all,
the type of |IsLeft|'s argument appears to be an arrow type---it is not.
It is matching only on constructors, because the kind-level |->| classifies
only type constants. \rae{Flesh this out once I know how I'm dealing with the
two arrows in Haskell.}

To get this partially-applied matching to work in \pico/, it is necessary
to have two different $[[PI]]$-quantifiers: $[[MPI]]$ and $[[UPI]]$. The
former is called a \emph{matchable} $[[PI]]$, the latter is \emph{unmatchable}.
Type constants are classified by $[[MPI]]$, whereas $\lambda$-abstractions
are classified by $[[UPI]]$.
Only matchable $[[MPI]]$-types are allowed as \ottkw{case} scrutinees.
When I write the unadorned $[[PI]]$, I actually mean a metavariable which
might be instantiated either to $[[MPI]]$ or $[[UPI]]$.

\paragraph{Matching on $[[Type]]$}

Today's Haskell also has the ability, through its type families, to match on
members of $[[Type]]$. For example:
\begin{code}
type family IntLike x where
  IntLike Integer = !True
  IntLike Int     = !True
  IntLike _       = !False
\end{code}
This ability for a function to inspect the choice of a type---and not a code
for a type---is unique to Haskell, as far as I am aware. With the type families
in today's Haskell, discerning between types is done by simple pattern matching.
However, if we compile type families to \ottkw{case} statements, we need a way
to deal with this construct.

Fortunately, types like |Either| resemble data constructors like |Just|:
both are classified by matchable quantification(s) over a type headed by another
type constant. In the case of |Either|, we have $|Either| : 
[[MPI _:Rel Type{}, _:Rel Type{}. Type{} ]]$;\footnote{Why $[[Rel]]$? See
the end of
\pref{sec:relevance-of-datatypes}.} note that the body of the
$[[PI]]$-type is headed by the constant $[[Type{}]]$. For |Just|,
we have $|Just|_{[[ {a} ]]} : [[MPI _ :Rel a. &Maybe{} a]]$.\footnote{The
$[[ {a} ]]$ subscript is explained in \pref{sec:universals}.}
With this similarity, it is not hard to create a typing rule for a \ottkw{case}
statement that can handle both data constructors (like |Just|) and types
(like |Either|).

A key feature, however, that is needed to support matching on $[[Type]]$ is
default patterns. For a closed datatype, where all the constructors can be
enumerated, default patterns are merely a convenience; any default can be
expanded to list all possible constructors. For an open type, like $[[Type]]$,
the availability of the default pattern is essential. It is for this reason alone
that I have chosen to include default patterns in \pico/.

\paragraph{Hypothetical equality}

\Pico/ allows abstraction over coercions, much like any $\lambda$-calculus
allows abstraction over expressions (or, in a call-by-value calculus,
values). Coercion abstraction means that a type equality may be \emph{assumed}
in a given type. When we wish to evaluate a term that assumes an equality,
we must apply that term to evidence that the equality holds---an actual coercion.
It is this ability, to assume an equality, that allows \pico/ to have
GADTs. See the example in \pref{sec:pico-gadt-example} for the details.

\subsection{Design requirements for \pico/}

In the course of any language design, there needs to be a guiding principle
to aid in making free design decisions. The chief motivator for the design
of \pico/ is that it should be suitable for use as the internal language
of a Haskell compiler. This use case provides several desiderata:

\paragraph{Decidable, syntax-directed, efficient type-checking}
The use of types in a compiler's intermediate language serves only as a check
of the correctness of the compiler. Any programmer errors are caught before
the intermediate language code is emitted, and so a correct compiler should
only produce well-typed intermediate-language programs, if it produces such
programs at all. In addition, a correct compiler performing program transformations
on the intermediate language should take a well-typed program to a well-typed
program. However, not all compilers are correct, and thus it is helpful
to have a way to check that intermediate-language program generation and
transformation is at least type-preserving. To check this property, we need
to type-check the intermediate language, both after it is originally
produced and after every transformation. It thus must be easy and efficient
to do so.

\Pico/ essentially encodes a typing derivation right in the syntax of types
and coercions. It is thus very easy to write a type-checker for the language.
Type-checking is manifestly decidable and can be done in one pass over the
program text, with no constraint solving.\footnote{I do not claim that it
is strictly linear, as a formal analysis of its running time is beyond the
scope of this dissertation. In particular, one rule
(see \pref{sec:pico-case}) requires the use of a unification algorithm
and likely breaks linearity.} \Pico/'s lack of a termination requirement
also significantly lowers the burden of implementation of a type-checker
for the language.

\paragraph{Erasability}

An intermediate-language program should make clear what information can be
erased at runtime. After all, when the compiler is done performing optimizations,
runtime code generation must take place, and we thus need to know what
information can be dropped. It is for this reason that \pico/ includes the
relevance annotations.

\paragraph{A balance between ease of proving and ease of implementation}
\Pico/ serves two goals: to be a template for an implementation, and also
to be a calculus used to prove type safety. These goals are sometimes at
odds with each other.

These two goals of System~FC have tugged in
different directions since the advent of FC. Historically, published
versions of the language have greatly simplified certain details. 
No previously published treatment of FC has included support for recursion,
either through \ottkw{letrec} or \ottkw{fix}. In contrast, the implemented
version of FC makes certain choices for efficiency; for example, applied
type constructors, such as |Either Int Bool|, have a different representation
than do applied type variables, such as |a Int Bool|. The former is stored
as the head constructor with a list of arguments, and the latter is stored
as nested binary applications. This is convenient when implementing but
meddlesome when proving properties. The divergence between published FC
and the implemented version (more often called GHC Core) have led to a
separate document just to track the implemented version~\cite{ghc-core-spec}.

In the design of \pico/, I have aimed for balance between these two needs.
Because of the risk that non-termination might cause unsoundness, I have
explicitly included \ottkw{fix} in the design, just to make sure that
the non-termination is obvious.\footnote{With $[[Type{}]] : [[Type{}]]$, we
have the possibility of Girard's paradox~\cite{girard-thesis,simplification-girard-paradox} and thus
can have non-termination even without \ottkw{fix}, but making the non-termination
more obvious clarifies that we can achieve type safety without termination.}
I have not, however, included an explicit \ottkw{let} or \ottkw{letrec}
construct, as the specification of these would be quite involved, and yet
desugaring these constructs into $[[\]]$ and \ottkw{fix} is straightforward.
(See \pref{sec:let-desugaring}.)

On the other hand, I have included \ottkw{case}. Having \ottkw{case} in the
language also significantly complicates the presentation, but here in a
useful way: the existence of \ottkw{case} (over unsaturated constructors)
motivates the distinction between $[[UPI]]$ and $[[MPI]]$. The desugaring
of \ottkw{case} into recursive types built, say, with \ottkw{fix} is not
nearly as simple as the desugaring of \ottkw{let}.

In the end, choices
such as these are somewhat arbitrary and come down to taste. I believe
that the choices I have made here bring us to a useful formalization with
the right points of complexity. Some of these design decisions are considered
in more depth after \pico/ has been presented;
see \pref{sec:pico-design-decisions}.

\subsection{Other applications of \pico/}

It is my hope that \pico/ sees application beyond just in Haskell. In designing
it, I have tried to permit certain Haskell idioms (call-by-name semantics,
the extra capabilities of \ottkw{case} expressions outlined above) while
still retaining a general enough flavor that it could be adapted to other
settings. I believe that the arguments above about \pico/'s design mean
that it is a suitable starting-point for the design of an
intermediate language for any dependently typed surface language. Other uses
might want call-by-value instead of call-by-name or to remove the somewhat
fiddly distinction between $[[MPI]]$ and $[[UPI]]$. These changes should be
rather straightforward to make.

In certain areas, I have decided not to support certain existing Haskell
constructs directly in \pico/ because doing so would clutter the language,
making its applicability beyond Haskell harder to envision. Various
extensions of \pico/---which would likely appear in an implementation of
\pico/ within GHC---are discussed in \pref{sec:pico-extensions}. These
include representation polymorphism and support for the $([[->]])$ type 
constructor, for example.

\subsection{No roles in \pico/}

Recent versions of System FC have included \emph{roles}~\cite{safe-coercions},
which distinguish between two different notions of type equality:
nominal equality is the equality relation embodied in Haskell's |(~)|
operator, whereas representational equality relates types that have
bit-for-bit identical runtime representations. Tracking these two
equality relations is important for allowing zero-cost conversions
between types known to have the same representation, and it is an
important feature to boost performance of programs that use |newtype|
to enforce abstraction.

However, roles greatly clutter the language
and its proofs. Including them throughout this dissertation would distract
us from the main goal of understanding a dependently typed language
with $[[Type{}]] : [[Type{}]]$ and
at ease with non-termination. It is for this reason that I have chosen
to omit roles entirely from this work. I am confident that, in time, roles
can be integrated with the language presented here, perhaps along the
lines I have articulated in a draft paper~\cite{overabundance-of-equalities},
though the treatment there still leaves something to be desired.
Regardless of clutter, having a solid approach to combining roles with
dependent types will be a prerequisite of releasing a performant
implementation of dependent types in GHC.

\section{A formal specification of \pico/}

\begin{figure}
Metavariables:
\[
\begin{array}{rl@@{\qquad}rl}
[[T]] & \text{algebraic datatype} & [[K]] & \text{data constructor} \\
[[a,b,x]] & \text{type/term variable} & [[c]] & \text{coercion variable} \\
[[i, j, kk, n]] & \text{natural number/index}
\end{array}
\]
\[
\begin{array}{rcl@@{\quad}l}
[[PI]] &\bnfeq& [[MPI]] & \text{matchable dep.~quantifier} \\
&\bnfor& [[UPI]] & \text{unmatchable dep.~quantifier} \\
[[z]] &\bnfeq& [[a]] \bnfor [[c]] & \text{type or coercion variable} \\
[[H]] &\bnfeq& [[T]] \bnfor [[K]] \bnfor [[Type]] & \text{constant} \\
[[rel]] &\bnfeq& [[Rel]] \bnfor [[Irrel]] & \text{relevance annotation} \\
[[d]] &\bnfeq& [[a :rel k]] \bnfor [[c : phi]] & \text{binder} \\
[[phi]] &\bnfeq& [[t1 (k1)~(k2) t2]] & \text{heterogeneous equality} \\
[[t]], [[s]], [[k]] &\bnfeq& [[a]] \bnfor [[t p]] \bnfor [[PI d.t]] \bnfor [[\d.t]] 
                   & \text{dependent types} \\
&\bnfor& [[H{ts}]] & \text{constant applied to universals} \\
&\bnfor& [[t |> g]] & \text{kind cast} \\
&\bnfor& [[case_k t of alts]] & \text{case-splitting} \\
&\bnfor& [[fix t]] & \text{recursion} \\
&\bnfor& [[absurd g t]] & \text{absurdity elimination} \\
[[p]] &\bnfeq& [[t]] \bnfor [[{t}]] \bnfor [[g]] & \text{argument} \\
[[alt]] &\bnfeq& [[pat -> t]] & \text{case alternative} \\
[[pat]] &\bnfeq& [[H]] \bnfor [[_]] & \text{pattern} \\
[[g,h]] &\bnfeq& [[c]] & \text{coercion assumption} \\
&\bnfor& [[<t>]] \bnfor [[sym g]] \bnfor [[g1 ;; g2]] & \text{equivalence} \\
&\bnfor& [[H{gs}]] \bnfor [[g w]] \bnfor [[PI a:rel h.g]] \bnfor [[PI c:(h1,h2).g]]   & \text{congruence} \\
&\bnfor& \multicolumn{2}{l}{[[case_h g of calts]] \bnfor [[fix g]]
\bnfor [[\a :rel h.g]] \bnfor [[\c:(h1,h2).g]]  
\bnfor [[absurd (h1,h2) g]]} \\
&\bnfor& [[t1 ~={h} t2]] & \text{coherence} \\
&\bnfor& [[argk g]] \bnfor [[argk n g]] \bnfor [[res^n g]] \bnfor [[g@w]] & \text{$[[PI]]$-type decomposition} \\
&\bnfor& [[nth n g]] & \text{injectivity} \\
&\bnfor& [[kind g]] & \text{``John Major'' equality} \\
&\bnfor& [[step t]] & \text{$\beta$-equivalence} \\
[[calt]] &\bnfeq& [[pat -> g]] & \text{case alternative in coercion} \\
[[w]] &\bnfeq& [[g]] \bnfor [[{g}]] \bnfor [[(g1,g2)]] & \text{coercion argument} \\[1ex]
[[S]] &\bnfeq& [[empty]]  & \text{signature} \\
&\bnfor& [[S, T:(as:ks)]] & \text{algebraic datatype} \\
&\bnfor& [[S, K:(D;T)]] & \text{data constructor} \\
[[G,D]] &\bnfeq& [[empty]] \bnfor [[G, d]] & \text{context/telescope} \\
[[theta]] &\bnfeq& [[empty]] \bnfor [[theta, t/a]] \bnfor [[theta, g/c]] & \text{substitution} \\[1ex]
\end{array}
\]
\caption{The grammar of \pico/}
\label{fig:pico-grammar}
\label{fig:coercions-grammar}
\end{figure}

\begin{figure}
\[
\begin{array}{rcl}
\overline{\text{\phantom{T}}} &\defeq& \text{(an overbar) indicates a list} \\
[[_]] &\defeq& \text{a fresh variable whose name is not used} \\
[[dom(D)]] &\defeq& \text{the list of variables bound in $[[D]]$} \\
[[prefix]](\cdot) &\defeq& \text{a prefix of a list; length specified elsewhere} \\
[[fv]](\cdot) &\defeq& \text{extract all free variables, as a set} \\
[[H]] &\defeq& [[H{blank}]] \text{ (when appearing in a type)} \\
[[PI D. t]] &\defeq& \text{nested $[[PI]]$s} \\
[[MUPI D. t]] &\defeq& \text{nested $[[PI]]$s, where the individual $[[PI]]$s used might differ} \\
[[\D.t]] &\defeq& \text{nested $[[\ ]]$s} \\
[[t1 [k1]~[k2] t2]] &\defeq& [[t1 (k1)~(k2) t2]] \text{ (when the kinds are obvious or unimportant)} \\
[[o]] &\defeq& \text{an erased coercion} \\
[[#]] &\defeq& \text{the sets of free variables of two entities are distinct} \\
\lfloor \cdot \rfloor &\defeq& \text{coercion erasure (\pref{sec:coercion-erasure-intro})} \\
\llfloor \cdot \rrfloor &\defeq& \text{type erasure (\pref{sec:type-erasure})} \\
\ottkw{let} &\text{is}& \text{used in the metatheory only and should be eagerly expanded}\\
\end{array}
\]
\caption{Notation conventions of \pico/}
\label{fig:pico-notation}
\end{figure}

\begin{figure}
\[\def\arraystretch{1.5}
\begin{array}{cl}
[[S |-tc H : D1;D2;H']] & \text{\parbox{.7\textwidth}{Constant $[[H]]$ has universals $[[D1]]$,
existentials $[[D2]]$, and belongs to parent type $[[H']]$.}} \\
[[S;G |-ty t : k]] & \text{Type $[[t]]$ has kind $[[k]]$.} \\
[[S;G;s;t0 |-alt pat -> t : k]] & \text{\parbox{.7\textwidth}{Case alternative $[[pat -> t]]$
yields something of kind $[[k]]$ when used with a scrutinee $[[t0]]$ of
type $[[s]]$.}} \\
[[S;G |-co g : phi]] & \text{Coercion $[[g]]$ proves proposition $[[phi]]$.} \\
[[S;G |-prop phi]] & \text{Proposition $[[phi]]$ is well formed.} \\
[[S;G |-vec ps : D]] & \text{Vector $[[ps]]$ is classified by telescope $[[D]]$.} \\
[[S;G |-cev ps : D]] & \text{\parbox{.7\textwidth}{Vector $[[ps]]$ is classified by telescope $[[D]]$
(with induction defined from the end).}} \\
[[|-sig S]] & \text{Signature $[[S]]$ is well formed.} \\
[[S |-ctx G]] & \text{Context $[[G]]$ is well formed.} \\
[[S;G |-s t --> t']] & \text{Type $[[t]]$ reduces to type $[[t']]$ in one step.}
\end{array}
\]
\begin{lemma*}[Kind regularity (\pref{lem:kind-reg})]
If $[[S;G |-ty t : k]]$, then $[[S;Rel(G) |-ty k : Type{} ]]$.
\end{lemma*}
\begin{lemma*}[Prop.~regularity (\pref{lem:prop-reg})]
If $[[S;G |-co g : phi]]$, then $[[S;Rel(G) |-prop phi]]$.
\end{lemma*}
\caption{Judgments used in the definition of \pico/}
\label{fig:pico-judgments}
\end{figure}

The full grammar of \pico/ appears in \pref{fig:pico-grammar} and
notation conventions appear in \pref{fig:pico-notation}. We will cover
these in detail in the following sections. Later
sections of this chapter will cover portions of the typing rules, but for
a full listing of all the typing rules of the language, please see
\pref{app:pico-rules}. \pref{fig:pico-judgments} includes the judgment
forms and two key lemmas, useful in understanding the judgments.
All of the metatheory lemmas, theorems, and proofs appear in
\pref{app:pico-proofs}. This chapter mentions several key lemmas and
theorems, but the ordering here is intended for readability and
lemma statements may be abbreviated; please
see the appendix for the correct dependency ordering and full statements.

You will see that the \pico/ language is centered around what I call types,
represented by metavariables $[[t]]$, $[[s]]$, and $[[k]]$. As \pico/ is a
full dependently typed language with a unified syntax for terms, types, and
kinds, this production could be called ``expressions'' and could be assigned
the metavariable $[[e]]$. However, I have decided to reserve $[[e]]$ (and the
moniker ``expression'') for \emph{erased} expressions only, after all the types
have been removed. These expressions are used only in the type erasure theorem
(\pref{sec:type-erasure}); the rest of the metatheory is about types. Nevertheless,
a program written in \pico/ intended to be run will technically be a type,
and types in \pico/ have an operational semantics
(\pref{sec:operational-semantics}).

Note also the definition for arguments $[[p]]$: the application form $[[t p]]$
applies a type to an argument, which can be a type, an irrelevant type,
or a coercion. It would be equivalent to have three productions in the definition
for types, but having a separate definition for arguments allows us to easily
discuss what I call \emph{vectors},\footnote{I have adopted this terminology
from \citet{gundry-thesis}.} which are lists of arguments $[[ps]]$.

As you will see in \pref{fig:pico-notation}, my presentation of \pico/ uses
several abbreviations and elisions in its typesetting. In particular, I
frequently write types like $[[PI D. t]]$ to represents a nested $[[PI]]$-type,
binding the variables listed in $[[D]]$ (which, as you can see, is just a list
of binders $[[d]]$). An equality proposition in \pico/ lists both the related
types and their kinds. Often, the kinds are redundant, obvious, or unimportant,
and so I elide them in those cases.

All of the metatheory in this dissertation is typeset using
\package{ott}~\cite{ott}. This tool effectively type-checks my work,
preventing me from writing, say, the nonsense $[[a]]{:}[[phi]]$, which is
rightly a parsing error.\footnote{Indeed, to include that example in the text,
  I had to avoid rendering the example in \package{ott} syntax.} In addition,
I have configured my use of \package{ott} to require me to write the kinds
of an equality proposition even when I intend for them to be elided in the
rendered output, as a check to make sure these parameters can indeed be written
with the information to hand.

\rae{Is this outline still accurate?}
This chapter proceeds by explaining all of the various typing judgments
individually. \pref{sec:contexts-rel-annots} explains contexts $[[G]]$,
along with relevance annotations. \pref{sec:signatures} explains
signatures $[[S]]$, which contain specifications for constants $[[H]]$.
Having explained the more unexpected aspects of the syntax, I then
present examples of \pico/ programs in \pref{sec:pico-examples}.
Types come next, in \pref{sec:pico-types}, followed by coercions
in \pref{sec:pico-coercions}. The metatheory is discussed in
Sections~\ref{sec:metatheory-one} and~\ref{sec:metatheory-two}.
The chapter concludes in \pref{sec:pico-extensions}
by considering a variety of extensions to \pico/ that are needed for
full, backward-compatible support for Haskell as embodied in GHC~8.

\section{Contexts $[[G]]$ and relevance annotations}
\label{sec:contexts-rel-annots}
\label{sec:ty-var}
\label{sec:pico-relevance}

One of the distinctive aspects of \pico/ is its use of relevance annotations
on binders. Every type variable binding $[[a :rel k]]$ comes with a relevance
annotation $[[rel]]$, which can be either $[[Rel]]$ or $[[Irrel]]$. A
typing context $[[G]]$ is just a list of such binders (along with, perhaps,
coercion variable binders) and so retains the relevance annotation. These
annotations come into play only in the rule for checking variable occurrences:
\[
\ottdruleTyXXVar{}
\]
Note that this rule requires $[[a:Rel k \in G]]$, with a relevant binder.
Thus, only variables that are considered relevant---that is, variables that
will remain at runtime---can be used in an expression. As described briefly
above, when we ``go up a level'', we reset the context, making all variables
marked as relevant. This resetting is done by the $[[Rel(G)]]$ operation,
defined recursively on the structure of $[[G]]$ as follows:
\begin{align*}
[[Rel(empty) &= empty]] \\
[[Rel(G, a :rel k) &= Rel(G), a :Rel k]] \\
[[Rel(G, c:phi) &= Rel(G), c:phi]]
\end{align*}
The $[[Rel(G)]]$ operation is used, for example, in the judgment to check
contexts for validity:\\[\baselineskip]
\ottdefnCtx{}

Here, we see that a binding $[[a :rel k]]$ can be appended onto a context
$[[G]]$ when the $[[a]]$ is fresh and the $[[k]]$ is well-typed at $[[Type{}]]$
in $[[Rel(G)]]$. The reason for using $[[Rel(G)]]$ instead of $[[G]]$ here
is that the kind $[[k]]$ does not exist at runtime, regardless of the
relevance annotation on $[[a]]$. We are thus free to essentially ignore
the relevance annotations on $[[G]]$, which is what $[[Rel(G)]]$ does.
The same logic applies to the use of $[[Rel(G)]]$ in the \rul{Ctx\_CoVar}
rule. Indeed, all premises involving coercions use $[[Rel(G)]]$, as all
coercions are erased and are thus irrelevant.

In order for premises that use $[[Rel(G)]]$ to work in the metatheory,
we must frequently use the following lemma:

\begin{lemma*}[Increasing relevance (\pref{lem:increasing-rel})]
Let $[[G]]$ and $[[G']]$ be the same except that some bindings
in $[[G']]$ are labeled $[[Rel]]$ where those same bindings
in $[[G]]$ are labeled $[[Irrel]]$. Any judgment about $[[G]]$
is also true about $[[G']]$.
\end{lemma*}

\paragraph{Regularity}
Regularity is an important property of \pico/, allowing us to easily
assume well-formed contexts and signatures:

\begin{lemma*}[Context regularity (\pref{lem:ctx-reg})]
If:
\begin{enumerate}
\item $[[S;G |-ty t : k]]$, OR
\item $[[S;G |-co g : phi]]$, OR
\item $[[S;G |-prop phi]]$, OR
\item $[[S;G;s0;t0 |-alt alt : k]]$, OR
\item $[[S;G |-vec ps : D]]$, OR
\item $[[S |-ctx G]]$
\end{enumerate}
Then $[[S |-ctx prefix(G)]]$ and $[[|-sig S]]$, where $[[prefix(G)]]$ is an
arbitrary prefix of $[[G]]$. Furthermore, both resulting derivations are no
larger than the input derivations.
\end{lemma*}

\section{Signatures $[[S]]$ and type constants $[[H]]$}
\label{sec:signatures}

The typing rules in \pico/ are all parameterized by both a signature
$[[S]]$ and a context $[[G]]$. Signatures contain bindings for all global
constants: type and data constructors. In contrast, contexts contain
local bindings, for type and coercion variables. Several treatments of
System FC assume a fixed, global signature, but I find it more precise
here to make dependency on this signature explicit.

\subsection{Signature validity}
\label{sec:term-arguments-are-existentials}
\label{sec:universals}

The judgment to check the validity of a signature follows:\\[\baselineskip]
\ottdefnSig{}

We see here the two different entities that can be added to a signature,
an algebraic datatype (ADT) $[[T]]$ or a data constructor $[[K]]$.

An ADT is classified only by its list of universally quantified variables
(often shortened to \emph{universals}), as this is the only piece of information
that varies between ADTs. For example, the Haskell type \id{Int} contains
no universals, while \id{Either} contains two (both of kind $[[Type]]$),
and \id{Proxy}'s universals are $[[(a : Type{}, b : a)]]$. The relevance
of universals is predetermined (see \pref{sec:relevance-of-datatypes}) and so
no relevance annotations appear on ADT specifications. Additionally,
coercion variables are not permitted here---coercion variables would
be very much akin to Haskell's misfeature of datatype
contexts\footnote{See discussion of how this is a misfeature at
\url{https://prime.haskell.org/wiki/NoDatatypeContexts}.} and so are excluded.

A data constructor is classified by a telescope $[[D]]$ of existentially
bound variables (or \emph{existentials})
and the ADT to which it belongs. The grammar for telescopes
is the same as that for contexts, but we use the metavariables $[[G]]$
and $[[D]]$ in distinct ways: $[[G]]$ is used as the context for typing judgments,
whereas $[[D]]$ is more often used as some component of a type. A telescope
is a list of binders---both type variables and coercion variables---where
later binders may depend on earlier ones. A data constructor's existentials are
the data that cannot be determined from an applied data constructor's type.
In this formulation, the term \emph{existential} also includes what would
normally be considered term-level arguments.

For example, let's consider these
Haskell definitions:
%
\begin{code}
data Tuple a where
  MkTuple :: forall a. Int -> Char -> a -> Tuple a
data Ex a where
  MkEx :: forall a b. b -> a -> Ex a
\end{code}
%
If I have a value of type |Tuple Double|, then I know the types of the data
stored in a |MkTuple|, but I do not know the |Int|, the |Char|, or the
|Double|---these are the existentials. Similarly, if I have a value of type
|Ex Char|, then I know that the type of one argument to |MkEx|, but I do not
know the type of the other; I also know neither value. In this case, the
second type, |b|, is existential, as are both values (of types |b| and |a|,
respectively).

The use of the term \emph{existential} to refer to term-level arguments
may be non-standard, but it is quite convenient (while remaining
 technically accurate)
in the context of a pure
type system with ADTs.

\subsection{Looking up type constants}
\label{sec:ty-con}

Information about type constants is retrieved via the following
judgment:\\[\baselineskip]
\ottdefnTc{}

\begin{figure}
\ottdefnVec{}
\caption{Formation of vectors $[[ps]]$}
\label{fig:vec-judgment}
\end{figure}

The judgment $[[S |-tc H : D1;D2;H']]$
retrieves three pieces of data about a type constant
$[[H]]$: its universals, its existentials, and the root of the result type.
This judgment is best understood in concert with the typing rule that handles
type constants, which also uses the typing judgment on vectors, presented
in \pref{fig:vec-judgment}:
\[
\ottdruleTyXXCon{}
\]
Let's tackle these in order of complexity.

\subsubsection{The constant $[[Type]]$}
The constant $[[Type]]$ has no universals, no existentials, and $[[Type]]$'s
type is $[[Type]]$, as \rul{Tc\_Type} tells us. Thus, in the use of
\rul{Ty\_Con} when $[[H{ts}]]$ is just $[[Type{blank}]]$ (normally, we omit
such empty braces), we see that $[[D1]]$, $[[D2]]$, and $[[ts]]$ are all empty,
meaning that we get $[[S;G |-ty Type{} : Type{}]]$, as desired.

\subsubsection{Algebraic datatypes}
\label{sec:relevance-of-datatypes}

Let's consider \id{Maybe} as an example. We see that the list of universals
$[[D1]]$ is empty for all ADTs. Thus, the list of universal arguments $[[ts]]$
must be empty in \rul{Ty\_Con}. The list of existentials $[[D2]]$ is
$[[a :Rel Type{}]]$ and the result type
root is $[[Type]]$, both by \rul{Tc\_ADT}. We thus get
$[[S;G |-ty &Maybe{} : MPI a :Rel Type{}. Type{}]]$, as desired. (Note that
$[[a]]$ is unused in the body of the $[[MPI]]$ and thus that this type
could also be written as $[[Type{} -> Type{}]]$.)

I have argued here how the rules work out this case correctly,
but it may surprise the reader to see that the argument to \id{Maybe} is
treated as an \emph{existential} here---part of $[[D2]]$---and not a
universal. This could best be understood if we consider $[[Type]]$ itself
to be an open ADT (that is, an extensible ADT) with no universal parameters.
To make this even more concrete, here is how it might look in Haskell:
%
% NB: The ^^ after Int below is to prevent lhs2TeX from centering the
% column of constructors.
\begin{spec}
data Type where
  Bool    ::  Type
  Int ^^  ::  Type
  Maybe   ::  Type -> Type
  Proxy   ::  forall (k :: Type). k -> Type
  ...
\end{spec}
%
Thinking of ADTs this way, we can see why the argument to |Maybe| is
existential, just like other arguments to constructors. We can also see
that the kind parameter |k| to |Proxy| is also considered an existential
in this context.

The last detail to cover here is the relevance annotation on the $[[as]]$,
as assigned in \rul{Tc\_ADT}: all the variables are considered relevant.
This is a free choice in the design of \pico/. Any choice of relevance
annotations would work, including allowing the user to decide on a case-by-case
basis. I have chosen to mark them as relevant, however, with the consideration
that these ADTs might be present at runtime. There is nothing in \pico/ that
restricts ADTs to be present only at compile time; the user might write a
runtime computation that returns |Bool|, for example.\footnote{This
statement does not mean that you can extract the value |Maybe Int| from
|Just 3|, which would require preserving all types for runtime.} (Such a facility
replaces Haskell's current |TypeRep| facility~\cite{typerep}.) By marking
the ADT parameters as relevant, a runtime decision can be made between, say,
|Maybe Int| and |Maybe Bool|. This seems useful, and so I have decided to make
these parameters relevant.

\subsubsection{Data constructors}
\label{sec:pico-either}

The most involved case is that for data constructors, where both the
universals and the existentials can be non-empty. We'll try to understand
\rul{Ty\_Con} first by an example inspired by the Haskell
expression |Left True :: Either Bool Char|. Let's recall the definition
of |Either|, a basic sum type:
%
\begin{code}
data Either :: Type -> Type -> Type where
  Left   :: a -> Either a b
  Right  :: b -> Either a b
\end{code}
In \pico/ this looks like the following:
\[
\begin{array}{l@@{\,}l}
[[S]] =& [[ &Either : (&&ax : Type{}, &&bx : Type{}), &Left : (&&xx :Rel &&ax; &Either), &Right : (&&xx :Rel &&bx; &Either)]], \\
& [[&Bool : (empty), &True : (empty; &Bool), &False : (empty; &Bool), &Char : (empty)]]\\[1ex]
\multicolumn{2}{l}{
[[S; empty |-ty &Left{&Bool{}, &Char{} } &True{} : &Either{} &Bool{} &Char{} ]]}
\end{array}
\]
%
We see how the universal arguments |Bool| and |Char| to the constructor |Left|
are specified in the subscript; without these arguments, there would be no way
to get the type of |Left True| in a syntax-directed way.

\paragraph{Universal argument saturation}
The grammar for type constant occurrences in types requires them to appear
fully saturated with respect to universals but perhaps unsaturated with
resepct to existentials. There are several reasons for this seemingly-peculiar
design:
\begin{itemize}
\item It is helpful to separate universals from existentials in a variety of
  contexts. For example, existentials are brought into scope on a
  \ottkw{case}-match, while universals are not. Separating out these arguments
  is also essential in the step rule \rul{S\_KPush}.

\item If \pico/ did not allow matching on unsaturated constants, it might
be most natural to require saturation with respect to both universals
and existentials (while still keeping these different arguments separate).
This would allow, for example, for a simple statement of the canonical
forms lemma (\pref{lem:canon-form}),
because only a $[[\ ]]$-expression would have a $[[PI]]$-type.

However, since \pico/ does allow matching on unsaturated constants, the
grammar must permit this form. Because of \pico/'s discernment between
matchable $[[MPI]]$ and unmatchable $[[UPI]]$, we retain the simplicity
of the canonical forms lemma, as any expression classified by a $[[MPI]]$
must be a partially applied constant and any expression classified by a
$[[UPI]]$ must be a $[[\ ]]$.

\item All univeral arguments are always irrelevant and erased during
type erasure (\pref{sec:type-erasure}). It is thus natural to separate
these from existentials in the grammar.
\end{itemize}

As with many design decisions, it is possible to redesign \pico/ and
avoid this unusual choice, but in my opinion, this design pays its
weight nicely.

\paragraph{Typing rules for data constructors}
The \rul{Tc\_DataCon} rule looks up a data constructor $[[K]]$ in the
signature $[[S]]$ to find its telescope of existentials $[[D]]$
and parent datatype $[[T]]$. The second premise of the rule then
looks up $[[T]]$ to get the universals. The universals are annotated
with $[[Irrel]]$, as universals are always irrelevant in data
constructors---universal arguments are properly part of the type
of a data constructor and are thus not needed at runtime. The
telescope of existentials $[[D]]$ and datatype $[[T]]$ are also
returned from $[[|-tc]]$.

Rule \rul{Ty\_Con} checks the supplied arguments $[[ts]]$ against
the telescope of universals, here named $[[D1]]$. Note that $[[ts]]$
are checked against $[[Rel(D1)]]$; the braces that appear in the
production $[[H{ts}]]$ are part of the concrete syntax and do not
represent wrapping each individual $[[t]] \in [[ts]]$ in braces
(cf.~\pref{sec:type-app-irrelevant}). Rule \rul{Ty\_Con} then
builds the result type, a $[[MPI]]$-type binding the existentials
and producing $[[H']]$---that is, the parent type $[[T]]$---applied
to all of the universals.

\section{Examples}
\label{sec:pico-examples}
\label{sec:pico-gadt-example}

Though these may make sense more fully after reading the sections below, it
may be helpful at this point to see a few short examples of \pico/ programs. 

We will work with a definition of length-indexed vectors, a tried-and-true
example of the design of GADTs. Here is how they are declared in Haskell
(further explanation is available in \pref{sec:length-indexed-vectors}):
%if style == poly
%format (UU x) = x
%endif
\begin{code}
data Nat = Zero | Succ Nat
data Vec :: Type -> Nat -> Type where
  VNil   :: Vec a (UU 0)
  VCons  :: a -> Vec a n -> Vec a (!Succ n)
\end{code}
If \pico/ had a concrete syntax, these declarations would be transformed
roughly into the following:
\begin{spec}
Nat   ::  Type
Zero  ::  Nat
Succ  ::  Nat -> Nat

Vec    ::  Type -> Nat -> Type
VNil   ::  forall (a :: Type) (n :: Nat). (n ~ Zero) -> Vec a n
VCons  ::  forall (a :: Type) (n :: Nat). 
           forall (m :: Nat). (n ~ Succ m) -> a -> Vec a m -> Vec a n
\end{spec}
The change seen here is just the transformation between specifying a GADT
equality constraint
via a return type in a declaration to using an explicit existential variable
with an explicit equality constraint.

In the abstract syntax of \pico/,
these declarations are represented by this signature $[[S0]]$:
\[
\begin{array}{r@@{\,}l}
[[S0]] = & [[&Nat : (empty)]], \\
& [[ &Zero : (empty; &Nat)]], \\
& [[ &Succ : (_ :Rel &Nat{}; &Nat)]], \\
 & [[&Vec : (&&ax : Type{}, &&nx : &Nat{})]], \\
& [[ &VNil : (c : &&nx [&Nat{}]~[&Nat{}] #0{}; &Vec)]], \\
& [[&VCons : (&&mx :Irrel &Nat{}, c : &&nx [&Nat{}]~[&Nat{}] &Succ{} &&mx, _ :Rel &&ax, _ :Rel &Vec{} &&ax &&mx; &Vec)]]
\end{array}
\]
Let's walk through these declarations.
Our binding for |Nat| includes an empty list
of universally quantified type variables. This binding is followed
by specifications for |Zero|, which lists no existential variables and
is a constructor of the datatype |Nat|, and |Succ|, which has one 
(anonymous) existential
variable and also belongs to |Nat|. 
The bindings for |Vec| and its constructors are similar, but with more
parameters. Note the coercion bindings in the telescopes associated with
|VNil| and |VCons|, as well as the irrelevant binding for the existential
|m| of |VCons|. The design we see here, echoing the Haskell, does not permit
runtime extraction of the length of a vector. If we changed the |m| to be
relevant, then runtime length extraction would be trivial.

We will now look at a few simple operations on vectors, first in Haskell
and then in \pico/.\footnote{In these examples, I assume the use of numerals
to specify elements of type |Nat|, and I also assume the existence of, e.g.,
|Bool|.}

\subsection{|isEmpty|}
First, a very simple test for emptiness, in order to familiarize ourselves
with pattern-match syntax in \pico/:
\begin{code}
isEmpty :: Vec a n -> Bool
isEmpty VNil        = True
isEmpty (VCons {})  = False
\end{code}
Translated to \pico/, we get the following:
\[
\begin{array}{r@@{\,}c@@{\,}l}
[[&isEmpty]] &:& [[UPI (&&ax :Irrel Type{}), (&&nx :Irrel &Nat{}), (&&vx :Rel &Vec{} &&ax &&nx). &Bool{}]] \\
[[&isEmpty]] &=& [[\ ]] [[(&&ax :Irrel Type{}), (&&nx :Irrel &Nat{}), (&&vx :Rel &Vec{} &&ax &&nx)]]. \\
&& [[case_&Bool{} &&vx of blank]] \\
&& \quad
\begin{array}{l@@{\,}l}
 [[&VNil]] &[[->]] [[\ (c : &&nx [&Nat{}]~[&Nat{}] #0{}), (c0 : &&vx [&Vec{} &&ax &&nx]~[&Vec{} &&ax &&nx] &VNil{&&ax,&&nx} c). &True{}]] \\
 [[&VCons]] &[[->]]
\begin{array}[t]{@@{}l@@{}l}
 [[\ ]] & [[ (&&mx :Irrel &Nat{}), (c : &&nx [&Nat{}]~[&Nat{}] &Succ{} &&mx), (&&xx :Rel &&ax), (&&xsx :Rel &Vec{} &&ax &&mx)]], \\
& [[ (c0 : &&vx [&Vec{} &&ax &&nx]~[&Vec{} &&ax &&nx] &VCons{&&ax,&&nx} &&mx c &&xx &&xsx)]]. \\
\multicolumn{2}{@@{}l}{[[ &False{}]]}
\end{array}
\end{array}
\end{array}
\]
The most striking feature about this \pico/ code is the form of the \ottkw{case}
expression. Unlike the concrete syntax of Haskell, patterns in \pico/ do not
directly bind any arguments. Note that there are no variable bindings to the left
of the arrows in the case-branches. Instead, I have chosen to have $\lambda$s
to the right of the arrow. This design choice greatly simplifies the typing
and scoping
rules for pattern matches, because it removes a binding site in the grammar
(leaving us with two: $[[PI]]$ and $[[\ ]]$). Because of the typing rule
for \ottkw{case} expressions (\pref{sec:pico-case}),
we still must bind all of the existentials
of a data constructor when matching against it---even when these existentials
are ignored, as we see here.

The matches also bind a variable not mentioned in the data constructors'
existentials: the coercion variable $[[c0]]$. This coercion witnesses the
equality between the scrutinee ($[[&&vx]]$, in this case) and the applied
data constructor that introduces the case-branch. This coercion variable
is bound in all matches, meaning that all pattern matching in \pico/
is dependent pattern matching.\footnote{Contrast to Gundry \citep{gundry-thesis},
which has two separate constructs, \ottkw{case} and \ottkw{dcase}, only
the latter of which does dependent matching.}

\subsection{|replicate|}
Let's now look at |replicate|, one of the simplest functions that requires
a proper $[[PI]]$-type. First, in Haskell: \rae{Should this be colored?}
%
\begin{spec}
replicate :: pi n -> a -> Vec a n
replicate Zero      _ = VNil
replicate (Succ m)  x = VCons x (replicate m x)
\end{spec}

%if style == newcode
\begin{code}
$(genSingletons [''Nat])

replicate :: Sing n -> a -> Vec a n
replicate SZero _ = VNil
replicate (SSucc m) x = VCons x (replicate m x)
\end{code}
%endif

\noindent
Now, in \pico/:
\[
\begin{array}{r@@{\,}c@@{\,}l}
[[&replicate]] &:& [[UPI (&&ax :Irrel Type{}), (&&nx :Rel &Nat{}), (&&xx :Rel &&ax). &Vec{} &&ax &&nx]] \\
[[&replicate]] &=& [[\ ]] [[&&ax :Irrel Type{}]]. \\
&&
\begin{array}{l@@{\,}l@@{}l}
\ottkw{fix} & [[\ ]] & [[(&&rx :Rel UPI (&&nx :Rel &Nat{}), (&&xx :Rel &&ax). &Vec{} &&ax &&nx)]], \\
&& [[(&&nx :Rel &Nat{}), (&&xx :Rel &&ax)]]. \\
& \multicolumn{2}{@@{\,}l}{%
\begin{array}{l}
[[case_{{&Vec{} &&ax &&nx}} &&nx of blank]] \\
\quad \begin{array}{l@@{\,}l}
[[&Zero]] &[[->]] [[\ c0 : &&nx [&Nat{}]~[&Nat{}] &Zero{}. &VNil{&&ax,&&nx} c0]] \\
[[&Succ]] &[[->]] [[\ &&mx :Rel &Nat{}, c0 : &&nx [&Nat{}]~[&Nat{}] &Succ{} &&mx. &VCons{&&ax,&&nx} {&&mx} c0 &&xx (&&rx &&mx &&xx)]]
\end{array}
\end{array}}
\end{array}
\end{array}
\]

This example shows the (standard) use of \ottkw{fix} as well as some of the
more exotic features of \pico/. In the case-branches, we see how we pass
universal arguments to the data constructors |VNil| and |VCons|. We also
see how we have to wrap irrelevant arguments (the $[[{&&mx}]]$ in the last
line) in braces. This example also shows where the coercion variable
$[[c0]]$ comes into play: it's needed to provide the coercion to the
|VNil| and |VCons| constructors to prove that the universal argument
$[[&&nx]]$ is indeed of the shape required for these constructors.
Without the ability to do a dependent pattern match, this example would
be impossible to write.\footnote{Unless you fake dependent types using
singletons or some other technique.}

\subsection{|append|}
\label{sec:example-with-stepn}

We'll now examine how to append two vectors. This operation will also
require the use of an addition operation, defined using prefix notation
so as not to provide a parsing challenge: \rae{color?}
%
\begin{spec}
plus :: Nat -> Nat -> Nat
plus Zero      n = n
plus (Succ m)  n = Succ (plus m n)

append :: Vec a m -> Vec a n -> Vec a (!plus m n)
append VNil          ys = ys
append (VCons x xs)  ys = VCons x (append xs ys)
\end{spec}

%if style == newcode
\begin{code}
$(singletons [d|
  plus :: Nat -> Nat -> Nat
  plus Zero      n = n
  plus (Succ m)  n = Succ (plus m n)
  |])

append :: Vec a m -> Vec a n -> Vec a (Plus m n)
append VNil ys = ys
append (VCons x xs) ys = VCons x (append xs ys)
\end{code}
%endif  

\begin{comment}
plus : pi (m : Nat) (n : Nat). Nat
plus = \ m n.
       case_Nat m of
         Zero -> \ c0 . n
         Succ -> \ m' c0 . Succ (plus m' n)

append : pi (a : Type) (m : Nat) (n : Nat) (xs : Vec a m) (ys : Vec a n).
            Vec a (plus m n)
append = \ a.
         fix \ (app : pi (m : Nat) (n : Nat) (xs : Vec a m) (ys : Vec a n).
                      Vec a (plus m n))
               (m : Nat) (n : Nat) (xs : Vec a m) (ys : Vec a n).
             case_(Vec a (plus m n)) xs of
               VNil -> \ (c : m ~ Zero) c0.
                       let c1 := <plus> c <n> in
                       let c2 := step^k (plus 0 n) in
                       ys ||> sym (<Vec> <a> (c1 ;; c2))
               VCons -> \ (m' : Nat) (c : m ~ Succ m') (x : a) (xs' : Vec a m')
                          (c0 : xs ~ VCons {m'} c x xs').
                        let c1 := <plus> c <n> in
                        let c2 := step^k (plus (Succ m') n) in
                        VCons{a,plus m n} {plus m' n} (c1 ;; c2) x (app m' n xs' ys)

g : plus m n ~ n
g = g1 ;; g2

g1 : plus m n ~ plus 0 n
g1 = <plus> c <n>

g2 : plus 0 n ~ n

step (plus 0 n) : plus 0 n ~ 

g3 : plus m n ~ Succ (plus m' n)
g3 = g4 ;; g5

g4 : plus m n ~ plus (Succ m') n
g4 = <plus> c <n>

g5 : plus (Succ m') n ~ Succ (plus m' n)
g5 = step^k' plus (Succ m') n
\end{comment}

\noindent And in \pico/ (where I elide the uninteresting |plus| for
brevity):
\[
\begin{array}{r@@{\,}c@@{\,}l@@{}}
[[&append]] &:& 
\begin{array}[t]{@@{}l@@{}l@@{}}
[[UPI]] & [[(&&ax :Irrel Type{}), (&&mx :Irrel &Nat{}), (&&nx :Irrel &Nat{}), (&&xsx :Rel &Vec{} &&ax &&mx), (&&ysx :Rel &Vec{} &&ax &&nx)]].\\
& [[&Vec{} &&ax (&plus &&mx &&nx)]]
\end{array} \\
[[&append]] &=&
\begin{array}[t]{@@{}l@@{}l@@{}}
[[\ ]] & [[(&&ax :Irrel Type{})]]. \\
& \ottkw{fix}\,
\begin{array}[t]{@@{}l@@{}l@@{}}
[[\ ]] & ([[&app]] [[:Rel]]
\begin{array}[t]{@@{}l@@{}l@@{}}
[[ UPI]] & [[ (&&mx :Irrel &Nat{}), (&&nx :Irrel &Nat{}), (&&xsx :Rel &Vec{} &&ax &&mx), (&&ysx :Rel &Vec{} &&ax &&nx)]]. \\
& [[ &Vec{} &&ax (&plus &&mx &&nx) ]]),
\end{array} \\
& [[(&&mx :Irrel &Nat{}), (&&nx :Irrel &Nat{}), (&&xsx :Rel &Vec{} &&ax &&mx), (&&ysx :Rel &Vec{} &&ax &&nx)]]. \\
\multicolumn{2}{@@{}l@@{}}{
[[case_{{&Vec{} &&ax (&plus &&mx &&nx)}} &&xsx of blank]]} \\
\multicolumn{2}{@@{}l@@{}}{
\quad \begin{array}{l@@{\,}c@@{\,}l@@{}}
[[&VNil]] &[[->]]& [[\ ]] [[(c : &&mx [&Nat{}]~[&Nat{}] &Zero{}), (c0 : &&xsx [&Vec{} &&ax &&mx]~[&Vec{} &&ax &&mx] &VNil{&&ax,&&mx} c)]]. \\
&& [[let c1 := <&plus> c <&&nx> in blank]] \\
&& [[let c2 := step^j (&plus &Zero{} &&nx) in blank]] \\
&& [[&&ysx |> sym (&Vec{} <&&ax> (c1 ;; c2))]] \\
[[&VCons]] &[[->]]& [[\ ]]
\begin{array}[t]{@@{}l@@{}}
 [[(&&m'x :Irrel &Nat{}), (c : &&mx [&Nat{}]~[&Nat{}] &Succ{} &&m'x), (&&xx :Rel &&ax), (&&xs'x :Rel &Vec{} &&ax &&m'x)]] \\
[[(c0 : &&xsx [&Vec{} &&ax &&mx]~[&Vec{} &&ax &&mx] &VCons{&&ax,&&mx} {&&m'x} c &&xx &&xs'x)]].
\end{array}\\
&& [[let c1 := <&plus> c <&&nx> in blank]] \\
&& [[let c2 := step^kk (&plus (&Succ{} &&m'x) &&nx) in blank]] \\
&& [[&VCons{&&ax, &plus &&mx &&nx} {&plus &&m'x &&nx} (c1 ;; c2) &&xx (&app {&&m'x} {&&nx} &&xs'x &&ysx)]]
\end{array}}
\end{array}
\end{array}
\end{array}
\]

This is the first example where we are required to write non-trivial
coercions. Let's start by considering the right-hand side of the
|VNil| case. As we see in the Haskell version, we wish to return |ys|.
However, |ys| has type |Vec a n|, and we need to return something of
type |Vec a (plus m n)|. We must, accordingly, cast |ys| to have type
|Vec a (plus m n)|. This is what the coercion $[[sym (&Vec{} <&&ax> (c1 ;; c2))]]$
is doing; it proves that |Vec a n| is in fact equal to |Vec a (plus m n)|.
Both the starting type |Vec a n| and the ending type |Vec a (plus m n)| have
the same prefix of |Vec a|. We use a congruence coercion
(\pref{sec:congruence-coercions}) $[[&Vec{} <&&ax> g]]$ to simplify our
problem. Now, we need only a coercion
$[[g]]$ that proves |plus m n| equals |n|.
(The use of \ottkw{sym} helpfully has reversed our proof obligation.)
This $[[g]]$ is built in two steps, tied together by using our transitivity
operator $[[;;]]$: $[[c1]]$, which uses our reflexivity operator
$\langle \cdot \rangle$, proves that |plus m n| equals |plus 0 n|
by using $[[c]]$, the GADT equality constraint from the |VNil| constructor;
and $[[c2]]$ proves that |plus 0 n| equals |n|.\footnote{Recall (\pref{fig:pico-notation}) that \ottkw{let} is defined by simple expansion. It is not
properly a language construct but instead is just a convenient abbreviation
in this writeup.} For this last coercion,
we use the \ottkw{step} coercion that reduces a type by one step. It is
fiddly (and unenlightening) to calculate the precise number of steps
necessary to get from |plus 0 n| to |n|, so I have just written that this
takes $j$ steps. It is straightforward to calculate $j$ in practice.

The coercion manipulations in the |VCons| case are similar.

Also of note in this example is the interplay between relevant variables
and irrelevant ones. We see that the lengths |m| and |n| are irrelevant
throughout this function. Indeed, we do not need lengths at runtime
to append two vectors. Accordingly, we can see that all uses of |m| and
|n| (or |m'|) occur in irrelevant contexts, such as coercions or
irrelevant arguments to functions.

\subsection{|safeHead|}
\label{sec:pico-example-absurd}

With length-indexed vectors, we can write a safe |head| operation, allowed
only when we know that the vector has a non-zero length:
%
\begin{code}
safeHead :: Vec a (!Succ n) -> a
safeHead (VCons x _) = x
\end{code}
%
Note that |safeHead| contains a total pattern match; the |VNil| alternative
is impossible given the type signature of the function.
This function translates to \pico/ thusly:
\[
\begin{array}{r@@{\,}c@@{\,}l@@{}}
[[&safeHead]] &:& [[UPI (&&ax :Irrel Type{}), (&&nx :Irrel &Nat{}), (&&vx :Rel &Vec{} &&ax (&Succ{} &&nx)). &&ax]] \\
[[&safeHead]] &=& [[\ ]] [[(&&ax :Irrel Type{}), (&&nx :Irrel &Nat{}), (&&vx :Rel &Vec{} &&ax (&Succ{} &&nx))]]. \\
&& [[case_&&ax &&vx of blank]] \\
&& \quad
\begin{array}{@@{}l@@{\,}l}
[[&VNil]] &[[->]] [[\ (c : &Succ{} &&nx [&Nat{}]~[&Nat{}] &Zero{}), (c0 : &&vx [&Vec{} &&ax (&Succ{} &&nx)]~[&Vec{} &&ax (&Succ{} &&nx)] &VNil{a,&Succ{} &&nx} c). absurd c &&ax]] \\
[[&VCons]] &[[->]] 
\begin{array}[t]{@@{}l@@{}l}
[[\ ]] & [[(&&mx :Irrel &Nat{}), (c : &Succ{} &&nx [&Nat{}]~[&Nat{}] &Succ{} &&mx), (&&xx :Rel &&ax), (&&xsx :Rel &Vec{} &&ax &&mx)]], \\
& [[(c0 : &&vx [&Vec{} &&ax (&Succ{} &&nx)]~[&Vec{} &&ax (&Succ{} &&nx)] &VCons{&&ax, &Succ{} &&nx} {&&mx} c &&xx &&xsx)]]. \\
\multicolumn{2}{@@{}l}{[[ &&xx]]}
\end{array}
\end{array}
\end{array}
\]

The new feature demonstrated in this example is the \ottkw{absurd} operator,
which appears in the body of the |VNil| case.
In order to be sure that \ottkw{case} expressions do not get stuck,
the typing rules
require that all matches are exhaustive. However, in general, in can be
undecidable to determine whether the type of a scrutinee indicates that
a certain constructor can be excluded. In order to step around this
potential trap, \pico/ supports absurdity elmination through \ottkw{absurd}.
The coercion passed into \ottkw{absurd} ($[[c]]$, above) must prove that
one constant equals another. This is, of course, impossible, and so we
allow $[[absurd g t]]$ to have any type $[[t]]$.

\section{Types $[[t]]$}
\label{sec:pico-types}

Having gone through several examples explaining the flavor of \pico/ code,
let's now walk through the remaining typing rules of the system.
Recall that we have already seen the typing rules for variables,
\rul{Ty\_Var} in \pref{sec:ty-var}, and constants, \rul{Ty\_Con} in
\pref{sec:ty-con}.

\subsection{Abstractions}
\label{sec:pico-type-abstractions}

The definition for types $[[t]]$ includes the usual productions for a pure
type system, including both a $[[PI]]$-form and a $[[\ ]]$-form:
\begin{gather*}
\ottdruleTyXXPi{}\rulesep
\ottdruleTyXXLam{}
\end{gather*}
%
The only novel component of these rules is the use of $[[Rel(G)]]$ in the
premise to \rul{Ty\_Pi}. Resetting the context here is appropriate because
we still wish to use irrelevant variables in types. As an example, the
use of $[[Rel(G)]]$ here is necessary to allow
the type of Haskell's |undefined|: $[[UPI a:Irrel Type{}. a]]$.

\subsection{Applications}
\label{sec:type-app-irrelevant}

Terms with a $[[PI]]$-type (either type constants or $[[\ ]]$-terms)
can be applied to arguments, via these rules:
\begin{gather*}
\ottdruleTyXXAppRel{}\rulesep
\ottdruleTyXXAppIrrel{}\rulesep
\ottdruleTyXXCApp{}
\end{gather*}
%
We see in these rules that the argument form for an abstraction over an
irrelevant binder requires braces. (See the conclusion of \rul{Ty\_AppIrrel}.)
The system would remain syntax-directed without marking off irrelevant
arguments, but type erasure (\pref{sec:type-erasure}) would then need to
be type-directed. It seems easier just to separate relevant arguments
from irrelevant arguments syntactically.

Note also the use of $[[Rel(G)]]$ in \rul{Ty\_AppIrrel} and \rul{Ty\_CApp};
resetting the context here happens because irrelevant arguments and coercions
are erased in the running program.

\subsection{Kind casts}

We can always use an equality to change the kind of a type:
\[
\ottdruleTyXXCast{}
\]
In this rule, a type of kind $[[k1]]$ is cast by $[[g]]$ to have a type
$[[k2]]$. As always, the coercion is checked in a reset context $[[Rel(G)]]$.
The final premise, $[[S;Rel(G) |-ty k2 : Type{}]]$ is implied by
the first premise (which is actually
$[[S;Rel(G) |-co g : k1 (Type{})~(Type{}) k2]]$) via proposition regularity,
but we must include it in order to prove
kind regularity\footnote{Both regularity lemmas are stated in \pref{fig:pico-judgments}.} before we prove coercion regularity.

\subsection{\ottkw{fix}}

\Pico/ supports fixpoints via the following rule:
\[
\ottdruleTyXXFix{}
\]
The rule requires type $[[t]]$ to have an unmatchable $[[UPI]]$ so that
we can be sure that $[[t]]$'s canonical form is indeed a $[[\ ]]$; otherwise
the progress theorem (\pref{sec:progress-thm-statement}) would not hold.

\subsection{\ottkw{case}}
\label{sec:pico-case}

Unsurprisingly, the typing rules to support pattern matching are the most
involved, presented here with the rules to type-check \ottkw{case}
branches:
\[
\ottdruleTyXXCase{}
\]
\ottdefnAlt{}

Most of the premises of \rul{Ty\_Case} are easy enough to explain:
\begin{itemize}
\item The result kind of a \ottkw{case}, $[[k]]$ is given right in the
syntax; the first premise $[[S;Rel(G) |-ty k : Type{}]]$ ensures that
it is a valid result kind.
\item We also must check the kind of the scrutinee, $[[t]]$. This kind
must have the form $[[MPI D. H{} ss]]$ (note the matchable $[[MPI]]$),
where the $[[ss]]$ cannot mention any of the variables bound in $[[D]]$.
(The $[[S;Rel(G) |-ty H{} ss : Type{}]]$ premise checks this scoping
condition.) Note that the scrutinee's type may be a $[[MPI]]$-type
in order to support matching against partially applied type and data
constructors.
\item The alternatives must be exhaustive and distinct. Exhaustivity
is needed to prove that a well-typed \ottkw{case} cannot get stuck,
and distinctness is necessary to prove that the reduction relation is
deterministic.
\end{itemize}

We are left to consider type-checking the alternatives. This is done
via the judgment with schema $[[S;G;s;t |-alt alt : k]]$. When 
$[[S;G;s;t |-alt alt : k]]$ holds, we know that the expression in the
case alternative $[[alt]]$ produces a type of kind $[[k]]$ when 
considered with signature $[[S]]$ and typing context $[[G]]$ and when
matched against a scrutinee $[[t]]$ of type $[[s]]$. The premises
of \rul{Ty\_Case} indeed check that all alternatives satisfy this
judgment.

\subsubsection{Checking \ottkw{case} alternatives}

The rule \rul{Alt\_Match} is intricate. This rule assumes we have
a scrutinee $[[t0]]$ of type $[[MPI D'. H'{} ss]]$, and we are checking
a case alternative $[[H -> t]]$.

First, we must verify that the constant $[[H]]$ is classified by $[[H']]$---that
is, either $[[H]]$ is a data constructor of the datatype $[[H']]$ or
$[[H]]$ is a datatype and $[[H']]$ is $[[Type]]$. We say that $[[H']]$ is
the \emph{parent} of $[[H]]$. This check is done by the
$[[S |-tc H : D1;D2;H']]$ premise, which also extracts the
universals $[[D1]]$ and existentials $[[D2]]$.

The next premise (reading
to the right) uses $[[D2[ss/dom(D1)] ]]$ to instantiate
the existentials with the known choices for
the universals. These known choices $[[ss]]$ are obtained from
determining the type of the scrutinee; see the appearance of
$[[ss]]$ in the type appearing before the $[[|-alt]]$ in the
conclusion of the rule. The second premise also splits the
instantiated existentials into two telescopes, $[[D3]]$ and $[[D4]]$.

Note that $[[D']]$ is an input to this rule; it is extracted from
the type of the scrutinee.
Accordingly, the third premise $[[dom(D4) = dom(D')]]$ serves two roles:
it fixes
the length of $[[D4]]$ (and, hence, $[[D3]]$) and it also forces any
renaming of bound variables necessary to line up the telescopes $[[D']]$
and $[[D4]]$. Keeping the names of the bound variables consistent between
these telescopes simplifies this rule. Note that, in the event that the
scrutinee is a fully-saturated datatype or data constructor,
$[[D4 = D']] = [[empty]]$ and $[[D3 = D2[ss/dom(D1)] ]]$.

The next premise uses a unification algorithm to make sure that the bound
telescope in the scrutinee's type, $[[D']]$, matches the expected shape
$[[D4]]$. We will return to this in \pref{sec:alt-match-matching}, below.
In the common case of $[[D' = empty]]$ (that is, full saturation of
the scrutinee), this premise is trivially satisfied. Also note that we do
not use the output of this premise, $[[theta]]$, anywhere in the rule, so
skipping it on a first reading is appropriate.

Lastly, we must check that the body of the alternative, $[[t]]$, has the
right type. This type must bind (by any combination of matchable $[[MPI]]$
and unmatchable $[[UPI]]$) all of the existentials in $[[D3]]$, as well
as the coercion variable witnessing the equality between $[[t0]]$ (the
scrutinee) and the applied $[[H]]$. In this rule the use of
$[[dom(D3)]]$ as a list of arguments to $[[H{ss}]]$ is a small pun;
we must imagine braces surrounding any variable in $[[dom(D3)]]$ that is
irrelevantly bound. The return type of the abstraction in $[[t]]$ must
be $[[k]]$, the result kind of the overall match.

For examples of this in action---at least in the fully saturated case---see
the worked out examples above (\pref{sec:pico-examples}).

\subsubsection{Unification in \rul{Alt\_Match}}
\label{sec:alt-match-matching}
\label{sec:example-using-kind-co}

Let's examine the use of unification in \rul{Alt\_Match} more carefully.
We will proceed by examining two examples, a simple one where unification
is unnecessary and a more involved one showing why we need this.

Our first example was given above, when first describing unsaturated matching
(\pref{sec:unsaturated-match-example}):
%{
%if style == newcode
%format IsLeft = "IsLeft2"
%endif
\begin{code}
type family IsLeft x where
  IsLeft !Left   = !True
  IsLeft !Right  = !False
\end{code}
%}
The translation of |Either| into \pico/ appears in \pref{sec:pico-either}.
This type family translated into the following \pico/ function (rewritten
to be lowercase according to Haskell naming requirements):
\[
\begin{array}{r@@{\,}c@@{\,}l}
[[&isLeft]] &:& [[UPI (&&ax :Irrel Type{}), (&&xx :Rel MPI (&&yx :Rel &&ax). &Either{} &&ax &&ax). &Bool{}]] \\
[[&isLeft]] &=& [[\ ]] [[(&&ax :Irrel Type{}), (&&xx :Rel MPI (&&yx :Rel &&ax). &Either{} &&ax &&ax)]] . \\
&& [[case_&Bool{} &&xx of blank]] \\
&& \quad
\begin{array}{l@@{\,}l}
[[&Left]] &[[->]] [[\ (c0 : &&xx [MPI (&&yx :Rel &&ax). &Either{} &&ax &&ax]~[MPI (&&yx :Rel &&ax). &Either{} &&ax &&ax] &Left{&&ax,&&ax}). &True{}]] \\
[[&Right]] &[[->]] [[\ (c0 : &&xx [MPI (&&yx :Rel &&ax). &Either{} &&ax &&ax]~[MPI (&&yx :Rel &&ax). &Either{} &&ax &&ax] &Right{&&ax,&&ax}). &False{}]]
\end{array}
\end{array}
\]
Comparing the first alternative against \rul{Alt\_Match}, we see the following
concrete instantiations of metavariables:
\[
\begin{array}{c@@{\quad}c}
\begin{array}{r@@{\,}l}
[[H &= &Left]] \\
[[D1 &= &&sx :Irrel Type{}, &&tx :Irrel Type{}]] \\
[[D2 &= &&yx :Rel &&sx]] \\
[[H' &= &Either]] \\
[[t0 &= &&xx]] \\
[[D' &= &&yx :Rel &&ax]]
\end{array}
&
\begin{array}{r@@{\,}l}
[[ss &= &&ax, &&ax]] \\
[[D3 &= empty]] \\
[[D4 &= &&yx :Rel &&ax]] \\
[[theta &= empty]] \\
[[t &= \ (c0 : &&xx [MPI (&&yx :Rel &&ax). &Either{} &&ax &&ax]~[MPI (&&yx :Rel &&ax). &Either{} &&ax &&ax] &Left{&&ax,&&ax}). &True{}]] \\
[[k &= &Bool{}]]
\end{array}
\end{array}
\]

In this example, the constructor is not applied to any existential variables, and
so $[[D3]]$, the telescope of binders that are to be bound by the match, is empty.
The only variable bound in the match body is the $[[c0]]$ dependent-match coercion
variable. Also note that $[[D4]]$, the instantiated suffix of the telescope of
existential arguments to |Left|, and $[[D']]$, the telescope of binders in the type
of the scrutinee, coincide. Accordingly, the match operation succeeds with an empty
substitution $[[theta = empty]]$.

In contrast, the following example shows why we need unification in \rul{Alt\_Match}:
\begin{code}
data X where
  MkX :: a -> a -> X
    -- NB: |a| is existential; no universals here

type family UnX x :: Bool where
  UnX (!MkX y) = y
\end{code}

\noindent Note that we're extracting the first (visible) argument from
an unsaturated use of |MkX|. This Haskell code translates to the following \pico/:
\[
\begin{array}{@@{}l@@{}}
\begin{array}{r@@{\,}l}
[[S]] =
& [[&X : (empty)]], \\
& [[&MkX : (&&ax :Irrel Type{}, &&yx :Rel &&ax, &&zx :Rel &&ax; &X)]]
\end{array}
\\[4ex]
\begin{array}{r@@{\,}c@@{\,}l}
[[&unX]] &:& [[UPI (&&xx :Rel MPI (&&zx :Rel &Bool{}). &X{}). &Bool{}]] \\
[[&unX]] &=& [[\ ]] [[(&&xx :Rel MPI (&&zx :Rel &Bool{}). &X{})]] . \\
&& [[case_&Bool{} &&xx of blank]] \\
&& \quad
[[&MkX]] [[->]]
\begin{array}[t]{@@{}l}
[[ \ ]] [[(&&ax :Irrel Type{}), (&&yz :Rel &&ax), (c0 : &&xx (MPI (&&zx :Rel &Bool{}). &X{})~(MPI (&&zx :Rel &&ax). &X{}) &MkX{} &&ax &&yz)]]. \\
[[&&yx |> sym (argk (kind c0))]]
\end{array}
\end{array}
\end{array}
\]
Before we get into the minutiae of \rul{Alt\_Match}, let's dwell a moment
on the cast necessary in the last line. According to both the type of
|unX| and the return type provided in the \ottkw{case}, the match must return
something of type |Bool|. Yet the body of a match must bind precisely the
existential variables of a data constructor; according to the definition of
|MkX|, the variable |y| has type |a|, not |Bool|. We thus must cast |y| from
|a| to |Bool|. We do this by extracting out the right coercion from $[[c0]]$.
This $[[c0]]$ is heterogeneous; I have typeset the code above with the kinds
explicit to show this. The left-hand kind is the declared type of |x|, binding
|z| of type |Bool|. The right-hand kind is the kind of |MkX a y|, which binds
|z| of type |a|. By using \ottkw{kind} (which extracts a kind equality from
a heterogeneous coercion; see \pref{sec:pico-kind-coercion}), followed by
\ottkw{argk} (which extracts a coercion between the kinds of the arguments
of $\Pi$-types; see \pref{sec:pico-argk-coercion}), and then \ottkw{sym} (which
reverses the orientation of a coercion), we get the coercion needed, of
type $[[&&ax [Type{}]~[Type{}] &Bool{}]]$.

Now, we'll try to understand the matching in \rul{Alt\_Match}. Let's once
again examine the concrete instantiations of the metavariables in
the rule:
\[
\begin{array}{c@@{\quad}c}
\begin{array}{r@@{\,}l}
[[H &= &MkX]] \\
[[D1 &= empty]] \\
[[D2 &= &&ax :Irrel Type{}, &&yx :Rel &&ax, &&zx :Rel &&ax]] \\
[[H' &= &X]] \\
[[t0 &= &&xx]] \\
[[D' &= &&zx :Rel &Bool{} ]]
\end{array}
&
\begin{array}{r@@{\,}l}
[[ss &= empty]] \\
[[D3 &= &&ax :Irrel Type{}, &&yx :Rel &&ax]] \\
[[D4 &= &&zx :Rel &&ax]] \\
[[theta &= &Bool{}/&&ax]] \\
[[t]] &= \langle \text{as above} \rangle \\
[[k &= &Bool{}]]
\end{array}
\end{array}
\]
Recall that $[[D3]]$ and $[[D4]]$ are the prefix and suffix, respectively,
of the telescope of existentials $[[D2]]$, after this telescope has been
instantiated with the known arguments for the universals. However, with |MkX|,
there are no universals at all (the datatype |X| takes no arguments), and
so this instantiation is a no-op. (The lack of universals shows up in the
equations above via an empty $[[D1]]$ and an empty $[[ss]]$.)
We thus have $[[D3,D4 = D2]]$, where the length of $[[D4]]$ must match
the length of $[[D']]$, the telescope of variable bound in the type
of the scrutinee. We see that the scrutinee $[[&&xx]]$ has type
$[[MPI (&&zx :Rel &Bool{}). &X{}]]$ and so $[[D' = &&zx :Rel &Bool{}]]$.
Thus $[[D3]]$---the existentials bound by the pattern match---has two
elements (|a| and |y|) and $[[D4]]$ has one (|z|).

We now must make sure that the shape of the types in $[[D']]$ match the
template given by the types in $[[D4]]$. That is, $[[D']]$ must be some
instance of $[[D4]]$, as determined by a unification algorithm
(discussed in more depth in \pref{sec:unification}). In this case,
the unification succeeds, assigning the type variable |a| to be |Bool|,
as shown in the choice for $[[theta]]$, above. Accordingly, the match
is well-typed.

Requiring this unification simply reduces the set of well-typed programs. It
is thus important to understand why the restriction is necessary. What goes
wrong if we omit it? The problem comes up in the proof for progress, in the
case where the scrutinee has a top-level cast. We will use step rule
\rul{S\_KPush} (see \pref{sec:pico-kpush}); that rule has several typing
premises\footnote{These unexpected typing premises to a small-step reduction
  rule are addressed in \pref{sec:typing-premises-in-reduction}.} which can
be satisfied only when this match succeeds. The restriction is
quite technical in nature, but any alternative not ruled out by the type
of the scrutinee should be acceptable. See the proof of progress in
\pref{app:progress-proof} for the precise details.

\subsubsection{Default alternatives}

\Pico/ supports \emph{default alternatives} through the form
$[[_ -> t]]$. This is a catchall case, to be used only when no
other case matches. In a language with a simpler treatment for
\ottkw{case} statements, a default would be unnecessary; every 
\ottkw{case} could simply enumerate all possible constructors.
However, \pico/ has two features that makes defaults indispensable:
\begin{itemize}
\item When matching on a scrutinee of kind $[[Type]]$ (or, say,
a function returning a $[[Type]]$), it would be 
impossible to enumerate all possibilities of this open type. Such
matches must have a default alternative.
\item If a scrutinee is partially applied, the typing rules dictate
a delicate unification process to make sure alternatives are well-typed.
(See \pref{sec:alt-match-matching}.) Given the design of \rul{Alt\_Match},
it is possible some of the constructors of a datatype would be ill-typed
as patterns in an unsaturated match. It might therefore be challenging to
detect whether an unsaturated match is exhaustive. To avoid this problem,
unsaturated matches may use a default alternative in order to be
unimpeachably exhaustive.
\end{itemize}

Happily, the typing rule \rul{Alt\_Default} for default alternatives
could hardly be simpler.

\subsubsection{Absurdity}

We saw in |safeHead| example (\pref{sec:pico-example-absurd}) the need
for absurdity elimination via the \ottkw{absurd} operator. Here is the
typing rule:
\[
\ottdruleTyXXAbsurd{}
\]
This rule requires that the coercion argument to \ottkw{absurd},
$[[g]]$, relate two unequal type constants $[[H1]]$ and $[[H2]]$.
The type $[[absurd g t]]$ can have any well-formed kind,
as chosen by $[[t]]$. Because $[[t]]$ is needed only to choose
the overall kind of the type, it is checked a context reset by
$[[Rel]]$.

As explained with the example, absurdity eliminiation is sometimes
needed in the
body of case alternatives that can never be reached.

\section{Operational semantics}
\label{sec:pico-op-sem}
\label{sec:progress-thm-statement}
\label{sec:operational-semantics}

Now that we have seen the static semantics of types, we are well-placed
to explore their dynamic semantics---how the types can reduce to values.
The dynamic semantics of types is expressed in \pico/ via a small-step
operational semantics, captured in the judgment
$[[S;G |-s t --> t']]$. Rules in this judgment are prefixed by
``\rul{S\_}''. It must be parameterized over typing environment because
of the push rules, as explained in \pref{sec:push-rules}.

The operational semantics obeys preservation and
progress theorems.

\begin{theorem*}[Preservation (\pref{thm:preservation})]
If $[[S;G |-ty t : k]]$ and $[[S;G |-s t --> t']]$, then
$[[S;G |-ty t' : k]]$.
\end{theorem*}

\begin{theorem*}[Progress (\pref{thm:progress})]
Assume $[[G]]$ has only irrelevant variable bindings.
If $[[S;G |-ty t : k]]$, then either $[[t]]$ is a value $[[v]]$, $[[t]]$
is a coerced value $[[v |> g]]$, or there exists $[[t']]$ such that
$[[S;G |-s t --> t']]$.
\end{theorem*}

The progress theorem is non-standard in two different ways:
\begin{itemize}
\item As discussed shortly (\pref{sec:evaluation-under-irrel-abs}),
reduction can take place in a context with irrelevant variable
bindings.
\item The progress theorem guarantees that a stuck type is \emph{either}
a value $[[v]]$ or a coerced value $[[v |> g]]$. This statement of
the theorem follows previous work (such as \citet{nokinds}) and is
applicable in the right spot in the proof of type erasure
(\pref{sec:type-erasure}).
\end{itemize}

The operational semantics are also deterministic.

\begin{lemma*}[Determinacy (\pref{lem:determinacy})]
If $[[S;G |-s t --> s1]]$ and $[[S;G |-s t --> s2]]$, then
$[[s1 = s2]]$.
\end{lemma*}

\subsection{Values}
\label{sec:evaluation-under-irrel-abs}
\label{sec:value-defn}
A subset of the types $[[t]]$ are considered values, written with the
metavariable $[[v]]$:

\begin{definition*}[Values]
Let values $[[v]]$ be defined by the following subgrammar of $[[t]]$:
\[
[[v]] \bnfeq [[H{ts} ps]] \bnfor [[PI d. t]] \bnfor [[\a:Rel k. t]]
                          \bnfor [[\a:Irrel k. v]] \bnfor [[\c:phi.t]]
\]
\end{definition*}
As we can see, values include applied constants, $\Pi$-types, and some
$\lambda$-types. However, note a subtle but important part of this definition:
the production for irrelevant abstractions is recursive. An irrelevant
abstraction $[[\a:Irrel k.t]]$ is a value if and only if $[[t]]$, the body,
is also a value. This choice is important in order to prove type erasure.

Our definition of values also gives us this convenient property:
\begin{lemma*}[Value types (\pref{lem:val-type})]
If $[[S;G |-ty v : k]]$, then $[[k]]$ is a value.
\end{lemma*}

During compilation, we wish to erase irrelevant components of an expression
completely. This includes irrelevant abstractions. Thus, the erasure operation,
written $[[ ||.|| ]]$ and further explored in \pref{sec:type-erasure},
includes this equation,
\[
[[ ||\a:Irrel k.t|| = ||t|| ]],
\]
erasing the abstraction entirely. 
Yet we must make sure to maintain the following lemma, referring to the
definition of values on erased expressions:

\begin{lemma*}[Expression redexes (\pref{lem:expr-redex})]
If $[[||t||]]$ is not an expression value, then $[[t]]$ is not a type
value.
\end{lemma*}

If we erase irrelevant abstractions but call all irrelevant abstractions
type values, then this lemma becomes false. We thus have a recursive
definition of values for irrelevant abstractions and, accordingly,
evaluate under irrelevant abstractions as well. See rule
\rul{S\_IrrelAbs\_Cong} in \pref{sec:step-congruence}.

\subsection{Reduction}

Several of the small-step rules perform actual reduction in a type:
\begin{gather*}
\ottdruleSXXBetaRel{}\rulesep
\ottdruleSXXBetaIrrel{}\rulesep
\ottdruleSXXCBeta{}\rulesep
\ottdruleSXXMatch{}\rulesep
\ottdruleSXXDefault{}\rulesep
\ottdruleSXXDefaultCo{}\rulesep
\ottdruleSXXUnroll{}
\end{gather*}
Note that \rul{S\_BetaIrrel} requires a value $[[v1]]$ in the body
of the abstraction in order to keep the rules deterministic. The only
other surprising feature in these rules is the way that \rul{S\_Match}
works, by applying the body of the alternative $[[t0]]$ to the actual
existential arguments to $[[H{ts}]]$ and a reflexive coercion. This
follows directly from my design of having \ottkw{case} alternatives
avoid a special binding form and use the existings forms in the language.

\subsection{Congruence forms}
\label{sec:step-congruence}

\Pico/ has several uninteresting congruence forms,
\begin{gather*}
\ottdruleSXXAppXXCong{}\rulesep
\ottdruleSXXCastXXCong{}\rulesep
\ottdruleSXXCaseXXCong{}\rulesep
\ottdruleSXXFixXXCong{}
\end{gather*}
and one more unusual one,
\[
\ottdruleSXXIrrelAbsXXCong{}
\]
This last rule allows for evaluation under irrelevant abstractions,
as described in \pref{sec:evaluation-under-irrel-abs}. It must add the
new irrelevant variable to the context, but is otherwise unexceptional.

\subsection{Push rules}
\label{sec:typing-premises-in-reduction}
\label{sec:push-rules}

\begin{figure}[p]
\newlength{\pushrulespace}
\setlength{\pushrulespace}{3ex}
\begin{gather*}
\ottdruleSXXTrans{} \\[\pushrulespace]
\ottdruleSXXPushRel{} \\[\pushrulespace]
\ottdruleSXXPushIrrel{} \\[\pushrulespace]
\ottdruleSXXCPush{} \\[\pushrulespace]
\ottdruleSXXAPush{} \\[\pushrulespace]
\ottdruleSXXFPush{} \\[\pushrulespace]
\ottdruleSXXKPush{}
\end{gather*}
\caption{Push rules}
\label{fig:push-rules}
\end{figure}

A system with explicit coercions like \pico/ must deal with the possibility
that coercions get in the way of reduction. For example, what happens when
we try to reduce
\[
[[ ((\ &&xx :Rel &Bool{}. &&xx) |> <&Bool{}>) &True{} ]] \quad ?
\]
Casting by a reflexive coercion should hardly matter, and yet no rule
yet described applies here. In particular, \rul{S\_BetaRel} does not.

To deal with this and similar scenarios, \pico/ follows the System FC
tradition and contains so-called \emph{push rules}, as shown in
\pref{fig:push-rules}. These rules are fiddly
but---ignoring \rul{S\_KPush} for a moment---straightforward. They simply serve to
rephrase a type with a coercion in the ``wrong'' place to an equivalent
type with the coercion moved out of the way. The rules can be derived
simply by following the typing rules and a desire to push the coercion aside.
Compared to previous work, the novelty here is in rules \rul{S\_APush}
(which handles reduction under irrelevant abstractions and must take into
account the awkward substitution in \rul{Co\_PiTy}; see \pref{sec:pico-co-pity})
and \rul{S\_FPush} (which handles \ottkw{fix}, never before seen in System FC),
but these rules again pose no design challenge other than the need for
attention to detail.

Many of the push rules share an odd feature: they have typing judgment
premises. These premises are the reason that the stepping judgment
is parameterized on a typing context. In order to prove the progress
theorem, it is necessary to prove \emph{consistency} (\pref{sec:consistency}),
which basically says that no coercion (made without assumptions) can prove,
say, |Int ~ Bool|. Still ignoring \rul{S\_KPush}, the consistency lemma
is enough to admit the typing premises to the push rules. However,
using consistency here would mean that the preservation theorem depends
on the consistency lemma, while consistency is normally used only to
prove progress. In seems to lead to cleaner proofs to avoid the dependency
of preservation on consistency, and so these typing premises are necessary.

The \rul{S\_KPush} rule is very intricate and makes use of a variety of
coercions. Explicating this rule in its entirety is best saved until after
we have covered coercions in more depth.

\section{Coercions $[[g]]$}
\label{sec:pico-coercions}

\Pico/ comes with a very rich theory of equality, embodied in the large
number of coercion forms. We will examine these forms in terms of the
properties they imbue on the equality relation. Note that the coercion
language is far from orthogonal; it is often possible to prove one thing
in multiple ways. Indeed, GHC comes with a
\emph{coercion optimizer}~\cite{coercion-optimization} that transforms
a coercion proving a certain proposition into another, simpler one proving
the same proposition. Enhancing this optimizer is beyond the scope of
this dissertation, however. It is needed only has a optimization in the
speed of compilation and is not central to the theory or metatheory of
the language.

All coercions are erased before runtime. (\pref{sec:type-erasure}) Accordingly,
we check for well-typed coercions (via the judgment
$[[S;G |-co g : phi]]$) only in contexts reset by the $[[Rel]](\cdot)$ operator.

\subsection{Equality is heterogeneous}
\label{sec:pico-kind-coercion}

The equality relation in \pico/ is heterogeneous, allowing |~| to relate
two types of different kinds. This is most clearly demonstrated in the
rule for the well-formedness of propositions:\footnote{This rule is the
entire judgment---there is no other form of proposition supported in
\pico/.} \\

\ottdefnProp{}

\noindent Note that the kinds $[[k1]]$ and $[[k2]]$ are allowed to differ.

The particular flavor of hetergeneous equality in \pico/ is so-called
``John Major'' equality~\cite{mcbride-thesis}, where an equality between two
types implies the equality between the kinds:
\[
\ottdruleCoXXKind{}
\]
As we can see, the \ottkw{kind} coercion form extracts a kind coercion
from a type coercion.

It's worth pausing here for a moment to consider two other meanings of
heterogeneous equality:
\paragraph{Trellys equality}
The equality relation studied in the Trellys project~\cite{trellys} a
heterogeneous equality with no equivalent of the \ottkw{kind} coercion. That
is, if we have a proof of $[[t1 (k1)~(k2) t2]]$, then there is no way to prove
$[[k1 [Type{}]~[Type{}] k2]]$ (absent other information). Indeed, Trellys
equality (that is, omitting the \rul{Co\_Kind} rule) would work in \pico/;
that coercion form is never needed in the metatheory. Omitting it would weaken
\pico/'s equational theory, however, and so I have decided to include it.

\paragraph{Flexible homogeneous equality}
Another possible meaning of heterogeneous equality is that $[[k1]]$ and $[[k2]]$
might not be definitionally equal, but they are provably equal.\footnote{I
am distinguishing here between \emph{definitional} equality and \emph{propositional} equality. The former, in \pico/, refers to $\alpha$-equivalence. Definitional
equality is the equality used implicitly in typing rules when we use the
same metavariable twice. If written explicitly, it is sometimes written
$\equiv$. Propositional equality, on the other hand, means an equality
that must be accompanied by a proof; in \pico/, |~| is the propositional
equality relation. Languages with a \rul{Conv} rule (\pref{sec:conv-rule})
import propositional equality into their definitional equality. \Pico/ does
not do this, requiring a cast to use a propositional equality.} Such
an equality would use this rule (not part of \pico/):
\[
\ottdrule{\ottpremise{[[S;G |-ty t1 : k1  //  S;G |-ty t2 : k2]]}%
\ottpremise{[[S;G |-co g : k1 [Type{}]~[Type{}] k2]]}}{[[S]];[[G]] [[|-prop]] [[t1]] \mathrel{{}^{[[k1]]}\sim_{[[g]]}^{[[k2]]}} [[t2]] \ok}{\rul{Prop\_Homogeneous}}
\]
Note how |~| is indexed by $[[g]]$, the proof that the kinds are equal.
I call this equality homogeneous, because even to form the equality |t1 ~ t2|,
we must know that the kinds are equal. Contrast to \rul{Prop\_Equality}, where
the proposition itself is well-formed even when the kinds and/or types are
not provably equal.

\subsection{Equality is hypothetical}

A key property of equality in \pico/ is that programs can \emph{assume} an
equality proof. This is how GADTs are implemented, by packing an equality
proof into a nugget of data and then extracting it again on pattern match.
In the body of the pattern match, we can assume the packed equality. Here
is the typing rule:
\[
\ottdruleCoXXVar{}
\]
Coercion variables are brought into scope by $\Pi$ and $\lambda$ over 
coercion binders.

\subsection{Equality is coherent}
\label{sec:coherence}
\label{sec:coercion-erasure-intro}

\Pico/'s equality relation is \emph{coherent}, in that the precise locations
and structure
of coercions within types is immaterial. This is a critical property,
because it is intended for a compiler to create and place these coercions.
Coherence is obtained through this coercion form:
\[
\ottdruleCoXXCoherence{}
\]
This coercion form requires two well-kinded types $[[t1]]$ and $[[t2]]$
as well as a coercion $[[h]]$ that relates their kinds. It also requires
the critical premise that $[[|t1| = |t2|]]$, where $\lfloor \cdot \rfloor$
is a \emph{coercion erasure} operation. This operation is separate
from (though
similar to) the type erasure operation spelled $[[||.||]]$ and discussed
several times thus far. The full definition of this operation is given
in \pref{defn:co-erasure}. More briefly, coercion erasure is defined
recursively on types, binders, case alternatives, and propositions
by the following equations, treating other forms homomorphically:
\begin{align*}
[[|t g| &= |t| o]] &
[[|t |> g| &= |t|]] \\
[[|absurd g t| &= absurd o |t|]] &
[[|(c:phi)| &= (o:|phi|)]]
\end{align*}
As we can see coercion erasure simply removes the coercions from a type.
We use $[[o]]$ to stand in for an erased coercion application. I sometimes
use the metavariable $[[ee]]$ to stand for a type that has its coercions
erased, but $[[t]]$ and $[[s]]$ may also refer to a coercion-erased
type, if that is clear from the context.

By using coercion erasure in its premise, the coherence coercion can
relate any two types that are the same, ignoring the coercions. This
is precisely what we mean by coherence.

The coherence rule implies that any two proofs of equality are considered
interchangeable---in other words, \pico/ assumes the uniqueness of identity
proofs (UIP)~\cite{hofmann-streicher}. This choice makes \pico/ ``anti-HoTT'',
that is, incompatible with homotopy type theory~\cite{hott}, which takes
as a key premise that there is more than one way to prove the identity
between two types. While baking UIP into the language may limit its applicability,
\pico/'s intended role as an intermediate language, where the coercions are
inferrred by the compiler, makes this choice necessary. We would not want
the static semantics of our programs to depend on the whims of how the
compiler placed its equality proofs.

Note that the coherence form in \pico/
is rather more general than the coherence form
used in my prior work~\cite{nokinds}. The way I have phrased coherence
is critical for my consistency proof. See \pref{sec:other-consistency-proofs}
for more discussion.

\subsection{Equality is an equivalence}

The equality relation |~| is explicitly an equivalence relation, via these
rules:
\begin{gather*}
\ottdruleCoXXRefl{}\rulesep
\ottdruleCoXXSym{}\rulesep
\ottdruleCoXXTrans{}
\end{gather*}
Note the use of $[[<t>]]$ to denote a reflexive coercion over the type
$[[t]]$.\footnote{Reflexivity is actually admissible, given the coherence
  coercion form (\pref{sec:coherence}); it is retained here as it is
  exceedingly common in programs and conceptually simple.}

\subsection{Equality is (almost) congruent}
\label{sec:congruence-coercions}

Given coercions between the component parts of two types, we often want to build
a coercion relating the types themselves. For example, if we know that
$[[S;G |-co g1 : t1 [PI a:Rel k1'.k1]~[PI a:Rel k2'.k2] s1]]$
and $[[S;G |-co g2 : t2 [k1']~[k2'] s2]]$, then we can build
$[[S;G |-co g1 g2 : t1 t2 [k1[t2/a] ]~[k2[s2/a] ] s1 s2]]$.
The form $[[g1 g2]]$ is typed by a congruence rule; each form of type
has an associated congruence rule. The rules that do not bind variables
appear in \pref{fig:simple-cong-rules}; I'll call these the simple congruence
rules. Rules that do bind variables are
subtler; they appear in \pref{fig:binding-cong-rules}.

\begin{figure}
\begin{gather*}
\ottdruleCoXXCon{}\rulesep
\ottdruleCoXXAppRel{}\rulesep
\ottdruleCoXXAppIrrel{}\rulesep
\ottdruleCoXXCApp{}\rulesep
\ottdruleCoXXCase{}\rulesep
\ottdruleCoXXFix{}\rulesep
\ottdruleCoXXAbsurd{}
\end{gather*}
\caption{Congruence rules that do not bind variables}
\label{fig:simple-cong-rules}
\end{figure}

\begin{figure}
\begin{gather*}
\ottdruleCoXXPiTy{}\rulesep
\ottdruleCoXXPiCo{}\rulesep
\ottdruleCoXXLam{}\rulesep
\ottdruleCoXXCLam{}
\end{gather*}
\caption{Congruence rules that bind variables}
\label{fig:binding-cong-rules}
\end{figure}

The simple congruence rules simply build up larger coercions from smaller ones.
With the exception of \rul{Co\_Absurd}, they assert that the types related
by the coercion are well-formed; it is easier simply to check the types than
to repeat all the conditions in the relevant typing rules. The typing premises
for \ottkw{absurd} are simple enough on their own, however.

The notation I use for congruence rules deliberately mimics that of types.
However, do not be fooled: the coercion $[[g1 g2]]$ does \emph{not} apply
a ``coercion function'' $[[g1]]$ to some argument. The coercion $[[g1 g2]]$
never $\beta$-reduces to become some $[[g[g2/c] ]]$. Similarly, the
$\lambda$-coercion (one of the binding congruence forms) does \emph{not}
define a $\lambda$-abstraction over coercions; it witnesses the equality
between two $\lambda$-abstraction types.

\subsubsection{Binding congruence forms}
\label{sec:binding-cong-forms}
\label{sec:lambda-coercion}
\label{sec:pico-co-pity}

The binding coercions forms (\pref{fig:binding-cong-rules}) all have a
particular challenge to meet. Suppose we know that
$[[S;G |-co h : k1 [Type{}]~[Type{}] k2]]$ and we wish to prove equality
between $[[PI a:rel k1. t1]]$ and $[[PI a:rel k2. t2]]$. We surely must
have a coercion $[[g]]$ relating $[[t1]]$ to $[[t2]]$. But in what context
should we check $[[g]]$? We
cannot assign $[[a]]$ both $[[k1]]$ and $[[k2]]$.

In \pico/, I have chosen to favor the left-hand kind in the context
and do a substitution in the result. Let's examine \rul{Co\_PiTy}
closely. The coercion $[[h]]$ indeed relates $[[k1]]$ and $[[k2]]$.
The coercion $[[g]]$ is checked in the context $[[G, a:Rel k1]]$---note 
the use of $[[k1]]$ there.\footnote{Regardless of the relevance annotation
$[[rel]]$ on the coercion, the context is extended with a binding marked
$[[Rel]]$, echoing the use of $[[Rel(d)]]$ in the premise to \rul{Ty\_Pi}
(\pref{sec:pico-type-abstractions}).}
Accordingly, the types related by $[[g]]$ ($[[s1]]$ and $[[s2]]$) might
mention $[[a]]$, assumed to be of type $[[k1]]$. For $[[s1]]$, that assumption
is correct; the left-hand type in the result is $[[PI a:rel k1.s1]]$.
However, for $[[s2]]$, this assumption is wrong: we wish $[[a]]$ to have
kind $[[k2]]$ in the right-hand result type. In order to fix up the mess,
the conlusion of \rul{Co\_PiTy} does an unusual substitution, mentioning the
type $[[ s2[a |> sym h/a] ]]$. This takes $[[s2]]$---well-typed in a context
where $[[a]]$ has kind $[[k1]]$---and changes it to expect $[[a]]$ to have
kind $[[k2]]$. It does this by casting $[[a]]$ by $[[sym h]]$, a coercion
from $[[k2]]$ to $[[k1]]$. We can thus use the (standard) substitution lemma
(\pref{lem:ty-subst}) to show that this result type is itself well-typed,
as needed to prove regularity (\pref{lem:prop-reg}). The other binding
congruence forms use similar substitutions in their conclusions, for
similar reasons.

This extra substitution in the conclusion is indeed asymmetric and
a bit unwieldy,\footnote{See the statement of the push rule \rul{S\_APush}
(\pref{sec:push-rules})
for an example of how its unwieldiness can bite.} but this treatment is,
on balance, better than the only known alternative. Other type systems
similar to \pico/~\cite{nokinds,gundry-thesis,van-doorn-explicit-convertibility-proofs}
use
an entirely different way of handling congruence coercions with binders:
instead of trying to treat $[[a]]$ as a variable with two different kinds,
they invent fresh variables. What I write as $[[PI a:rel h.g]]$, they would
write as $[[PI]]_{[[h]]} ([[a1]],[[a2]],[[c]]).[[g]]$, binding $[[a1]] : [[k1]]$
and $[[a2]] : [[k2]]$, as well as a coercion $[[c]] : [[a1 [k1]~[k2] a2]]$.
You can see either of those works for the details, but I have found this 
construction worse than the asymmetrical version. Other than the bookkeeping
overhead of extra variables, the three-variable version also requires
us to introduce a coercion variable even when making a congruence coercion
over a $\Pi$-type over a type variable. Coercion variables in the context
cause trouble (as discussed in \pref{sec:covar-restriction}), and my one-variable version helps to
contain the trouble.\footnote{See \pref{sec:one-var-no-covar}
for more discussion.}

As a further support to my choice of a one-variable binding form with an
asymmetrical rule, I have implemented both versions in GHC. Initially, I
implemented the three-variable form from \citet{nokinds}. This worked, but
it was often hard to construct the coercions, and it was sometimes a small
struggle to find names guaranteed to be fresh. When I refactored the code
to use the one-variable version formalized here, the code became simpler.

\subsubsection{Congruence over coercion binders}
\label{sec:almost-devoid}

The congruence forms over types that bind coercion variables 
(\rul{Co\_PiCo} and \rul{Co\_CLam}) have yet two
more wrinkles. The first is that there is no equivalent of
\rul{Co\_PiTy}'s $[[h]]$ coercion that relates two propositions; we must
settle for the pair of coercions $([[h1]],[[h2]])$ that appear in
\rul{Co\_PiCo} and \rul{Co\_CLam}. These coercions relate corresponding
parts of the propositions. 
The second wrinkle is in the $[[c ~# g]]$ premise of both of these rules.

\begin{definition*}[``Almost devoid'' (\pref{defn:almost-devoid})]
Define $[[c ~# g]]$ (pronounced ``$[[g]]$ is almost devoid of $[[c]]$'') to mean that the coercion variable $[[c]]$
appears nowhere in $[[g]]$ except, perhaps, in one of the types
related by a $[[t1 ~={h} t2]]$ coercion.
\end{definition*}

The almost-devoid condition on \rul{Co\_PiCo} and \rul{Co\_CLam} restricts
where the bound variable $[[c]]$ can appear in the coercion body. This
technical restriction, based on the original idea by \citet{nokinds},
is necessary for my proof of consistency
(\pref{sec:consistency}) to go through. The motivation for the restriction
is discussed in depth in
\pref{sec:covar-restriction}.

The key example that this restriction forbids looks like this:
\[
[[S]];[[G]] \not[[|-co]] [[PI c:(<&Int{}>,<&Bool{}>). c]] : [[(PI c:&Int{} [Type{}]~[Type{}] &Bool{}. &Int{}) [Type{}]~[Type{}] (PI c:&Int{} [Type{}]~[Type{}] &Bool{}. &Bool{}) ]]
\]
It would seem that this coercion would not cause harm, yet I know of no way
to prove consistency while allowing it. See \pref{sec:other-consistency-proofs}
for a discussion of other approaches.

Happily, this restriction is not likely to
bite when considering translating Dependent Haskell programs into \pico/,
as we can write functions witnessing the isomorphism between the two types
related above:
\[
\begin{array}{r@@{\,}c@@{\,}l}
[[&to]] &:& [[UPI (&&xx :Rel (UPI c:&Int{} [Type{}]~[Type{}] &Bool{}. &Int{})). (UPI c:&Int{} [Type{}]~[Type{}] &Bool{}. &Bool{})]] \\
[[&to]] &=& [[\ (&&xx :Rel (UPI c:&Int{} [Type{}]~[Type{}] &Bool{}. &Int{})), (c : &Int{} [Type{}]~[Type{}] &Bool{}). (&&xx c) |> c]] \\[1ex]
[[&from]] &:& [[UPI (&&xx :Rel (UPI c:&Int{} [Type{}]~[Type{}] &Bool{}. &Bool{})). (UPI c:&Int{} [Type{}]~[Type{}] &Bool{}. &Int{})]] \\
[[&from]] &=& [[\ (&&xx :Rel (UPI c:&Int{} [Type{}]~[Type{}] &Bool{}. &Bool{})), (c : &Int{} [Type{}]~[Type{}] &Bool{}). (&&xx c) |> sym c]]
\end{array}
\]
A compiler of Dependent Haskell creates functions such as these as
it is compiling a subsumption relationship $[[<=]]$, as discussed further
in \pref{sec:subsumption}. In other words, while we don't have
$[[(PI c:&Int{} [Type{}]~[Type{}] &Bool{}. &Int{}) [Type{}]~[Type{}] (PI c:&Int{} [Type{}]~[Type{}] &Bool{}. &Bool{})]]$, these two types are related by $[[<=]]$, in
both directions. This mean that
a Dependent Haskell program that expects one of these types
in a certain context, but gets the other type, is still well-typed.

When can the lack of the equality proof bite? Only when that proof is needed
as a coercion argument to some function or GADT constructor. As we've just
seen, using it to cast is unnecessary, as we can just use one component of
the isomorphism. The forbidden equalities all relate $\Pi$-types over
coercions. Yet, in Dependent Haskell, an abstraction over an equality
constraint is considered a polytype. Passing a polytype as an argument
is considered a use of impredicativity, which is not supported.
 (See \pref{sec:impredicativity}.) In particular, the equality constraint
|((Int ~ Bool) => Int) ~ ((Int ~ Bool) => Bool)| is malformed in Dependent
Haskell, because it passes polytypes as arguments to |~|. I thus conjecture
that no Dependent Haskell program is ruled out because of the coercion variable
restriction. Proving such a claim in all cases seems challenging, however,
and remains as an exercise for the reader.

\subsubsection{(Almost) Congruence}
\label{sec:congruence}

The coercion variable restriction means that equality is not quite congruent,
according to the following definition:

\begin{definition*}[Congruence]
Equality is congruent
if, whenever $[[S;G |-co g : s1 (k)~(k) s2]]$ and $[[S;G,a:rel k |-ty t : k0]]$,
then there exists $[[h]]$ such that $[[S;G |-co h : t[s1/a] (k0[s1/a])~(k0[s2/a]) t[s2/a] ]]$.
\end{definition*}

If we were to try to prove that equality is congruent,
it seems natural to proceed by induction
on the typing derivation for $[[t]]$. However, in the proof, we are stuck when
$[[t = PI c:phi.t0]]$. The congruence form for $\Pi$-types over coercions is
no help because of the coercion variable restriction. If we strengthen the
induction hypothesis to provide what we need in this case, then other cases
fail, unable to obey the restriction.

As a concrete example, consider this:
Let $[[G = &&yx :Rel &Int{}, c : #3{} [&Int{}]~[&Int{}] &&yx]]$ and
$[[t = \ (c' : &Int{} [Type{}]~[Type{}] &Bool{}). &&xx |> c']]$.
We know $[[S;G |-co c : #3{} [&Int{}]~[&Int{}] &&yx]]$ and
$[[S;G,&&xx:Rel &Int{} |-ty t : UPI (c' : &Int{} [Type{}]~[Type{}] &Bool{}). &Bool{}]]$.
Yet there seems to be no way to construct a proof of
$[[t[#3{}/&&xx] [UPI (c' : &Int{} [Type{}]~[Type{}] &Bool{}). &Bool{}]~[UPI (c' : &Int{} [Type{}]~[Type{}] &Bool{}). &Bool{}] t[&&yx/&&xx] ]]$.

Instead of proving congruence, I am left proving almost-congruence, as follows:

\begin{definition*}[Unrestricted coercion variables (\pref{defn:co-star})]
Define a new judgment $[[|-co*]]$ to be identical to $[[|-co]]$, except with
the $[[c ~# g]]$ premises removed from rules \rul{Co\_PiCo} and
\rul{Co\_CLam} and all recursive uses of $[[|-co]]$ replaced with $[[|-co*]]$.
\end{definition*}

Now, the proof for the following theorem is straightforward:
\begin{theorem*}[(Almost) Congruence (\pref{thm:almost-congruence})]
Equality is congruent, when checked with $[[|-co*]]$.
\end{theorem*}

What this means, in practice, is that we can often think of equality as
congruent, and intuition about the equality relation stemming from
congruence is often accurate. In particular, if the type $[[t]]$ in the
statement of congruence has no coercion abstractions or $\Pi$-types, then
congruence with repsect to $[[|-co]]$ holds.\footnote{This intuition is
hard to state precisely, because of the possibility that the contexts have
abstractions over coercions. We would somehow need a premise that states
that no coercion abstractions are ``reachable'' from $[[t]]$, but defining
such a property and then proving this claim seems not to pay its way.}

\subsection{Equality can be decomposed}

\Pico/ comes equipped with a large variety of ways of decomposing an equality
to get out a smaller one---in some sense, these are the inverses of the
congruence forms. We will approach these in batches.

\subsubsection{The \ottkw{argk} forms}
\label{sec:pico-argk-coercion}

\begin{figure}
\begin{gather*}
\ottdruleCoXXArgK{}\rulesep
\ottdruleCoXXCArgKOne{}\rulesep
\ottdruleCoXXCArgKTwo{}\rulesep
\ottdruleCoXXArgKLam{}\rulesep
\ottdruleCoXXCArgKLamOne{}\rulesep
\ottdruleCoXXCArgKLamTwo{}
\end{gather*}
\caption{The \ottkw{argk} rules of coercion formation}
\label{fig:argk-rules}
\end{figure}

The coercion form \ottkw{argk} extracts a coercion between
the kinds of the bound variables in a coercion relating abstractions.
The rules appear in \pref{fig:argk-rules}. The rules are actually
straightforward; look at \rul{Co\_ArgK} for a typical example.
This form extracts the equality between $[[k1]]$ and $[[k2]]$ from
the type of $[[g]]$. The other forms work analogously. The forms
with $\ottkw{argk}_i$ are necessary because \pico/ has no built-in
notion of an equality between equalities: If we tried to extract
a relation between propositions like we do in \rul{Co\_ArgK}, we
would need something that looks like $[[phi1]] [[~]] [[phi2]]$,
which does not exist in \pico/. So, we have to extract either the
left side of the propositions or the right side.

Note that these rules are still syntax-directed even though their
conclusions overlap: we can always find the proposition a coercion
proves and then decide which \ottkw{argk} rule to use.

\subsubsection{The instantiation forms}
\label{sec:co-inst}

Given a coercion between abstractions, we can instantiate the bound
variable and get a coercion between the instantiated bodies. The
rules for these coercions are in \pref{fig:inst-rules}.

\begin{figure}
\newcommand{\instrulesep}{\\[2ex]}
\begin{gather*}
\ottdruleCoXXInstRel{}\instrulesep
\ottdruleCoXXInstIrrel{}\instrulesep
\ottdruleCoXXCInst{}\instrulesep
\ottdruleCoXXInstLamRel{}\instrulesep
\ottdruleCoXXInstLamIrrel{}\instrulesep
\ottdruleCoXXCInstLam{}\instrulesep
\ottdruleCoXXRes{}\instrulesep
\ottdruleCoXXResLam{}
\end{gather*}
\caption{Instantiation rules of coercion formation}
\label{fig:inst-rules}
\end{figure}

These rules are essentially concrete instances of two rule schemas,
one for instantiation coercions built with $[[@]]$, and the other
for ``result'' coercions built with \ottkw{res}. The instantiation
coercions can work with one of three arguments types (relevant type,
irrelevant type, and coercion) and one of two forms ($\Pi$ and $\lambda$),
leading to six very similar rules. Along the same lines, \ottkw{res}
coercions work with both $\Pi$ and $\lambda$, though this form is
agnostic to the argument flavor, so we get only two rules.

The instantiation coercions are essential in writing the push rules
(\pref{sec:push-rules}) of the operational semantics.\footnote{It is
necessary for the system to allow instantiation on $\Pi$-types;
$\lambda$-types, on the other hand, are not strictly necessary to
instantiate in order to prove type safety. However, doing so is easy,
and so I took the opportunity to make the equality relation stronger.}

The \ottkw{res} coercions are a form of degenerate instantiation, usable
when the body of an abstraction (either $\Pi$ or $\lambda$) does not
mention the bound variable(s). Note that both \ottkw{res} rules require
that the body types ($[[t1]]$ and $[[t2]]$) are well-typed without any
of the bound variables in $[[D1]]$ or $[[D2]]$. These coercions also
allow for the possibility of looking through multiple binders. This ability
cannot be emulated by repeated use of \ottkw{res} because of the possibility
of an intermediate dependency. For example, consider the reflexive coercion
$[[g = <PI (a :Irrel Type{}), (b :Rel a). Type{}>]]$. We can see that
$[[res^2 g]]$ is well-typed, even though $[[res^1 g]]$ is not (because of
the appearance of $[[a]]$ in the type of $[[b]]$).

We must use \ottkw{res} instead of instantiation when we don't have a
coercion to use for the instantiation. This situation happens in the
\rul{S\_KPush} rule, where we need a coercion relating the bodies
of two propositionally equal $\Pi$-types, but we have no coercions to
hand to use in instantiation. See \pref{sec:pico-kpush} for more details.

\subsubsection{Type constants are injective}

In \pico/, all type constants are considered injective, as witnessed
by the \ottkw{nth} coercions, which extract an equality between arguments
of a type constant:
\begin{gather*}
\ottdruleCoXXNthRel{}\rulesep
\ottdruleCoXXNthIrrel{}
\end{gather*}
Both forms above require that we extract a coercion between \emph{type}
arguments,
never \emph{coercion} arguments. As discussed in \pref{sec:coherence},
we never need an explicit proof of equality between coercions. The last
line of premises in the rules are simply to produce the kinds to put
in the result proposition, where the kinds are elided in the typesetting.

Injectivity of type constants is sometimes
controversial~\cite{weirich-paradoxical-typecase} and is known to be
anti-classical~\cite{hur-injective-anti-classical}. However, in a type
system with $[[Type{}]] : [[Type{}]]$, yet another way to prove
absurdity does not weaken any property of the language. Injectivity
is vital in the \rul{S\_KPush} rule and thus remains part of the
language.

\subsection{Equality includes $\beta$-reduction}

The last rule to consider in the $[[|-co]]$ judgment is the one that
witnesses $\beta$-reduction:

\[
\ottdruleCoXXStep{}
\]

This rule is in place of having $\beta$-equivalence be part of definitional
equality, as is done in some other dependently typed languages, such as Coq.
Instead, in order to get a type to reduce, a \pico/ program must invoke the
\ottkw{step} coercion explicitly. Generating these coercions is quite painful
to do by hand (as seen in the example in \pref{sec:example-with-stepn}),
but straightforward for a compiler.\footnote{If a type must reduce many
times, it would be more efficient to support a $\ottkw{step}^n$ coercion
form that performs $n$ steps at once. Indeed, this is what I plan to implement.
It is easier, however, to prove properties about single-step reduction.}

You will see that the rule requires both the redex and the reduct to be
well-kinded at kind $[[k]]$. The requirement on the reduct is implied by
the preservation theorem (\pref{thm:preservation}), but omitting it from
the rule means that the proofs of proposition regularity (\pref{lem:prop-reg})
and preservation would have to be mutually inductive. It seems simpler
just to add this extra, redundant premise.

\subsection{Discussion}

The coercion language in \pico/ is quite extensive, boasting (or suffering
from, depending on your viewpoint) 34 separate typing rules. \rae{Has that
number changed since Jun 16?} I consider here, briefly, why this is so.

There are several coercion forms that are absolutely essential for \pico/ to
be proven typesafe and yet remain meaningful. These include the equivalence
and coherence rules, assumptions, the $\Pi$-congruence form over type
variables,\footnote{This form is needed only to support reduction under
  irrelevant $\lambda$s.} \ottkw{argk} over $\Pi$, instantiation over $\Pi$,
injectivity, and $\beta$-reduction. With the exception of assumptions
(\rul{Co\_Var}) and $\beta$-reduction (\rul{Co\_Step}), these forms are all
needed somewhere in the push rules (\pref{sec:push-rules}).\footnote{I am
  considering here a version of \pico/ without unsaturated matches. If we wish
  to include unsaturated matches, we would also need \ottkw{res} over $\Pi$.}
Assumptions and $\beta$-reduction, however, make \pico/ what it is; the
language would be near-useless as a candidate for an internal
dependently-typed language without these.

The rest of the forms merely enrich the equality relation, while remaining
inessential. I have decided to include them to make the equality relation
relate more types. Doing so makes \pico/---and, in turn, Dependent Haskell---more
expressive. When adding rules, we must be careful that the new forms do
not violate consistency (or other proved properties), so they are not entirely
free. Perhaps there are more useful, safe rules one could add later, simply
by updating the relevant proofs. Because \pico/ never inspects the structure
of a coercion, adding new rules introduces only a minimal burden on any
implementation---essentially just for bookkeeping. I thus leave open the
possibility of more coercions as \pico/ gets used in practice.

\section{The \rul{S\_KPush} rule}
\label{sec:pico-kpush}

The \rul{S\_KPush} rule handles the case where the scrutinee of a \ottkw{case}
expression is headed by a cast. As in all previous work on System FC, this
push rule is the most intricate. However, in this dissertation, I have taken
a new approach to \rul{S\_KPush} that does not require the so-called ``lifting
lemma'' of previous work.\footnote{See for example, \citet{nokinds}, which
contains a good, detailed explication of the lifting lemma.} This
lifting lemma is a generalization of the congruence property, which
does not hold in \pico/ (\pref{sec:congruence}). Instead,
I rely on instantiating the type of a type constant, and on the fact that
type constant types are always closed. As the computational content of the
\rul{S\_KPush} rule must actually be implemented as part of a compiler that
uses \pico/, this (slightly) simpler statement of \rul{S\_KPush}
may prove to be a
measurable optimization
in practice.

A few examples can demonstrate the general idea. First off, note that in
\rul{S\_KPush}, only the scrutinee matters; the alternatives remain
the same before and after the reduction. With that in mind, we can see
scrutinees before and after pushing in \pref{tab:kpush-examples}.

\begin{table}
\newcommand{\pushrow}[1]{\multicolumn{3}{l}{#1}}
\begin{center}
\rowcolors{1}{white}{gray!25}
\setlength{\arrayrulewidth}{.1em}
\begin{tabular}{llc}
Original scrutinee & Assumptions / Notes \\
\pushrow{Pushed scrutinee} \\ \hline
$[[&True{} |> <&Bool{}>]]$ & simple case; no universals & (1)\\
\pushrow{$[[&True{}]]$} \\[2ex]
$[[&&Justx{&Int{}} #3{} |> g]]$ &
$\begin{array}[t]{@@{}l@@{}}
[[S;G |-co g : &Maybe{} &Int{} [Type{}]~[Type{}] &Maybe{} &&bx]] \\
[[&&bx :Irrel Type{} \in G]]
\end{array}$ & (2)\\
\pushrow{$
[[&&Justx{&&bx} (#3{} |> argk (<MPI &&ax :Irrel Type{}, &&xx :Rel &&ax. &Maybe{} &&ax>@(nth 1 g)))]]$} \\[2ex]
%
$[[&MkG{&Bool{}} <&Bool{}> |> g]]$ &
$\begin{array}[t]{@@{}l@@{}}
[[S;G |-co g : &&Gx{} &Bool{} [Type{}]~[Type{}] &&Gx{} &&bx]] \\
[[&&bx :Irrel Type{} \in G]]
\end{array}$  & (3) \\
\pushrow{
$\begin{array}[t]{@@{}l@@{}}
[[&MkG{&&bx} (sym (argk 1 h) ;; <&Bool{}> ;; argk 2 h)]] \text{, where} \\
\quad [[h = <MPI (&&ax :Irrel Type{}), (c : &&ax [Type{}]~[Type{}] &Bool{}). &&Gx{} &&ax>@(nth 1 g)]] \\[2ex]
\end{array}$} \\[2ex]
%
$[[(&Pack{&Bool{}} &True{} &MkP{&Bool{},&True{}}) |> g]]$ &
$\begin{array}[t]{@@{}l@@{}}
[[S;G |-co g : MPI d1. &Ex{} &Bool{} [Type{}]~[Type{}] MPI d2. &Ex{} &&bx]] \\
[[d1 = &&yx :Rel &Proxy{} &Bool{} &True{}]]\\
[[d2 = &&yx :Rel &Proxy{} &&bx (&True{} |> g2)]]\\
[[S;G |-co g2 : &Bool{} [Type{}]~[Type{}] &&bx]] \\
[[&&bx :Irrel Type{} \in G]]
\end{array}$ & (4) \\
\pushrow{
$\begin{array}[t]{@@{}l@@{}}
[[&Pack{&&bx} {&True{} |> h0'} (&MkP{&Bool{},&True{}} |> h1')]] \text{, where} \\
\quad [[k = MPI (&&kx :Irrel Type{}), (&&ax :Irrel &&kx), (&&xx :Rel &Proxy{} &&kx &&ax), (&&yx :Rel &Proxy{} &&kx &&ax). &Ex{} &&kx]] \\
\quad [[h0 = <k>@(nth 1 (res^1 g))]] \\
\quad [[h0' = argk h0]] \\
\quad [[h1 = h0@(&True{} ~={h0'} &True{} |> h0')]] \\
\quad [[h1' = argk h1]] \\
\end{array}$} \\
%
\end{tabular}
\end{center}

The reductions above assume the following datatypes:
%{
%if style == newcode
%format Ex = "Ex2"
%format Bool = "Bool2"
%format True = "True2"
%format False = "False2"
%format Maybe = "Maybe2"
%format Just = "Just2"
%format Nothing = "Nothing2"
%endif
\begin{code}
data Bool = False | True
data Maybe a = Just a | Nothing
data G a where
  MkG :: G Bool
data Proxy (a :: k) = MkP
data Ex k where
  Pack :: forall (a :: k). Proxy a -> Proxy a -> Ex k
\end{code}
%}
And in \pico/:
\[
\begin{array}{r@@{\,}l}
[[S]] = &
[[&Bool : (empty), &False : (empty; &Bool), &True : (empty; &Bool)]] \\
& [[&Maybe : (&&ax : Type{}), &&Justx : (&&xx :Rel &&ax; &Maybe), &&Nothingx : (empty; &Maybe)]] \\
& [[&&Gx : (&&ax : Type{}), &MkG : (c : &&ax [Type{}]~[Type{}] &Bool{}; &&Gx)]] \\
& [[&Proxy : (&&kx : Type{}, &&ax : &&kx), &MkP : (empty; &Proxy)]] \\
& [[&Ex : (&&kx : Type{}), &Pack : (&&ax :Irrel &&kx, &&xx :Rel &Proxy{} &&kx &&ax, &&yx :Rel &Proxy{} &&kx &&ax; &Ex)]]
\end{array}
\]
\caption{Examples of \rul{S\_KPush}}
\label{tab:kpush-examples}
\end{table}

\paragraph{Example (1)}
In this example, there are no universals of the type in question (|Bool|), and
so ``pushing'' is extraordinarily simple: just drop the coercion. We can see
this in terms of \rul{S\_KPush} in that both $[[ts]]$ and $[[ps]]$ are empty.
Note that if we had a non-reflexive coercion in the scrutinee---that is, if
the scrutinee were, say, $[[&True{} |> g]]$ with $[[S;G |-co g : &Bool{} [Type{}]~[Type{}] &&ax]]$---the \ottkw{case} expression would not be well-typed.
Rule \rul{Ty\_Case} requires the type of a scrutinee to be of the form
$[[MPI D.H{} ss]]$. The type |a| does not have this form, and so such a
scrutinee is disallowed.
Also note that we cannot have $[[&True{} |> g]]$ with $[[S;G |-co g : &Bool{} [Type{}]~[Type{}] &Int{}]]$ due to the consistency lemma (\pref{sec:consistency}).

\paragraph{Example (2)}
This is the simplest non-trivial example. We need to push a coercion
$[[g]]$ proving |Maybe Int ~ Maybe b| into $[[&&Justx{&Int{}} #3{}]]$.
This casted scrutinee has type |Maybe b|; the pushed scrutinee must have the
same type. We thus know it must start with $[[&&Justx{&&bx}]]$.
The only challenge left is to cast the argument, |3|, with a coercion
that proves |Int ~ b|. We will always be able to extract this coercion
from the coercion casting the scrutinee, $[[g]]$. But how, in general?

\begin{figure}
{
\setlength{\belowdisplayskip}{-20pt}
\setlength{\belowdisplayshortskip}{-20pt}
\ottfundefnbuildXXkpushXXco{}\\[1ex]
\setlength{\abovedisplayskip}{-20pt}
\setlength{\abovedisplayshortskip}{-20pt}
\setlength{\belowdisplayskip}{-30pt}
\setlength{\belowdisplayshortskip}{-30pt}
\ottfundefncastXXkpushXXarg{}
}
\caption{Helper functions implementing \rul{S\_KPush}}
\label{fig:kpush-func}
\end{figure}

The coercion needed to cast each (existential) argument to a constructor
must surely depend on the type of the constructor. Previous versions of
System FC did a transformation on this type to produce the coercion. 
In this work, I instantiate the type using the $[[@]]$ operator 
(\pref{sec:co-inst}) via
the helper metatheory functions $[[build_kpush_co]]$ and $[[cast_kpush_arg]]$,
presented in \pref{fig:kpush-func}.

In our case---pushing a coercion into |Just|---we take |Just|'s type
($[[MPI &&ax :Irrel Type{}, &&xx :Rel &&ax. &Maybe{} &&ax]]$) and instantiate
|a| by the coercion $[[nth 1 g]]$, which proves |Int ~ b|.
We are thus left with a coercion that proves
\[
[[(MPI &&xx :Rel &Int{}. &Maybe{} &Int{}) [Type{}]~[Type{}] (MPI &&xx :Rel &&bx. &Maybe{} &&bx)]].
\]
Then, all we have to do is use \ottkw{argk} to extract the coercion proving
|Int ~ b| and we can use it to cast |3|.

Seeing the above action in the definition for \rul{S\_KPush} may be
challenging. Let's take another look, focusing on the metavariables
in the definition of the rule (presented in \pref{fig:push-rules}).
The type $[[s]]$ is the type of the underlying (uncasted) scrutinee, and
$[[s']]$ is the type of the casted scrutinee. In our example, we have
$[[s = &Maybe{} &Int{}]]$ and $[[s' = &Maybe{} &&bx]]$. Note that neither
of these are $[[MPI]]$-types, and thus the telescope $[[D2]]$ from the rule
is empty, with $n = 0$. The $[[k]]$ metavariable in the rule is the type
of |Just|, above. The coercion we are building is the one to cast the first
argument, that is, $[[g1]]$. The second argument to $[[build_kpush_co]]$ is
a list of all previous existential arguments, but in our case, there are no
previous arguments, so this list is empty. We thus have
$[[g1 = build_kpush_co(<k>@(nth 1 g); empty)]]$.\footnote{Technically,
we should write $[[res^0 g]]$, because the superscript in \ottkw{res} coercions
is part of the language, not the metatheory. However, a $\ottkw{res}^0$ coercion
is a no-op, so I leave it out here for simplicity.} We can see from the
definition of $[[build_kpush_co]]$ that the function just returns its first
argument when its second argument is empty, and so we get
$[[g1 = <k>@(nth 1 g)]]$ as desired.
The use of $[[cast_kpush_arg]]$ is to apply the right \ottkw{argk} form
(\pref{sec:pico-argk-coercion}),
depending on whether we are casting a type or ``casting'' a coercion.

We focus on understanding $[[cast_kpush_arg]]$ on the next example.

\paragraph{Example (3)}

\begin{figure}
\[
\begin{CD}
[[&&bx]] @@>{[[sym (argk 1 h)]]}>> [[&Bool{}]] \\
@@. @@VV{[[<&Bool{}>]]}V \\
[[&Bool{}]] @@<{\phantom{[[sym (argk 1 h)]]}}<{[[argk 2 h]]}< [[&Bool{}]]
\end{CD}
\]
\caption{``Casting'' a coercion in Example (3)}
\label{fig:kpush-cast-co}
\end{figure}

The datatype |G| is a simple-as-they-come GADT. In this example, we cast
|MkG :: G Bool| to have type |G b| (for some type variable |b|).
The action in \rul{S\_KPush} here is actually quite similar to the previous
case, because |MkG| is quite similar to |Just|: both take one argument,
whose type depends on the one universal parameter. The difference here is
that |MkG|'s argument is a coercion, whereas |Just|'s is a type. We thus
cannot use \ottkw{argk} in exactly the same way as before, instead requiring
$\ottkw{argk}_1$ and $\ottkw{argk}_2$, as diagrammed in \pref{fig:kpush-cast-co}.
In this example, two of the steps in the diagram are redundant, but they will
not be, in general. It can be convenient to think of constructions such
as this as ``casting'' a coercion---that is, taking the coercion $[[<&Bool{}>]]$
and changing it to connect |b| with |Bool|. Indeed, prior work~\cite{nokinds}
even used a special notation for this: $[[g]] [[|>]] [[h1]] \sim [[h2]]$,
but I find it clearer to avoid the sugar.

\paragraph{Example (4)}

Having warmed ourselves up on the simpler examples above, Example (4) demonstrates
the full complexity of \rul{S\_KPush}, including dependent existential
arguments and an unsaturated scrutinee. We'll take these complications one
at a time.

Having dependent existential arguments is what motivates the intricacies
of $[[build_kpush_co]]$. Since the pushed-in cast changes universal arguments
(unless it's reflexive), we need to cast existential arguments that may be
dependent on the universals. However, if a later existential argument is
dependent upon an earlier one and we change the earlier one, we must also
change that later one. In this example, the first existential argument
(instantiated to |True|) depends on the universal argument (instantiated to
|Bool|), and the second existential depends on the first. The first existential
is cast by $[[h0']]$ and thus the second must be cast by $[[h1']]$, which
essentially replaces the occurrence of |True| in the type of the applied
|MkP| constructor with $[[&True{} |> h0']]$, using a coherence coercion
built with $[[~=]]$. Indeed, this is the whole point of $[[build_kpush_co]]$---using
coherence to alter the types of later exisentials depending on earlier ones.
Here is the critical correctness property of $[[build_kpush_co]]$:

\begin{lemma*}[Correctness of $[[build_kpush_co]]$ (\pref{lem:build-kpush-co})]
Assume $[[S;G |-cev ps : D[ts/as] ]]$, and let $[[gi = build_kpush_co(h; ps_{1..i-1})]]$
and $[[pi' = cast_kpush_arg(pi;gi)]]$.
If $[[S;Rel(G) |-co h : (MPI D.s)[ts/as] [Type{}]~[Type{}] (MPI D.s)[ts'/as] ]]$, then:
\begin{enumerate}
\item
$[[S;Rel(G) |-co build_kpush_co(h; ps) : s[ts/as][ps/dom(D)] [Type{}]~[Type{}] s[ts'/as][ps'/dom(D)] ]]$
\item $[[S;G |-cev ps' : D[ts'/as] ]]$
\end{enumerate}
\end{lemma*}

This lemma is phrased in terms of $[[|-cev]]$; that relation includes the
same elements as $[[|-vec]]$ but allows induction from right-to-left instead
of the usual left-to-right. The $[[h]]$ in the lemma statement relates the
type of a constructor to itself, but with the universals instantiated with
potentially different concrete arguments. These instantiations come directly
from the coercion being pushed into the scrutinee, by way of \ottkw{nth}.
(Note that the $[[MPI]]$ quantifiers in the type of $[[h]]$ above are not
a consequence of the possibility of unsaturation; instead, these are the
existentials of the data constructor.) The lemma concludes that the resulting
coercion relates the instantiated coercion (that is, the one built by
$[[build_kpush_co]]$) to itself, with substitutions for both the universals
and some existentials. Along the way, it also asserts the validity of the
cast existentials, via the $[[|-cev]]$ result.

The remaining detail of Example (4) is its unsaturation. This is handled more
simply by a \ottkw{res} coercion (\pref{sec:co-inst}), which looks through
binders to relate the bodies of two abstract types. Indeed, \rul{S\_KPush} is
the reason that the \ottkw{res} coercion exists at all, though it is not
a burden to support in the metatheory.

\section{Metatheory: Consistency}
\label{sec:metatheory-one}
\label{sec:consistency}

Broadly speaking, the type safety proof proceeds along lines well established
by prior work~\cite{nokinds-extended,closed-type-families-extended,safe-coercions-jfp}.
Indeed, the only challenge in proving the preservation theorem is in dealing
with \rul{S\_KPush}. the tricky bit is all in proving the correctness of
$[[build_kpush_co]]$; see \pref{sec:pico-kpush}. Otherwise, the proof of preservation
is as expected.

On the other hand, progress is a challenge. We proceed by proving consistency
and then using that to prove progress.

\begin{lemma*}[Consistency (\pref{lem:consistency})]
If $[[G]]$ contains only irrelevant type variable bindings and
$[[S;G |-co g : t1 [k1]~[k2] t2]]$
then $[[t1 ! t2]]$.
\end{lemma*}

We restrict $[[G]]$ not to have any coercion variables bound. Otherwise,
a coercion assumption might relate, say, |Int| and |Bool| and we would
be unable to prove consistency. As consistency is needed only during
the progress proof, this restriction does not pose a problem.

\subsection{Compatibility}

\begin{figure}
\ottdefnCons{}
\caption{Type compatibility}
\label{fig:compatibility}
\end{figure}

The statement of consistency depends on the $[[t1 ! t2]]$ relation
(pronounced ``$[[t1]]$ is compatible with $[[t2]]$''), as given in
\pref{fig:compatibility}. The goal of compatibility is to relate any
two values (as defined in \pref{sec:value-defn})
that have the same head; non-values are compatible with everything.
Note, in particular, in \rul{C\_TyCon}, that we care only that the two
$[[H]]$ are the same. The universals ($[[ts]]$/$[[ts']]$) and existentials
($[[ps]]$/$[[ps']]$) are allowed to differ. The one exception to this general
scheme is in the \rul{C\_PiTy} rule, where we require the bodies $[[t]]$/$[[t']]$
also to be compatible. This is necessary because irrelevant binders are erased,
and we thus must be sure that any exposed types are also compatible.

Consistency is used in the progress proof mainly in order to establish the
typing premises of the push rules (\pref{sec:push-rules}). A representative
example is in the case when we are trying to show that an application $[[t1 t2]]$
is either a value or can step (it is clearly not a coerced value; recall
the statement of the progress theorem from \pref{sec:progress-thm-statement}).
The induction hypothesis tells us that $[[t1]]$
is a value, a coerced value, or can step. If it can step, we are done by
\rul{S\_App\_Cong}. If $[[t1]]$ is a value, we can determine that it is a
$\lambda$-abstraction and thus we can do $\beta$-reduction. The remaining
case is when $[[t1]]$ is a coerced value $[[v |> g]]$. We need to be able
to show that $[[g]]$ relates two $\Pi$-types in order to use \rul{S\_PushRel}.
The right-hand type must be
a $\Pi$-type because it is the function in an application. But the only way
we can show that the left-hand type is a $\Pi$-type is by appealing to
consistency.

We know, at this point, that the type being casted is a value; thus its
type is also a value (\pref{lem:val-type}, also introduced in
\pref{sec:value-defn}). At this point, now that we know that both types
involved in the type of the coercion $[[g]]$ are not values, compatibility
becomes a much stronger definition, allowing us to conclude that if the
types are compatible and if one is a $\Pi$-type, the other must surely also
be a $\Pi$-type. Because we can rule out non-values in the places where we
wish to invoke the consistency lemma, the flexibility around non-values
does not get in our way.

\subsection{The parallel rewrite relation}

To prove consistency, I (following prior work) define a parallel rewrite
relation, written $[[t1 ~> t2]]$, and show that this relation includes pairs
of only compatible types. A small wrinkle with this definition is that the
rewrite relation works over only types whose coercions have been erased, as
per the $\lfloor \cdot \rfloor$ operation, initially introduced along with
coherence coercions in
\pref{sec:coercion-erasure-intro}. The operation, as you may recall, removes
all casts from a type, and replaces coercion arguments with an uninformative
$[[o]]$. Stripping out casts and coercions is important in the rewrite relation;
if the rewrite relation considered these features, the language would lose
its coherence property. Going forward, I use a convention where all types
written as being related by $[[~>]]$ have had their coercions erased.

\begin{figure}
\begin{ottdefnblock}{$[[t ~> t']]$}{Type parallel reduction, over erased types}
\begin{gather*}
\begin{array}{@@{}c@@{}}
\ottdruleRXXRefl{}\\[3ex]
\ottdruleRXXCon{}\\[3ex]
\ottdruleRXXAppRel{}\\[3ex]
\ottdruleRXXAppIrrel{}\\[3ex]
\ottdruleRXXCApp{}\\[3ex]
\end{array}
\quad
\begin{array}{@@{}c@@{}}
\ottdruleRXXPi{}\\[3ex]
\ottdruleRXXLam{}\\[3ex]
\ottdruleRXXFix{}\\[3ex]
\ottdruleRXXAbsurd{}\\[3ex]
\end{array}\\
\ottdruleRXXCase{}\rulesep
\ottdruleRXXBetaRel{}\rulesep
\ottdruleRXXBetaIrrel{}\rulesep
\ottdruleRXXCBeta{}\rulesep
\ottdruleRXXMatch{}\rulesep
\ottdruleRXXDefault{}\rulesep
\ottdruleRXXUnroll{}
\end{gather*}
\end{ottdefnblock}
\caption{Parallel reduction over erased types}
\label{fig:rewrite-rel-ty}
\end{figure}

\begin{figure}
\ottdefnRedBnd{}\\
\ottdefnRedCo{}
\caption{Parallel reduction auxiliary relations}
\label{fig:rewrite-rel-aux}
\end{figure}

The rewrite relation $[[~>]]$ appears in \pref{fig:rewrite-rel-ty}
and \pref{fig:rewrite-rel-aux}. Following
conventions in the rewriting literature, I write $[[t1 ~> t3 <~ t2]]$ to
mean that $[[t1 ~> t3]]$ and $[[t2 ~> t3]]$, and I write $[[t1 ~>* t2]]$ to
mean the transitive closure of $[[~>]]$.

\subsubsection{Substitution}

The relation is almost a non-deterministic, strong version of normal reduction ($[[S;G |-s t --> t']]$). In all the congruence forms (toward the top of
\pref{fig:rewrite-rel-ty}), the relation definition recurs in every component,
as necessary to support the following lemma:

\begin{lemma*}[Parallel reduction substitution in parallel (\pref{lem:red-subst-par})]
Assume $[[ps ~> ps']]$.
\begin{enumerate}
\item If $[[t1 ~> t2]]$, then $[[t1[ps/zs] ~> t2[ps'/zs] ]]$.
\item If $[[d1 ~> d2]]$, then $[[d1[ps/zs] ~> d2[ps'/zs] ]]$.
\end{enumerate} 
\end{lemma*}

Note that all of the reductions are single-step.

Beyond the congruence rules, the rewrite relation includes parallel variants
of the reduction rules from the normal step relation, toward the bottom
of the figure. Note that these allow the components of a type to step as
the reduction happens, as required for the local diamond lemma needed to
prove confluence.

\subsubsection{Confluence}

This reduction relation is confluent (that is, has the Church-Rosser property).
I prove this by proving a local diamond lemma:

\begin{lemma*}[Local diamond (\pref{lem:local-diamond})] ~
\begin{enumerate}
\item
If $[[t0 ~> t1]]$ and $[[t0 ~> t2]]$, then there exists $[[t3]]$ such
that $[[t1 ~> t3 <~ t2]]$.
\item
If $[[d0 ~> d1]]$ and $[[d0 ~> d2]]$, then there exists $[[d3]]$
such that $[[d1 ~> d3 <~ d2]]$.
\end{enumerate}
\end{lemma*}

The proof of this lemma reasons by induction on the structure of
$[[t0]]$/$[[d0]]$ and makes heavy use of the substitution lemma above. It is
not otherwise challenging. The local diamond lemma implies confluence.

\subsection{Completeness of the rewrite relation}
\label{sec:covar-restriction}

Having written a confluent rewrite relation, we must also connect this relation
to our equality relation. This is done via the following lemma:

\begin{lemma*}[Completeness of type reduction (\pref{lem:complete-red})] ~
If $[[S;G |-co g : t1 (k1)~(k2) t2]]$ and $[[c ~# g]]$ for every $[[c:phi \in G]]$,
then:
\begin{enumerate}
\item There exists some
erased type $[[ee]]$
such that $[[|t1| ~>* ee *<~ |t2|]]$.
\item There exists some erased type $[[ee]]$
such that
$[[|k1| ~>* ee *<~ |k2|]]$.
\end{enumerate}
\end{lemma*}

Both the statement and proof of this lemma are rather more challenging than
the previous ones. The proof proceeds by induction on the typing derivation.
It is necessary in the proof to use the induction hypothesis
on a premise where the context $[[G]]$ is extended with a coercion variable
(say, in the case for \rul{Co\_PiCo}). Thus, even though we will only use this
lemma in a context with no coercion variables, we must strengthen the induction
hypothesis to allow for coercion variables. Critically, though, we restrict
how all coercion variables in the context can appear in $[[g]]$, according to
the definition of $[[~#]]$, introduced in \pref{sec:almost-devoid}. This
restriction allows us to skip the impossible \rul{Co\_Var} case while still
allowing induction in the \rul{Co\_PiCo} case.

The definition of $[[c ~# g]]$ allows $[[c]]$ to appear in the types related
by a coherence $[[~=]]$ coercion. Happily in the \rul{Co\_Coherence} case
(when proving clause 1 of the lemma), we do not need to use the induction
hypothesis, as a premise of \rul{Co\_Coherence} states that the erased types
are, in fact, already equal. It is for precisely this reason that $[[c ~# g]]$
can allow $[[c]]$ in the types in a coherence coercion.

We also see that the statement of the completeness lemma requires us to prove
both that the types are joinable under $[[~>]]$ and also the kinds. Otherwise,
there would be no way to handle the \ottkw{kind} case.

Having strengthened the induction hypothesis appropriately, the actual proof
is not too hard. The case for transitivity uses confluence---this is the only
place confluence is used. The decomposition forms use the fact that when a
value type reduces under $[[~>]]$, the reduct has to have the same shape as
the redex, with individual components in the redex reducing to those same
components in the reduct. To deal with \ottkw{step}, we must consider the
different possibilities given by the $[[S;G |-s t --> t']]$ relation.
The proper reduction rules all have analogues in $[[~>]]$, the congruence
rules all follow from the induction hypothesis, and the push rules cause
no change to a type with its coercions erased. To prove that the kinds
are joinable, we must rely heavily on the deterministic nature of the typing
relation, but there are no other undue complications.

\subsection{From completeness to consistency}

Having established the relationship between $[[S;G |-co g : phi]]$ and
joinability with respect to the rewrite relation, we must only show that
the rewrite relation relates compatible types. Here are the key lemmas:

\begin{lemma*}[Joinable types are consistent (\pref{lem:joinable-cons})]
If $[[ee1 ~>* ee3 *<~ ee2]]$, then $[[ee1 ! ee2]]$.
\end{lemma*}

\begin{lemma*}[Erasure/consistency (\pref{lem:erase-cons})]
If $[[|t1| ! |t2|]]$, then $[[t1 ! t2]]$.
\end{lemma*}

Other than some care needed around irrelevant abstractions (which cause
recursion in the rules defining $[[!]]$), these lemmas are not hard
to prove.

With all the groundwork laid, we can now conclude our consistency lemma,
stated near the top of this section.

\subsection{Related consistency proofs}
\label{sec:other-consistency-proofs}

There are a few aspects of the consistency proof where it may be helpful to
highlight the differences between my proof here and those in prior work.\footnote{The comments below imperil other, published proofs of consistency. The authors of these proofs have conceded to me in private communication
that their proofs were incorrect and do not dispute my claims below.}

\subsubsection{Non-linear, non-terminating rewrite systems are not confluent}

As described in some detail by \citet{closed-type-families}, non-terminating
rewrite systems
with non-linear left-hand sides are not confluent. We can easily see that the
rewrite relation $[[~>]]$ is not terminating. In this presentation, however,
its ``left-hand side'' is linear. Breaking from previous work, I have phrased
type families in \pico/ as $\lambda$-expressions that use \ottkw{case}; thus
the parallel to rewrite systems is not as apparent as in previous work.
In the context of my work here, a non-linear left-hand side would look like
a primitive equality check, as further explored in \pref{sec:equals-ctf}.
Because the formalization of \pico/ that I am presenting does not contain
this equality operator, I avoid the non-confluence problem described by
\citet{closed-type-families}.

Nevertheless, promising new work in the term-rewriting
community~\cite{kahrs-trss-are-un} suggests that there is a way to prove
consistency without confluence even after adding an equality check. I leave
it as future work to reconcile the approach here with the recent result
cited above.

\subsubsection{The proof of consistency by \citet{nokinds} is wrong}

The type system presented by \citet{nokinds} is very similar to \pico/, although
without dependency. Its treatment of \rul{Co\_PiCo} is subtly different,
however. Although there are numerous changes in how their syntax is structured,
Weirich et al.~effectively loosen the definition of $[[c ~# g]]$ to allow
$[[c]]$ anywhere in a coherence coercion ($[[t1 ~={h} t2]]$). In contrast,
\pico/ allows $[[c]]$ only in $[[t1]]$ or $[[t2]]$, but not in $[[h]]$.
When armed with the \ottkw{kind} coercion (identical in \pico/ to the version
by Weirich et al.), this allows us to violate a key lemma used to prove
consistency. Here is the counterexample coercion, translated into \pico/:

\[
[[g = UPI c:(<&Int{}>,<&Bool{}>). kind (#3{} ~={c} (#3{} |> c))]]
\]

In the body of the abstraction, the coercion variable $[[c]]$ has type
|Int ~ Bool|. We can use a coherence coercion to relate |3| and
$[[#3{} |> c]]$; their kinds are also related by $[[c]]$. We can then
extract the kinds of the types related by the coherence coercion. Putting
it all together yields this fact:

\[
[[S;empty |-co g : (UPI c:&Int{} [Type{}]~[Type{}] &Bool{}. &Int{}) [Type{}]~[Type{}] (UPI c:&Int{} [Type{}]~[Type{}] &Bool{}. &Bool{})]]
\]
The problem is that we can see that no rewrite relation will join the two
types related by $[[g]]$. Because Weirich et al.'s system permits $[[g]]$,
its consistency proof must be wrong. (\Pico/ rules out $[[g]]$ for using
$[[c]]$ in an illegal spot---the kind coercion in the subscript for $[[~=]]$.)
Note that the language by Weirich et al.~might indeed be consistent (I have
no counterexample to consistency), but this
fact is surely not proved via the use of a rewrite relation in the way presented
in that paper.

\subsubsection{A one-variable version of \rul{Co\_PiTy} simplifies the consistency proof}
\label{sec:one-var-no-covar}

Weirich et al.'s language differs along a different dimension, using three
binders instead of one in its version of \rul{Co\_PiTy}. (See discussion in
\pref{sec:binding-cong-forms}.) Apart from the awkwardness of needing extra
variable names, the three-binder approach poses another problem: it introduces
a coercion variable into the context. Unlike for their \rul{Co\_PiCo},
Weirich et al.~do not introduce a coercion variable restriction for this
coercion variable, as it is always a proof of equality between two variables.
This extra coercion variable cannot imperil consistency. To prove this in the
consistency proof, Weirich et al.~employ a notion of ``Good'' contexts, which
must be threaded through their proofs. My one-variable version, with no
bound coercion variable, avoids this compliation.

\subsubsection{The proof of consistency by \citet{gundry-thesis} is wrong}

Gundry, in his thesis, takes a very different approach to proving consistency
of his \emph{evidence} language, also closely related to \pico/. He sets up,
essentially, a step-indexed logical relation and uses it to consider only
closed coercions; when, say, a coercion variable is added to the context,
Gundry quantifies over all possible closing substitutions.

A key property of Gundry's logical relation is transitivity. Yet, in his
proof of transitivity, the indices do not work out. Gundry was not able
to spot a straightforward solution, and in unpublished work, Weirich also
tackled this problem and failed. Neither Gundry nor Weirich (nor I) have
a proof that the step-indexed logical relation approach is not able to work,
but no one has been able to finish the proof, either.

The failure of this approach is disappointing, because Gundry's \emph{evidence}
language does not have the coercion variable restriction inherent in \pico/'s
\rul{Co\_PiCo} rule. Gundry's language thus allows more coercions than
does \pico/.

Can a System FC-like language be proven consistent without a coercion variable
restriction on its analogue of \rul{Co\_PiCo}? My personal belief is ``yes''---given that I believe such a language is, in fact, consistent---but researchers
have yet to show it.

\section{Metatheory: Type erasure}
\label{sec:metatheory-two}
\label{sec:type-erasure}

A critical property of any intermediate language used to compile Haskell is
its ability to support type erasure. Haskell takes pride in erasing all of
its complicated, helpful types before runtime, and the intermediate language
must show that this is possible. \Pico/ acheives this goal through its
relevance annotations, where irrelevant abstractions and applications
are erased. In previous, non-dependent intermediate languages for Haskell,
irrelevant abstractions and applications are also erased, but these were
easier to spot, as they dealt with types instead of terms. In \pico/, types
and terms are indistinguishable, so we are required to use relevance
annotations.

I prove the type erasure property via defining an untyped $\lambda$-calculus
with an operational semantics, defining an erasure operation that translates
from \pico/ to the untyped calculus, and proving a simulation property between
the two languages.

\subsection{The untyped $\lambda$-calculus}

\begin{figure}
\[
\begin{array}{rcl@@{\quad}l}
[[e]] &\bnfeq& [[a]] \bnfor [[H]] \bnfor [[e y]] \bnfor [[PI]] \bnfor [[case e of ealts]] \bnfor [[\a.e]] \bnfor [[\o.e]] \bnfor [[fix e]] & \text{expression}\\
[[y]] &\bnfeq& [[e]] \bnfor [[o]] & \text{argument}\\
[[ealt]] &\bnfeq& [[pat -> e]] & \text{case alternative}
\end{array}
\]
\ottdefnEStep{}
\[
\begin{array}{cc}
\begin{array}{r@@{\,}l}
[[ ||a|| &= a ]] \\
[[ ||H{ts}|| &= H ]] \\
[[ ||t1 t2|| &= ||t1|| ||t2|| ]] \\
[[ ||t1 {t2}|| &= ||t1|| ]] \\
[[ ||t1 g|| &= ||t1|| o]] \\
[[ ||PI d.t|| &= PI]] \\
[[ ||t |> g|| &= ||t|| ]]
\end{array}
&
\begin{array}{r@@{\,}l}
[[ ||case_k t of alts|| &= case ||t|| of ||alts|| ]] \\
[[ ||\a:Rel k. t|| &= \a.||t|| ]] \\
[[ ||\a:Irrel k. t|| &= ||t|| ]] \\
[[ ||\c:phi.t|| &= \o.||t|| ]] \\
[[ ||fix t|| &= fix ||t|| ]] \\
[[ || absurd g t || &= PI ]] \\
[[ ||pat -> t || &= pat -> ||t|| ]]
\end{array}
\end{array}
\]
\caption{The type-erased $\lambda$-calculus}
\label{fig:erased-calculus}
\end{figure}

The definition of our erased calculus appears in \pref{fig:erased-calculus}.
It is an untyped $\lambda$-calculus with datatypes (allowing for default
patterns) and \ottkw{fix}. The language also contains a fixed constant\footnote{Actually, two fixed constants, $[[MPI]]$ and $[[UPI]]$.}
$[[PI]]$, here only to have something for $\Pi$-types to erase to.

The calculus also supports ``coercion abstraction''
via its $[[\o.e]]$ and $[[e o]]$ forms. The existence of these forms mean that
coercion abstractions are not fully erased. We can see why this must be so
in the following example: let $[[t = \ c:&Int{} [Type{}]~[Type{}] &Bool{}. &&notx (#3{} |> c)]]$. The type $[[t]]$ is a valid \pico/ type. We do not have to
worry about the nonsense in the body of the abstraction because consistency
guarantees that we will never be able to apply $[[t]]$ to a (closed) coercion.
As an abstraction, $[[t]]$ is a value and a normal form. However, if our
type erasure operation dropped coercion abstractions, then disaster would
strike. The erased expression would be $[[&&notx #3{}]]$, which
is surely stuck. We thus retain coercion abstractions and applications, while
dropping the coercions themselves by rewriting all coercions with the uninformative $[[o]]$.

What has now happened to our claim of type erasure? Coercions exist only to
alter types, so have we kept some meddlesome vestige of types around? In a
sense, yes, we have kept some type information around until runtime. However,
I can claim that the remaining abstractions are not meddlesome. The way in
which coercion abstractions could cause harm at runtime is by causing a program
to be a value when the user is not expecting it. For example, if a compiler
translated the Haskell program |1 + 2| into the expression
$[[\]] {[[o]]}. |1 + 2|$, then we would never get |3|. I thus make this claim:
no Haskell program ever evaluates to a coercion abstraction. This claim
is properly a property of the type inference / elaboration algorithm and so
is deferred until \pref{sec:no-coercion-abstractions}. \rae{Make sure this lines
up.}

\subsection{Simulation}

Here is the simulation property we seek:

\begin{theorem*}[Type erasure (\pref{thm:type-erasure})]
If $[[S;G |-s t --> t']]$, then either $[[||t|| --> ||t'||]]$ or
$[[||t|| = ||t'||]]$.
\end{theorem*}

Note that the untyped language might step once or not at all. For example,
when \pico/ steps by a push rule, the untyped language does not step. The
proof of this theorem is very straightforward.

\subsection{Types do not prevent evaluation}

Proving only that the erased calculus simulates \pico/ is not quite enough,
as it still might be possible that an expression in the erased
calculus can step even though the
\pico/ type from which it was derived is a normal form. The property we need
is embodied in this theorem:

\begin{theorem*}[Types do not prevent evaluation (\pref{thm:expr-eval})]
Suppose $[[S;G |-ty t : k]]$ and $[[G]]$ has only irrelevant variable bindings.
If $[[ ||t|| --> e' ]]$, then $[[ S;G |-s t --> t']]$ and either $[[ ||t'|| = e']]$ or 
$[[||t'|| = ||t||]]$.
\end{theorem*}
%
This theorem would be false if \pico/ did not step under irrelevant binders,
for example.

The proof depends on both the progress theorem and the type erasure (simulation)
theorem above, as well as this key lemma:

\begin{lemma*}[Expression redexes (\pref{lem:expr-redex})]
If $[[ ||t|| ]]$ is not an expression value, then $[[t]]$ is neither
a value nor a coerced value.
\end{lemma*}

This lemma is straightforward to prove inductively on the structure of $[[t]]$,
and then the proof of the theorem above simply stitches together the pieces.

\section{Discussion}

\subsection{Design decisions}
\label{sec:pico-design-decisions}

\section{Extensions}
\label{sec:pico-extensions}

\subsection{\ottkw{let}}
\label{sec:let-desugaring}

\subsection{A primitive equality check}
\label{sec:equals-ctf}

\rae{Extensions: split, |Equals|, representation polymorphism, |(->)|, compression (\ottkw{step} becoming $\ottkw{step}^n$).}


