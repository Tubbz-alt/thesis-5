%% -*- mode: LaTeX compile-command: "cd ..; make compile" -*-

%if style == newcode
%include rae.fmt

\begin{code}
-- import Pico.Ott
-- import Pico.Syn
import Prelude hiding ( Either(..), replicate )
import Data.Kind ( Type )
import qualified GHC.TypeLits as TL
import Data.Singletons.TH hiding ( Proxy(..) )
import Data.Singletons.Prelude

type family UU n where
  UU 0 = !Zero
  UU n = !Succ (UU (n TL.- 1))

\end{code}

%endif

\chapter{\Pico/}
\label{cha:pico}

This chapter presents \pico/, the internal language Dependent Haskell compiles
into. I have proved type safety (via the usual preservation
and progress theorems, \pref{thm:preservation} and \pref{thm:progress})
and type erasure (\pref{thm:type-erasure} and \pref{thm:expr-eval}).
I believe \pico/ would make a strong candidate for the internal language
in a future version of GHC.

\section{Overview}
\label{sec:conv-rule}

\Pico/ (pronounced like ``$\Pi$-co'', never ``peek-o'')
descends directly from the long line of work on System FC~\cite{systemfc}.
It is most closely related to the version of System FC presented in my prior
work~\cite{fckinds} and in Gundry's thesis~\cite{gundry-thesis}.

\Pico/
sits in the $\lambda$-cube~\cite{lambda-cube}
 on the same vertex as the Calculus of Constructions~\cite{coquand-cc}, but
with a very different notion of equality. A typical dependently typed
calculus contains a \emph{conversion} rule, something like this:
\[
\ottdrule{\ottpremise{\tau : \kappa_1 \qquad \kappa_1 \equiv \kappa_2}}{\tau : \kappa_2}{\rul{Conv}}
\]
This rule encapsulates the point of type equivalence: if a type $\tau$ is found
to have some kind $\kappa_1$ and $\kappa_1$ is known to be equivalent to
some $\kappa_2$, then we can say that $\tau$ has kind $\kappa_2$.\footnote{I tend
to use the word ``kind'' when referring to the classification of a type. However,
in the languages considered in this dissertation, kinds and types come from the
same grammar; the terms ``type'' and ``kind'' are technically equivalent.
Nevertheless, I find that discerning between these two words can aid intuition
and will continue to do so throughout the dissertation. \rae{Do I discuss elsewhere??}}
This rule is flexible and helps a language to be succinct. It has a major
drawback, however: it is not syntax directed. In general, determining
whether $\kappa_1 \equiv \kappa_2$ might not be easy. Indeed, type equivalence
in \pico/ is undecidable, so we would have a hard time building a type-checker
with a \rul{Conv} rule such as this one. Other dependently typed languages
are forced to restrict expressiveness in order to keep type-checking
decidable; this need for decidable type equivalence is one motivation to design
a dependently typed language to be strongly normalizing.

\Pico/'s approach to type equivalence (and the \rul{Conv} rule) derives from
the \emph{coercions} that provide the ``C'' in ``System FC''. Instead of relying
on a non-syntax-directed equivalence relation, \pico/'s type equivalence
requires evidence of equality in the form of coercions. Here is a simplified
version of \pico/'s take
of the \rul{Conv} rule:
\[
\ottdrule{\ottpremise{[[t]] : [[k1]] \qquad [[g]] : [[k1 [Type{}]~[Type{}] k2]]}}{[[t |> g]] : [[k2]]}{\rul{Ty\_Cast}}
\]
In this rule, the metavariable $[[g]]$ stands for a \emph{coercion}, a proof
of the equality between two types. Here, we see that $[[g]]$ proves that
kinds $[[k1]]$ and $[[k2]]$ are equivalent. Thus, we can type $[[t |> g]]$
at $[[k2]]$ as long as $[[t]]$ can be typed at $[[k1]]$. Note the critical
appearance of $[[g]]$ in the conclusion of the rule: this rule is syntax-directed.
The type-checker simply needs to check the equality proofs against a set of
(also syntax-directed) rules, not to check some more general equivalence relation.

The grammar for coercions (in~\pref{fig:coercions}) allows for a wide variety
of coercion forms, giving \pico/ a powerful notion of type equivalence.
However, this grammar includes no evaluation or proper $\lambda$-abstractions.\footnote{There is a coercion form that starts with $\lambda$; it is only a
congruence form for $\lambda$-abstractions in types, not a $\lambda$-abstraction
in the coercion language. See \pref{sec:lambda-coercion}.}
Thus, the fact that evaluation in \pico/ might not terminate does not threaten
the type safety of the language. Coercions are held separate from types,
and proving consistency of the coercion language (\pref{sec:consistency})---in
other words, that we cannot prove |Int ~ Bool|---is the heart of the
type safety proof. It does not, naturally, depend on any termination proof,
nor any termination checking of the program being checked. The independence
of \pico/'s type safety result from termination means that \pico/ can avoid
many potential traps that have snagged other dependently typed languages
that rely on intricate termination checks~\cite{...}.

\subsection{Features of \pico/}

\Pico/ is a dependently typed $\lambda$-calculus with algebraic datatypes and
a fixpoint operator. Recursion is modeled only via this fixpoint operator;
there is no recursive |let|. Other than the way in which the operational
semantics deals with coercions in the form of \emph{push rules}, the
small-step semantics is what you might expect for a call-by-name
$\lambda$-calculus.

The typing relations, however, have a few features worth mentioning up front;
other unusual features are best explained after the detailed coverage of
\pico/; see \pref{sec:pico-design-decisions}.

\paragraph{Relevance annotations and type erasure}
A key concern when compiling a dependently typed language is type erasure.
Given that terms and types can intermingle, what should be erased during
compilation? And what data is necessary to be retained until runtime.
Dependent Haskell (and, in turn, \pico/) forces the user to specify this
detail at each quantifier (\pref{sec:relevance}). In the formal grammar
of \pico/, we distinguish between $[[PI]] [[a:Rel k]].\, ...$ and
$[[PI]] [[a:Irrel k]].\, ...$. The former is the type of an abstraction
that is retained at runtime, written with a |pi| in Haskell;
the latter abstraction, written with |forall| is fully erased.
In order to back up this claim of full erasure of irrelevant quantification,
evaluation happens under irrelevant abstractions; see \pref{sec:step-under-abs}.

So that we can be sure a variable's relevance is respected at use sites,
variable contexts $[[G]]$ track the relevance of bound variables. Only
relevant variables may appear in the ``level'' in which they were bound;
when a typing premise refers to a higher ``level'', the context is altered to
mark all variables as relevant. For example, the \ottkw{case} construct
$[[case_k t of alts]]$ includes the return kind of the entire \ottkw{case}
expression as its $[[k]]$ subscript. This kind is type-checked in a context
where all variables are marked as relevant; because the kind is erased
during compilation, the use of an irrelevant variable there is allowed.
As they are also erased, coercions are considered fully irrelevant as well.

My treatment of resetting the context is precisely like what is done
by \citet{erasure-pure-type-systems}.

\paragraph{Matching on partially-applied constants}
\Pico/ does not contain type families. Instead, it uses $\lambda$-abstractions
and \ottkw{case} expressions, as are more familiar to functional programmers.
And yet, I wish for \pico/ to support the variety of ways in which type families
are used in today's Haskell. One curiosity of today's Haskell is that it allows
matching on partially-applied data constructors:
\begin{code}
type family IsLeft a where
  IsLeft !Left   = !True
  IsLeft !Right  = !False
\end{code}
The type family |IsLeft| is inferred to have kind
|forall k. (k -> Either k k) -> Bool|. That is, it matches on the |Left|
and |Right| constructors, even though these are not applied to arguments.
While it may seem that |IsLeft| is matching on a \emph{function}---after all,
the type of |IsLeft|'s argument appears to be an arrow type---it is not.
It is matching only on constructors, because the kind-level |->| classifies
only type constants. \rae{Flesh this out once I know how I'm dealing with the
two arrows in Haskell.}

To get this partially-applied matching to work in \pico/, it is necessary
to have two different $[[PI]]$-quantifiers: $[[MPI]]$ and $[[UPI]]$. The
former is called a \emph{matchable} $[[PI]]$, the latter is \emph{unmatchable}.
Type constants are classified by $[[MPI]]$, whereas $\lambda$-abstractions
are classified by $[[UPI]]$.
Only matchable $[[MPI]]$-types are allowed as \ottkw{case} scrutinees.
When I write the unadorned $[[PI]]$, I actually mean a metavariable which
might be instantiated either to $[[MPI]]$ or $[[UPI]]$.

\paragraph{Matching on $[[Type]]$}

Today's Haskell also has the ability, through its type families, to match on
members of $[[Type]]$. For example:
\begin{code}
type family IntLike x where
  IntLike Integer = !True
  IntLike Int     = !True
  IntLike _       = !False
\end{code}
This ability for a function to inspect the choice of a type---and not a code
for a type---is unique to Haskell, as far as I am aware. With the type families
in today's Haskell, discerning between types is done by simple pattern matching.
However, if we compile type families to \ottkw{case} statements, we need a way
to deal with this construct.

Fortunately, types like |Either| resemble data constructors like |Just|:
both are classified by matchable quantification(s) over a type headed by another
type constant. In the case of |Either|, we have $|Either| : 
[[MPI _:Rel Type{}, _:Rel Type{}. Type{} ]]$;\footnote{Why $[[Rel]]$? See
\pref{sec:relevance-of-datatypes}.} note that the body of the
$[[PI]]$-type is headed by the constant $[[Type{}]]$. For |Just|,
we have $|Just|_{[[ {a} ]]} : [[MPI _ :Rel a. &Maybe{} a]]$.\footnote{The
$[[ {a} ]]$ subscript is explain in \pref{sec:universals}.}
With this similarity, it is not hard to create a typing rule for a \ottkw{case}
statement that can handle both data constructors (like |Just|) and types
(like |Either|).

A key feature, however, that is needed to support matching on $[[Type]]$ is
default patterns. For a closed datatype, where all the constructors can be
enumerated, default patterns are merely a convenience; any default can be
expanded to list all possible constructors. For an open type, like $[[Type]]$,
the availability of the default pattern is essential. It is for this reason alone
that I have chosen to include default patterns in \pico/.

\paragraph{Hypothetical equality}

\Pico/ allows abstraction over coercions, much like any $\lambda$-calculus
allows abstraction over expressions (or, in a call-by-value calculus,
values). Coercion abstraction means that a type equality may be \emph{assumed}
in a given type. When we wish to evaluate a term that assumes an equality,
we must apply that term to evidence that the equality holds---an actual coercion.
It is this ability, to assume an equality, that allows \pico/ to have
GADTs. See the example in \pref{sec:pico-gadt-example} for the details.

\subsection{Design requirements for \pico/}

In the course of any language design, there needs to be a guiding principle
to aid in making free design decisions. The chief motivator for the design
of \pico/ is that it should be suitable for use as the internal language
of a Haskell compiler. This use case provides several desiderata:

\paragraph{Decidable, syntax-directed, efficient type-checking}
The use of types in a compiler's intermediate language serves only as a check
of the correctness of the compiler. Any programmer errors are caught before
the intermediate language code is emitted, and so a correct compiler should
only produce well-typed intermediate-language programs, if it produces such
programs at all. In addition, a correct compiler performing program transformations
on the intermediate language should take a well-typed program to a well-typed
program. However, not all compilers are correct, and thus it is helpful
to have a way to check that intermediate-language program generation and
transformation is at least type-preserving. To check this property, we need
to type-check the intermediate language, both after it is originally
produced and after every transformation. It thus must be easy and efficient
to do so.

\Pico/ essentially encodes a typing derivation right in the syntax of types
and coercions. It is thus very easy to write a type-checker for the language.
Type-checking is manifestly decidable and can be done in one pass over the
program text, with no constraint solving.\footnote{I do not claim that it
is strictly linear, as a formal analysis of its running time is beyond the
scope of this dissertation. In particular, one rule
(see \pref{sec:case-expressions}) requires the use of a unification algorithm
and likely breaks linearity.} \Pico/'s lack of a termination requirement
also significantly lowers the burden of implementation of a type-checker
for the language.

\paragraph{Erasability}

An intermediate-language program should make clear what information can be
erased at runtime. After all, when the compiler is done performing optimizations,
runtime code generation must take place, and we thus need to know what
information can be dropped. It is for this reason that \pico/ includes the
relevance annotations.

\paragraph{A balance between ease of proving and ease of implementation}
\Pico/ serves two goals: to be a template for an implementation, and also
to be a calculus used to prove type safety. These goals are sometimes at
odds with each other.

These two goals of System~FC have tugged in
different directions since the advent of FC. Historically, published
versions of the language have greatly simplified certain details. 
No previously published treatment of FC has included support for recursion,
either through \ottkw{letrec} or \ottkw{fix}. In contrast, the implemented
version of FC makes certain choices for efficiency; for example, applied
type constructors, such as |Either Int Bool|, have a different representation
than do applied type variables, such as |a Int Bool|. The former is stored
as the head constructor with a list of arguments, and the latter is stored
as nested binary applications. This is convenient when implementing but
meddlesome when proving properties. The divergence between published FC
and the implemented version (more often called GHC Core) have led to a
separate document just to track the implemented version~\cite{ghc-core-spec}.

In the design of \pico/, I have aimed for balance between these two needs.
Because of the risk that non-termination might cause unsoundness, I have
explicitly included \ottkw{fix} in the design, just to make sure that
the non-termination is obvious.\footnote{With $[[Type{}]] : [[Type{}]]$, we
have the possibility of Girard's paradox~\cite{girard-paradox} and thus
can have non-termination even without \ottkw{fix}, but making the non-termination
more obvious clarifies that we can achieve type safety without termination.}
I have not, however, included an explicit \ottkw{let} or \ottkw{letrec}
construct, as the specification of these would be quite involved, and yet
desugaring these constructs into $[[\]]$ and \ottkw{fix} is straightforward.
(See \pref{sec:let-desugaring}.)

On the other hand, I have included \ottkw{case}. Having \ottkw{case} in the
language also significantly complicates the presentation, but here in a
useful way: the existence of \ottkw{case} (over unsaturated constructors)
motivates the distinction between $[[UPI]]$ and $[[MPI]]$. The desugaring
of \ottkw{case} into recursive types built, say, with \ottkw{fix} is not
nearly as simple as the desugaring of \ottkw{let}.

In the end, choices
such as these are somewhat arbitrary and come down to taste. I believe
that the choices I have made here bring us to a useful formalization with
the right points of complexity. Some of these design decisions are considered
in more depth after \pico/ has been presented;
see \pref{sec:pico-design-decisions}.

\subsection{Other applications of \pico/}

It is my hope that \pico/ sees application beyond just in Haskell. In designing
it, I have tried to permit certain Haskell idioms (call-by-name semantics,
the extra capabilities of \ottkw{case} expressions outlined above) while
still retaining a general enough flavor that it could be adapted to other
settings. I believe that the arguments above about \pico/'s design mean
that it is a suitable starting-point for the design of an
intermediate language for any dependently typed surface language. Other uses
might want call-by-value instead of call-by-name or to remove the somewhat
fiddly distinction between $[[MPI]]$ and $[[UPI]]$. These changes should be
rather straightforward to make.

In certain areas, I have decided not to support certain existing Haskell
constructs directly in \pico/ because doing so would clutter the language,
making its applicability beyond Haskell harder to envision. Various
extensions of \pico/---which would likely appear in an implementation of
\pico/ within GHC---are discussed in \pref{sec:pico-extensions}. These
include representation polymorphism and support for the $([[->]])$ type 
constructor, for example.

\subsection{No roles in \pico/}

Recent versions of System FC have included \emph{roles}~\cite{coercible},
which distinguish between two different notions of type equality:
nominal equality is the equality relation embodied in Haskell's |(~)|
operator, whereas representational equality relates types that have
bit-for-bit identical runtime representations. Tracking these two
equality relations is important for allowing zero-cost conversions
between types known to have the same representation, and it is an
important feature to boost performance of programs that use |newtype|
to enforce abstraction.

However, roles greatly clutter the language
and its proofs. Including them throughout this dissertation would distract
us from the main goal of understanding a dependently typed language
with $[[Type{}]] : [[Type{}]]$ and
at ease with non-termination. It is for this reason that I have chosen
to omit roles entirely from this work. I am confident that, in time, roles
can be integrated with the language presented here, perhaps along the
lines I have articulated in a draft paper~\cite{overabundance-of-equalities},
though the treatment there still leaves something to be desired.
Regardless of clutter, having a solid approach to combining roles with
dependent types will be a prerequisite of releasing a performant
implementation of dependent types in GHC.

\section{A formal specification of \pico/}

\begin{figure}
Metavariables:
\[
\begin{array}{rl@@{\qquad}rl}
[[T]] & \text{algebraic datatype} & [[K]] & \text{data constructor} \\
[[a,b,x]] & \text{type/term variable} & [[c]] & \text{coercion variable} \\
[[i, j, kk, n]] & \text{natural number/index}
\end{array}
\]
\[
\begin{array}{rcl@@{\quad}l}
[[PI]] &\bnfeq& [[MPI]] & \text{matchable dep.~quantifier} \\
&\bnfor& [[UPI]] & \text{unmatchable dep.~quantifier} \\
[[z]] &\bnfeq& [[a]] \bnfor [[c]] & \text{type or coercion variable} \\
[[H]] &\bnfeq& [[T]] \bnfor [[K]] \bnfor [[Type]] & \text{constant} \\
[[rel]] &\bnfeq& [[Rel]] \bnfor [[Irrel]] & \text{relevance annotation} \\
[[d]] &\bnfeq& [[a :rel k]] \bnfor [[c : phi]] & \text{binder} \\
[[phi]] &\bnfeq& [[t1 (k1)~(k2) t2]] & \text{heterogeneous equality} \\
[[t]], [[s]], [[k]] &\bnfeq& [[a]] \bnfor [[t p]] \bnfor [[PI d.t]] \bnfor [[\d.t]] 
                   & \text{dependent types} \\
&\bnfor& [[H{ts}]] & \text{constant applied to universals} \\
&\bnfor& [[t |> g]] & \text{kind cast} \\
&\bnfor& [[case_k t of alts]] & \text{case-splitting} \\
&\bnfor& [[fix t]] & \text{recursion} \\
&\bnfor& [[absurd g t]] & \text{absurdity elimination} \\
[[p]] &\bnfeq& [[t]] \bnfor [[{t}]] \bnfor [[g]] & \text{argument} \\
[[alt]] &\bnfeq& [[pat -> t]] & \text{case alternative} \\
[[pat]] &\bnfeq& [[H]] \bnfor [[_]] & \text{pattern} \\
[[g,h]] &\bnfeq& [[c]] & \text{coercion assumption} \\
&\bnfor& [[<t>]] \bnfor [[sym g]] \bnfor [[g1 ;; g2]] & \text{equivalence} \\
&\bnfor& [[H{gs}]] \bnfor [[g w]] \bnfor [[PI a:rel h.g]] \bnfor [[PI c:(h1,h2).g]]   & \text{congruence} \\
&\bnfor& \multicolumn{2}{l}{[[case_h g of calts]] \bnfor [[fix g]]
\bnfor [[\a :rel h.g]] \bnfor [[\c:(h1,h2).g]]  
\bnfor [[absurd (h1,h2) g]]} \\
&\bnfor& [[t1 ~={h} t2]] & \text{coherence} \\
&\bnfor& [[argk g]] \bnfor [[argk n g]] \bnfor [[res^n g]] \bnfor [[g@w]] & \text{$[[PI]]$-type decomposition} \\
&\bnfor& [[nth n g]] & \text{injectivity} \\
&\bnfor& [[kind g]] & \text{``John Major'' equality} \\
&\bnfor& [[step t]] & \text{$\beta$-equivalence} \\
[[calt]] &\bnfeq& [[pat -> g]] & \text{case alternative in coercion} \\
[[w]] &\bnfeq& [[g]] \bnfor [[{g}]] \bnfor [[(g1,g2)]] & \text{coercion argument} \\[1ex]
[[S]] &\bnfeq& [[empty]]  & \text{signature} \\
&\bnfor& [[S, T:(as:ks)]] & \text{algebraic datatype} \\
&\bnfor& [[S, K:(D;T)]] & \text{data constructor} \\
[[G,D]] &\bnfeq& [[empty]] \bnfor [[G, d]] & \text{context/telescope} \\
[[theta]] &\bnfeq& [[empty]] \bnfor [[theta, t/a]] \bnfor [[theta, g/c]] & \text{substitution} \\[1ex]
[[e]] &\bnfeq& [[a]] \bnfor [[H]] \bnfor [[e y]] \bnfor [[PI]] \bnfor [[case e of ealts]] & \text{erased expression} \\
& \bnfor & [[\a.e]] \bnfor [[\o.e]] \bnfor [[fix e]] \\
[[y]] &\bnfeq& [[e]] \bnfor [[o]] & \text{erased argument} \\
[[ealt]] &\bnfeq& [[pat -> e]] & \text{erased alternative} \\
\end{array}
\]
\caption{The grammar of \pico/}
\label{fig:pico-grammar}
\end{figure}

\begin{figure}
\[
\begin{array}{rcl}
\overline{\text{\phantom{T}}} &\defeq& \text{(an overbar) indicates a list} \\
[[_]] &\defeq& \text{a fresh variable whose name is not used} \\
[[dom(D)]] &\defeq& \text{the list of variables bound in $[[D]]$} \\
[[prefix]](\cdot) &\defeq& \text{a prefix of a list; length specified elsewhere} \\
[[fv]](\cdot) &\defeq& \text{extract all free variables, as a set} \\
[[H]] &\defeq& [[H{blank}]] \text{ (when appearing in a type)} \\
[[PI D. t]] &\defeq& \text{nested $[[PI]]$s} \\
[[MUPI D. t]] &\defeq& \text{nested $[[PI]]$s, where the individual $[[PI]]$s used might differ} \\
[[\D.t]] &\defeq& \text{nested $[[\ ]]$s} \\
[[t1 [k1]~[k2] t2]] &\defeq& [[t1 (k1)~(k2) t2]] \text{ (when the kinds are obvious or unimportant)} \\
[[o]] &\defeq& \text{an erased coercion} \\
[[#]] &\defeq& \text{the sets of free variables of two entities are distinct} \\
\lfloor \cdot \rfloor &\defeq& \text{coercion erasure (\pref{sec:coercion-erasure})} \\
\llfloor \cdot \rrfloor &\defeq& \text{type erasure (\pref{sec:type-erasure})} \\
\ottkw{let} &\text{is}& \text{used in the metatheory only and should be eagerly expanded}\\
\end{array}
\]
\caption{Notation conventions of \pico/}
\label{fig:pico-notation}
\end{figure}

\begin{figure}
\[\def\arraystretch{1.5}
\begin{array}{cl}
[[S |-tc H : D1;D2;H']] & \text{\parbox{.7\textwidth}{Constant $[[H]]$ has universals $[[D1]]$,
existentials $[[D2]]$, and belongs to parent type $[[H']]$.}} \\
[[S;G |-ty t : k]] & \text{Type $[[t]]$ has kind $[[k]]$.} \\
[[S;G;s;t0 |-alt pat -> t : k]] & \text{\parbox{.7\textwidth}{Case alternative $[[pat -> t]]$
yields something of kind $[[k]]$ when used with a scrutinee $[[t0]]$ of
type $[[s]]$.}} \\
[[S;G |-co g : phi]] & \text{Coercion $[[g]]$ proves proposition $[[phi]]$.} \\
[[S;G |-prop phi]] & \text{Proposition $[[phi]]$ is well formed.} \\
[[S;G |-vec ps : D]] & \text{Vector $[[ps]]$ is classified by telescope $[[D]]$.} \\
[[S;G |-cev ps : D]] & \text{\parbox{.7\textwidth}{Vector $[[ps]]$ is classified by telescope $[[D]]$
(with induction defined from the end).}} \\
[[|-sig S]] & \text{Signature $[[S]]$ is well formed.} \\
[[S |-ctx G]] & \text{Context $[[G]]$ is well formed.} \\
[[S;G |-s t --> t']] & \text{Type $[[t]]$ reduces to type $[[t']]$ in one step.}
\end{array}
\]
\caption{Judgments used in the definition of \pico/}
\label{fig:pico-judgments}
\end{figure}

The full grammar of \pico/ appears in \pref{fig:pico-grammar} and
notation conventions appear in \pref{fig:pico-notation}. We will cover
these in detail in the following sections. Later
sections of this chapter will cover portions of the typing rules, but for
a full listing of all the typing rules of the language, please see
\pref{app:pico-rules}. \pref{fig:pico-judgments} includes the judgment
forms. All of the metatheory lemmas, theorems, and proofs appear in
\pref{app:pico-proofs}. This section mentions several key lemmas and
theorems, but the ordering here is intended for readability and
lemma statements may be abbreviated; please
see the appendix for the correct dependency ordering and full statements.

You will see that the \pico/ language is centered around what I call types,
represented by metavariables $[[t]]$, $[[s]]$, and $[[k]]$. As \pico/ is a
full dependently typed language with a unified syntax for terms, types, and
kinds, this production could be called ``expressions'' and could be assigned
the metavariable $[[e]]$. However, I have decided to reserve $[[e]]$ (and the
moniker ``expression'') for \emph{erased} expressions only, after all the types
have been removed. These expressions are used only in the type erasure theorem
(\pref{sec:type-erasure}); the rest of the metatheory is about types. Nevertheless,
a program written in \pico/ intended to be run will technically be a type,
and types in \pico/ have an operational semantics
(\pref{sec:operational-semantics}).

Note also the definition for arguments $[[p]]$: the application form $[[t p]]$
applies a type to an argument, which can be a type, an irrelevant type,
or a coercion. It would be equivalent to have three productions in the definition
for types, but having a separate definition for arguments allows us to easily
discuss what I call \emph{vectors},\footnote{I have adopted this terminology
from \citet{gundry-thesis}.} which are lists of arguments $[[ps]]$.

As you will see in \pref{fig:pico-notation}, my presentation of \pico/ uses
several abbreviations and elisions in its typesetting. In particular, I
frequently write types like $[[PI D. t]]$ to represents a nested $[[PI]]$-type,
binding the variables listed in $[[D]]$ (which, as you can see, is just a list
of binders $[[d]]$). An equality proposition in \pico/ lists both the related
types and their kinds. Often, the kinds are redundant, obvious, or unimportant,
and so I elide them in those cases.

All of the metatheory in this dissertation is typeset using
\package{ott}~\cite{ott}. This tool effectively type-checks my work,
preventing me from writing, say, the nonsense $[[a]]{:}[[phi]]$, which is
rightly a parsing error.\footnote{Indeed, to include that example in the text,
  I had to avoid rendering the example in \package{ott} syntax.} In addition,
I have configured my use of \package{ott} to require me to write the kinds
of an equality proposition even when I intend for them to be elided in the
rendered output, as a check to make sure these parameters can indeed be written
with the information to hand.

\rae{Is this outline still accurate?}
This chapter proceeds by explaining all of the various typing judgments
individually. \pref{sec:contexts-rel-annots} explains contexts $[[G]]$,
along with relevance annotations. \pref{sec:signatures} explains
signatures $[[S]]$, which contain specifications for constants $[[H]]$.
Having explained the more unexpected aspects of the syntax, I then
present examples of \pico/ programs in \pref{sec:pico-examples}.
Types come next, in \pref{sec:pico-types}, followed by coercions
in \pref{sec:pico-coercions}. The metatheory is discussed in
\pref{sec:metatheory}. The chapter concludes in \pref{sec:pico-extensions}
by considering a variety of extensions to \pico/ that are needed for
full, backward-compatible support for Haskell as embodied in GHC~8.

\section{Contexts $[[G]]$ and relevance annotations}
\label{sec:contexts-rel-annots}
\label{sec:ty-var}

One of the distinctive aspects of \pico/ is its use of relevance annotations
on binders. Every type variable binding $[[a :rel k]]$ comes with a relevance
annotation $[[rel]]$, which can be either $[[Rel]]$ or $[[Irrel]]$. A
typing context $[[G]]$ is just a list of such binders (along with, perhaps,
coercion variable binders) and so retains the relevance annotation. These
annotations come into play only in the rule for checking variable occurrences:
\[
\ottdruleTyXXVar{}
\]
Note that this rule requires $[[a:Rel k \in G]]$, with a relevant binder.
Thus, only variables that are considered relevant---that is, variables that
will remain at runtime---can be used in an expression. As described briefly
above, when we ``go up a level'', we reset the context, making all variables
marked as relevant. This resetting is done by the $[[Rel(G)]]$ operation,
defined recursively on the structure of $[[G]]$ as follows:
\begin{align*}
[[Rel(empty) &= empty]] \\
[[Rel(G, a :rel k) &= Rel(G), a :Rel k]] \\
[[Rel(G, c:phi) &= Rel(G), c:phi]]
\end{align*}
The $[[Rel(G)]]$ operation is used, for example, in the judgment to check
contexts for validity:\\[\baselineskip]
\ottdefnCtx{}

Here, we see that a binding $[[a :rel k]]$ can be appended onto a context
$[[G]]$ when the $[[a]]$ is fresh and the $[[k]]$ is well-typed at $[[Type{}]]$
in $[[Rel(G)]]$. The reason for using $[[Rel(G)]]$ instead of $[[G]]$ here
is that the kind $[[k]]$ does not exist at runtime, regardless of the
relevance annotation on $[[a]]$. We are thus free to essentially ignore
the relevance annotations on $[[G]]$, which is what $[[Rel(G)]]$ does.
The same logic applies to the use of $[[Rel(G)]]$ in the \rul{Ctx\_CoVar}
rule. Indeed, all premises involving coercions use $[[Rel(G)]]$, as all
coercions are erased and are thus irrelevant.

\paragraph{Regularity}
Regularity is an important property of \pico/, allowing us to easily
assume well-formed contexts and signatures:

\begin{lemma*}[Context regularity (\pref{lem:ctx-reg})]
If:
\begin{enumerate}
\item $[[S;G |-ty t : k]]$, OR
\item $[[S;G |-co g : phi]]$, OR
\item $[[S;G |-prop phi]]$, OR
\item $[[S;G;s0;t0 |-alt alt : k]]$, OR
\item $[[S;G |-vec ps : D]]$, OR
\item $[[S |-ctx G]]$
\end{enumerate}
Then $[[S |-ctx prefix(G)]]$ and $[[|-sig S]]$, where $[[prefix(G)]]$ is an
arbitrary prefix of $[[G]]$. Furthermore, both resulting derivations are no
larger than the input derivations.
\end{lemma*}

\section{Signatures $[[S]]$ and type constants $[[H]]$}
\label{sec:signatures}

The typing rules in \pico/ are all parameterized by both a signature
$[[S]]$ and a context $[[G]]$. Signatures contain bindings for all global
constants: type and data constructors. In contrast, contexts contain
local bindings, for type and coercion variables. Several treatments of
System FC assume a fixed, global signature, but I find it more precise
here to make dependency on this signature explicit.

\subsection{Signature validity}
\label{sec:term-arguments-are-existentials}

The judgment to check the validity of a signature follows:\\[\baselineskip]
\ottdefnSig{}

We see here the two different entities that can be added to a signature,
an algebraic datatype (ADT) $[[T]]$ or a data constructor $[[K]]$.

An ADT is classified only by its list of universally quantified variables
(often shortened to \emph{universals}), as this is the only piece of information
that varies between ADTs. For example, the Haskell type \id{Int} contains
no universals, while \id{Either} contains two (both of kind $[[Type]]$),
and \id{Proxy}'s universals are $[[(a : Type{}, b : a)]]$. The relevance
of universals is predetermined (see \pref{sec:adt-relevance}) and so
no relevance annotations appear on ADT specifications. Additionally,
coercion variables are not permitted here---coercion variables would
be very much akin to Haskell's misfeature of datatype
contexts~\cite{datatype-contexts} and so are excluded.

A data constructor is classified by a telescope $[[D]]$ of existentially
bound variables (or \emph{existentials})
and the ADT to which it belongs. The grammar for telescopes
is the same as that for contexts, but we use the metavariables $[[G]]$
and $[[D]]$ in distinct ways: $[[G]]$ is used as the context for typing judgments,
whereas $[[D]]$ is more often used as some component of a type. A telescope
is a list of binders---both type variables and coercion variables---where
later binders may depend on earlier ones. A data constructor's existentials are
the data that cannot be determined from an applied data constructor's type.
In this formulation, the term \emph{existential} also includes what would
normally be considered term-level arguments.

For example, let's consider these
Haskell definitions:
%
\begin{code}
data Tuple a where
  MkTuple :: forall a. Int -> Char -> a -> Tuple a
data Ex a where
  MkEx :: forall a b. b -> a -> Ex a
\end{code}
%
If I have a value of type |Tuple Double|, then I know the types of the data
stored in a |MkTuple|, but I do not know the |Int|, the |Char|, or the
|Double|---these are the existentials. Similarly, if I have a value of type
|Ex Char|, then I know that the type of one argument to |MkEx|, but I do not
know the type of the other; I also know neither value. In this case, the
second type, |b|, is existential, as are both values (of types |b| and |a|,
respectively).

The use of the term \emph{existential} to refer to term-level arguments
may be non-standard, but it is quite convenient (while remaining
 technically accurate)
in the context of a pure
type system with ADTs.

\subsection{Looking up type constants}
\label{sec:ty-con}

Information about type constants is retrieved via the following
judgment:\\[\baselineskip]
\ottdefnTc{}

The judgment $[[S |-tc H : D1;D2;H']]$
retrieves three pieces of data about a type constant
$[[H]]$: its universals, its existentials, and the root of the result type.
This judgment is best understood in concert with the typing rule that handles
type constants:
\[
\ottdruleTyXXCon{}
\]
Let's tackle these in order of complexity.

\subsubsection{The constant $[[Type]]$}
The constant $[[Type]]$ has no universals, no existentials, and $[[Type]]$'s
type is $[[Type]]$, as \rul{Tc\_Type} tells us. Thus, in the use of
\rul{Ty\_Con} when $[[H{ts}]]$ is just $[[Type{blank}]]$ (normally, we omit
such empty braces), we see that $[[D1]]$, $[[D2]]$, and $[[ts]]$ are all empty,
meaning that we get $[[S;G |-ty Type{} : Type{}]]$, as desired.

\subsubsection{Algebraic datatypes}
Let's consider \id{Maybe} as an example. We see that the list of universals
$[[D1]]$ is empty for all ADTs. Thus, the list of universal arguments $[[ts]]$
must be empty in \rul{Ty\_Con}. The list of existentials $[[D2]]$ is
$[[a :Rel Type{}]]$ and the result type
root is $[[Type]]$, both by \rul{Tc\_ADT}. We thus get
$[[S;G |-ty &Maybe{} : MPI a :Rel Type{}. Type{}]]$, as desired. (Note that
$[[a]]$ is unused in the body of the $[[MPI]]$ and thus that this type
could also be written as $[[Type{} -> Type{}]]$.)

I have argued here how the rules work out this case correctly,
but it may surprise the reader to see that the argument to \id{Maybe} is
treated as an \emph{existential} here---part of $[[D2]]$---and not a
universal. This could best be understood if we consider $[[Type]]$ itself
to be an open ADT (that is, an extensible ADT) with no universal parameters.
To make this even more concrete, here is how it might look in Haskell:
%
% NB: The ^^ after Int below is to prevent lhs2TeX from centering the
% column of constructors.
\begin{spec}
data Type where
  Bool    ::  Type
  Int ^^  ::  Type
  Maybe   ::  Type -> Type
  Proxy   ::  forall (k :: Type). k -> Type
  ...
\end{spec}
%
Thinking of ADTs this way, we can see why the argument to |Maybe| is
existential, just like other arguments to constructors. We can also see
that the kind parameter |k| to |Proxy| is also considered an existential
in this context.

The last detail to cover here is the relevance annotation on the $[[as]]$,
as assigned in \rul{Tc\_ADT}: all the variables are considered relevant.
This is a free choice in the design of \pico/. Any choice of relevance
annotations would work, including allowing the user to decide on a case-by-case
basis. I have chosen to mark them as relevant, however, with the consideration
that these ADTs might be present at runtime. There is nothing in \pico/ that
restricts ADTs to be present only at compile time; the user might write a
runtime computation that returns |Bool|, for example.\footnote{This
statement does not mean that you can extract the value |Maybe Int| from
|Just 3|, which would require preserving all types for runtime.} (Such a facility
replaces Haskell's current |TypeRep| facility~\cite{typerep}.) By marking
the ADT parameters as relevant, a runtime decision can be made between, say,
|Maybe Int| and |Maybe Bool|. This seems useful, and so I have decided to make
these parameters relevant.

\subsubsection{Data constructors}
\label{sec:pico-either}

The most involved case is that for data constructors, where both the
universals and the existentials can be non-empty. We'll try to understand
\rul{Ty\_Con} first by an example inspired by the Haskell
expression |Left True :: Either Bool Char|. Let's recall the definition
of |Either|, a basic sum type:
%
\begin{code}
data Either :: Type -> Type -> Type where
  Left   :: a -> Either a b
  Right  :: b -> Either a b
\end{code}
In \pico/ this looks like the following:
\[
\begin{array}{l@@{\,}l}
[[S]] =& [[ &Either : (&&ax : Type{}, &&bx : Type{}), &Left : (&&xx :Rel &&ax; &Either), &Right : (&&xx :Rel &&bx; &Either)]], \\
& [[&Bool : (empty), &True : (empty; &Bool), &False : (empty; &Bool), &Char : (empty)]]\\[1ex]
\multicolumn{2}{l}{
[[S; empty |-ty &Left{&Bool{}, &Char{} } &True{} : &Either{} &Bool{} &Char{} ]]}
\end{array}
\]
%
We see how the universal arguments |Bool| and |Char| to the constructor |Left|
are specified in the subscript; without these arguments, there would be no way
to get the type of |Left True| in a syntax-directed way.

\paragraph{Universal argument saturation}
The grammar for type constant occurrences in types requires them to appear
fully saturated with respect to universals but perhaps unsaturated with
resepct to existentials. There are several reasons for this seemingly-peculiar
design:
\begin{itemize}
\item It is helpful to separate universals from existentials in a variety of
  contexts. For example, existentials are brought into scope on a
  \ottkw{case}-match, while universals are not. Separating out these arguments
  is also essential in the step rule \rul{S\_KPush}.

\item If \pico/ did not allow matching on unsaturated constants, it might
be most natural to require saturation with respect to both universals
and existentials (while still keeping these different arguments separate).
This would allow, for example, for a simple statement of the canonical
forms lemma (\pref{lem:canon-form}),
because only a $[[\ ]]$-expression would have a $[[PI]]$-type.

However, since \pico/ does allow matching on unsaturated constants, the
grammar must permit this form. Because of \pico/'s discernment between
matchable $[[MPI]]$ and unmatchable $[[UPI]]$, we retain the simplicity
of the canonical forms lemma, as any expression classified by a $[[MPI]]$
must be a partially applied constant and any expression classified by a
$[[UPI]]$ must be a $[[\ ]]$.

\item All univeral arguments are always irrelevant and erased during
type erasure (\pref{sec:type-erasure}). It is thus natural to separate
these from existentials in the grammar.
\end{itemize}

As with many design decisions, it is possible to redesign \pico/ and
avoid this unusual choice, but in my opinion, this design pays its
weight nicely.

\paragraph{Typing rules for data constructors}
The \rul{Tc\_DataCon} rule looks up a data constructor $[[K]]$ in the
signature $[[S]]$ to find its telescope of existentials $[[D]]$
and parent datatype $[[T]]$. The second premise of the rule then
looks up $[[T]]$ to get the universals. The universals are annotated
with $[[Irrel]]$, as universals are always irrelevant in data
constructors---universal arguments are properly part of the type
of a data constructor and are thus not needed at runtime. The
telescope of existentials $[[D]]$ and datatype $[[T]]$ are also
returned from $[[|-tc]]$.

Rule \rul{Ty\_Con} checks the supplied arguments $[[ts]]$ against
the telescope of universals, here named $[[D1]]$. Note that $[[ts]]$
are checked against $[[Rel(D1)]]$; the braces that appear in the
production $[[H{ts}]]$ are part of the concrete syntax and do not
represent wrapping each individual $[[t]] \in [[ts]]$ in braces
(cf.~\pref{sec:type-app-irrelevant}). Rule \rul{Ty\_Con} then
builds the result type, a $[[MPI]]$-type binding the existentials
and producing $[[H']]$---that is, the parent type $[[T]]$---applied
to all of the universals.

\section{Examples}

Though these may make sense more fully after reading the sections below, it
may be helpful at this point to see a few short examples of \pico/ programs. 

We will work with a definition of length-indexed vectors, a tried-and-true
example of the design of GADTs. Here is how they are declared in Haskell
(further explanation is available in \pref{sec:length-indexed-vectors}):
%if style == poly
%format (UU x) = x
%endif
\begin{code}
data Nat = Zero | Succ Nat
data Vec :: Type -> Nat -> Type where
  VNil   :: Vec a (UU 0)
  VCons  :: a -> Vec a n -> Vec a (!Succ n)
\end{code}
If \pico/ had a concrete syntax, these declarations would be transformed
roughly into the following:
\begin{spec}
Nat   ::  Type
Zero  ::  Nat
Succ  ::  Nat -> Nat

Vec    ::  Type -> Nat -> Type
VNil   ::  forall (a :: Type) (n :: Nat). (n ~ Zero) -> Vec a n
VCons  ::  forall (a :: Type) (n :: Nat). 
           forall (m :: Nat). (n ~ Succ m) -> a -> Vec a m -> Vec a n
\end{spec}
The change seen here is just the transformation between specifying a GADT
equality constraint
via a return type in a declaration to using an explicit existential variable
with an explicit equality constraint.

In the abstract syntax of \pico/,
these declarations are represented by this signature $[[S0]]$:
\[
\begin{array}{r@@{\,}l}
[[S0]] = & [[&Nat : (empty)]], \\
& [[ &Zero : (empty; &Nat)]], \\
& [[ &Succ : (_ :Rel &Nat{}; &Nat)]], \\
 & [[&Vec : (&&ax : Type{}, &&nx : &Nat{})]], \\
& [[ &VNil : (c : &&nx [&Nat{}]~[&Nat{}] #0{}; &Vec)]], \\
& [[&VCons : (&&mx :Irrel &Nat{}, c : &&nx [&Nat{}]~[&Nat{}] &Succ{} &&mx, _ :Rel &&ax, _ :Rel &Vec{} &&ax &&mx; &Vec)]]
\end{array}
\]
Let's walk through these declarations.
Our binding for |Nat| includes an empty list
of universally quantified type variables. This binding is followed
by specifications for |Zero|, which lists no existential variables and
is a constructor of the datatype |Nat|, and |Succ|, which has one 
(anonymous) existential
variable and also belongs to |Nat|. 
The bindings for |Vec| and its constructors are similar, but with more
parameters. Note the coercion bindings in the telescopes associated with
|VNil| and |VCons|, as well as the irrelevant binding for the existential
|m| of |VCons|. The design we see here, echoing the Haskell, does not permit
runtime extraction of the length of a vector. If we changed the |m| to be
relevant, then runtime length extraction would be trivial.

We will now look at a few simple operations on vectors, first in Haskell
and then in \pico/.\footnote{In these examples, I assume the use of numerals
to specify elements of type |Nat|, and I also assume the existence of, e.g.,
|Bool|.}

\subsection{|isEmpty|}
First, a very simple test for emptiness, in order to familiarize ourselves
with pattern-match syntax in \pico/:
\begin{code}
isEmpty :: Vec a n -> Bool
isEmpty VNil        = True
isEmpty (VCons {})  = False
\end{code}
Translated to \pico/, we get the following:
\[
\begin{array}{r@@{\,}c@@{\,}l}
[[&isEmpty]] &:& [[UPI (&&ax :Irrel Type{}), (&&nx :Irrel &Nat{}), (&&vx :Rel &Vec{} &&ax &&nx). &Bool{}]] \\
[[&isEmpty]] &=& [[\ ]] [[(&&ax :Irrel Type{}), (&&nx :Irrel &Nat{}), (&&vx :Rel &Vec{} &&ax &&nx)]]. \\
&& [[case_&Bool{} &&vx of blank]] \\
&& \quad
\begin{array}{l@@{\,}l}
 [[&VNil]] &[[->]] [[\ (c : &&nx [&Nat{}]~[&Nat{}] #0{}), (c0 : &&vx [&Vec{} &&ax &&nx]~[&Vec{} &&ax &&nx] &VNil{&&ax,&&nx} c). &True{}]] \\
 [[&VCons]] &[[->]]
\begin{array}[t]{@@{}l@@{}l}
 [[\ ]] & [[ (&&mx :Irrel &Nat{}), (c : &&nx [&Nat{}]~[&Nat{}] &Succ{} &&mx), (&&xx :Rel &&ax), (&&xsx :Rel &Vec{} &&ax &&mx)]], \\
& [[ (c0 : &&vx [&Vec{} &&ax &&nx]~[&Vec{} &&ax &&nx] &VCons{&&ax,&&nx} &&mx c &&xx &&xsx)]]. \\
\multicolumn{2}{@@{}l}{[[ &False{}]]}
\end{array}
\end{array}
\end{array}
\]
The most striking feature about this \pico/ code is the form of the \ottkw{case}
expression. Unlike the concrete syntax of Haskell, patterns in \pico/ do not
directly bind any arguments. Note that there are no variable bindings to the left
of the arrows in the case-branches. Instead, I have chosen to have $\lambda$s
to the right of the arrow. This design choice greatly simplifies the typing
and scoping
rules for pattern matches, because it removes a binding site in the grammar
(leaving us with two: $[[PI]]$ and $[[\ ]]$). Because of the typing rule
for \ottkw{case} expressions (\pref{sec:pico-case}),
we still must bind all of the existentials
of a data constructor when matching against it---even when these existentials
are ignored, as we see here.

The matches also bind a variable not mentioned in the data constructors'
existentials: the coercion variable $[[c0]]$. This coercion witnesses the
equality between the scrutinee ($[[&&vx]]$, in this case) and the applied
data constructor that introduces the case-branch. This coercion variable
is bound in all matches, meaning that all pattern matching in \pico/
is dependent pattern matching.\footnote{Contrast to Gundry \citep{gundry-thesis},
which has two separate constructs, \ottkw{case} and \ottkw{dcase}, only
the latter of which does dependent matching.}

\subsection{|replicate|}
Let's now look at |replicate|, one of the simplest functions that requires
a proper $[[PI]]$-type. First, in Haskell: \rae{Should this be colored?}
%
\begin{spec}
replicate :: pi n -> a -> Vec a n
replicate Zero      _ = VNil
replicate (Succ m)  x = VCons x (replicate m x)
\end{spec}

%if style == newcode
\begin{code}
$(genSingletons [''Nat])

replicate :: Sing n -> a -> Vec a n
replicate SZero _ = VNil
replicate (SSucc m) x = VCons x (replicate m x)
\end{code}
%endif

\noindent
Now, in \pico/:
\[
\begin{array}{r@@{\,}c@@{\,}l}
[[&replicate]] &:& [[UPI (&&ax :Irrel Type{}), (&&nx :Rel &Nat{}), (&&xx :Rel &&ax). &Vec{} &&ax &&nx]] \\
[[&replicate]] &=& [[\ ]] [[&&ax :Irrel Type{}]]. \\
&&
\begin{array}{l@@{\,}l@@{}l}
\ottkw{fix} & [[\ ]] & [[(&&rx :Rel UPI (&&nx :Rel &Nat{}), (&&xx :Rel &&ax). &Vec{} &&ax &&nx)]], \\
&& [[(&&nx :Rel &Nat{}), (&&xx :Rel &&ax)]]. \\
& \multicolumn{2}{@@{\,}l}{%
\begin{array}{l}
[[case_{{&Vec{} &&ax &&nx}} &&nx of blank]] \\
\quad \begin{array}{l@@{\,}l}
[[&Zero]] &[[->]] [[\ c0 : &&nx [&Nat{}]~[&Nat{}] &Zero{}. &VNil{&&ax,&&nx} c0]] \\
[[&Succ]] &[[->]] [[\ &&mx :Rel &Nat{}, c0 : &&nx [&Nat{}]~[&Nat{}] &Succ{} &&mx. &VCons{&&ax,&&nx} {&&mx} c0 &&xx (&&rx &&mx &&xx)]]
\end{array}
\end{array}}
\end{array}
\end{array}
\]

This example shows the (standard) use of \ottkw{fix} as well as some of the
more exotic features of \pico/. In the case-branches, we see how we pass
universal arguments to the data constructors |VNil| and |VCons|. We also
see how we have to wrap irrelevant arguments (the $[[{&&mx}]]$ in the last
line) in braces. This example also shows where the coercion variable
$[[c0]]$ comes into play: it's needed to provide the coercion to the
|VNil| and |VCons| constructors to prove that the universal argument
$[[&&nx]]$ is indeed of the shape required for these constructors.
Without the ability to do a dependent pattern match, this example would
be impossible to write.\footnote{Unless you fake dependent types using
singletons or some other technique.}

\subsection{|append|}
We'll now examine how to append two vectors. This operation will also
require the use of an addition operation, defined using prefix notation
so as not to provide a parsing challenge: \rae{color?}
%
\begin{spec}
plus :: Nat -> Nat -> Nat
plus Zero      n = n
plus (Succ m)  n = Succ (plus m n)

append :: Vec a m -> Vec a n -> Vec a (!plus m n)
append VNil          ys = ys
append (VCons x xs)  ys = VCons x (append xs ys)
\end{spec}

%if style == newcode
\begin{code}
$(singletons [d|
  plus :: Nat -> Nat -> Nat
  plus Zero      n = n
  plus (Succ m)  n = Succ (plus m n)
  |])

append :: Vec a m -> Vec a n -> Vec a (Plus m n)
append VNil ys = ys
append (VCons x xs) ys = VCons x (append xs ys)
\end{code}
%endif  

\begin{comment}
plus : pi (m : Nat) (n : Nat). Nat
plus = \ m n.
       case_Nat m of
         Zero -> \ c0 . n
         Succ -> \ m' c0 . Succ (plus m' n)

append : pi (a : Type) (m : Nat) (n : Nat) (xs : Vec a m) (ys : Vec a n).
            Vec a (plus m n)
append = \ a.
         fix \ (app : pi (m : Nat) (n : Nat) (xs : Vec a m) (ys : Vec a n).
                      Vec a (plus m n))
               (m : Nat) (n : Nat) (xs : Vec a m) (ys : Vec a n).
             case_(Vec a (plus m n)) xs of
               VNil -> \ (c : m ~ Zero) c0.
                       let c1 := <plus> c <n> in
                       let c2 := step^k (plus 0 n) in
                       ys ||> sym (<Vec> <a> (c1 ;; c2))
               VCons -> \ (m' : Nat) (c : m ~ Succ m') (x : a) (xs' : Vec a m')
                          (c0 : xs ~ VCons {m'} c x xs').
                        let c1 := <plus> c <n> in
                        let c2 := step^k (plus (Succ m') n) in
                        VCons{a,plus m n} {plus m' n} (c1 ;; c2) x (app m' n xs' ys)

g : plus m n ~ n
g = g1 ;; g2

g1 : plus m n ~ plus 0 n
g1 = <plus> c <n>

g2 : plus 0 n ~ n

step (plus 0 n) : plus 0 n ~ 

g3 : plus m n ~ Succ (plus m' n)
g3 = g4 ;; g5

g4 : plus m n ~ plus (Succ m') n
g4 = <plus> c <n>

g5 : plus (Succ m') n ~ Succ (plus m' n)
g5 = step^k' plus (Succ m') n
\end{comment}

\noindent And in \pico/ (where I elide the uninteresting |plus| for
brevity):
\[
\begin{array}{r@@{\,}c@@{\,}l@@{}}
[[&append]] &:& 
\begin{array}[t]{@@{}l@@{}l@@{}}
[[UPI]] & [[(&&ax :Irrel Type{}), (&&mx :Irrel &Nat{}), (&&nx :Irrel &Nat{}), (&&xsx :Rel &Vec{} &&ax &&mx), (&&ysx :Rel &Vec{} &&ax &&nx)]].\\
& [[&Vec{} &&ax (&plus &&mx &&nx)]]
\end{array} \\
[[&append]] &=&
\begin{array}[t]{@@{}l@@{}l@@{}}
[[\ ]] & [[(&&ax :Irrel Type{})]]. \\
& \ottkw{fix}\,
\begin{array}[t]{@@{}l@@{}l@@{}}
[[\ ]] & ([[&app]] [[:Rel]]
\begin{array}[t]{@@{}l@@{}l@@{}}
[[ UPI]] & [[ (&&mx :Irrel &Nat{}), (&&nx :Irrel &Nat{}), (&&xsx :Rel &Vec{} &&ax &&mx), (&&ysx :Rel &Vec{} &&ax &&nx)]]. \\
& [[ &Vec{} &&ax (&plus &&mx &&nx) ]]),
\end{array} \\
& [[(&&mx :Irrel &Nat{}), (&&nx :Irrel &Nat{}), (&&xsx :Rel &Vec{} &&ax &&mx), (&&ysx :Rel &Vec{} &&ax &&nx)]]. \\
\multicolumn{2}{@@{}l@@{}}{
[[case_{{&Vec{} &&ax (&plus &&mx &&nx)}} &&xsx of blank]]} \\
\multicolumn{2}{@@{}l@@{}}{
\quad \begin{array}{l@@{\,}c@@{\,}l@@{}}
[[&VNil]] &[[->]]& [[\ ]] [[(c : &&mx [&Nat{}]~[&Nat{}] &Zero{}), (c0 : &&xsx [&Vec{} &&ax &&mx]~[&Vec{} &&ax &&mx] &VNil{&&ax,&&mx} c)]]. \\
&& [[let c1 := <&plus> c <&&nx> in blank]] \\
&& [[let c2 := step^j (&plus &Zero{} &&nx) in blank]] \\
&& [[&&ysx |> sym (&Vec{} <&&ax> (c1 ;; c2))]] \\
[[&VCons]] &[[->]]& [[\ ]]
\begin{array}[t]{@@{}l@@{}}
 [[(&&m'x :Irrel &Nat{}), (c : &&mx [&Nat{}]~[&Nat{}] &Succ{} &&m'x), (&&xx :Rel &&ax), (&&xs'x :Rel &Vec{} &&ax &&m'x)]] \\
[[(c0 : &&xsx [&Vec{} &&ax &&mx]~[&Vec{} &&ax &&mx] &VCons{&&ax,&&mx} {&&m'x} c &&xx &&xs'x)]].
\end{array}\\
&& [[let c1 := <&plus> c <&&nx> in blank]] \\
&& [[let c2 := step^kk (&plus (&Succ{} &&m'x) &&nx) in blank]] \\
&& [[&VCons{&&ax, &plus &&mx &&nx} {&plus &&m'x &&nx} (c1 ;; c2) &&xx (&app {&&m'x} {&&nx} &&xs'x &&ysx)]]
\end{array}}
\end{array}
\end{array}
\end{array}
\]

This is the first example where we are required to write non-trivial
coercions. Let's start by considering the right-hand side of the
|VNil| case. As we see in the Haskell version, we wish to return |ys|.
However, |ys| has type |Vec a n|, and we need to return something of
type |Vec a (plus m n)|. We must, accordingly, cast |ys| to have type
|Vec a (plus m n)|. This is what the coercion $[[sym (&Vec{} <&&ax> (c1 ;; c2))]]$
is doing; it proves that |Vec a n| is in fact equal to |Vec a (plus m n)|.
Both the starting type |Vec a n| and the ending type |Vec a (plus m n)| have
the same prefix of |Vec a|. We use a congruence coercion
(\pref{sec:congruence-coercions}) $[[&Vec{} <&&ax> g]]$ to simplify our
problem. Now, we need only a coercion
$[[g]]$ that proves |plus m n| equals |n|.
(The use of \ottkw{sym} helpfully has reversed our proof obligation.)
This $[[g]]$ is built in two steps, tied together by using our transitivity
operator $[[;;]]$: $[[c1]]$, which uses our reflexivity operator
$\langle \cdot \rangle$, proves that |plus m n| equals |plus 0 n|
by using $[[c]]$, the GADT equality constraint from the |VNil| constructor;
and $[[c2]]$ proves that |plus 0 n| equals |n|.\footnote{Recall (\pref{fig:pico-notation}) that \ottkw{let} is defined by simple expansion. It is not
properly a language construct but instead is just a convenient abbreviation
in this writeup.} For this last coercion,
we use the \ottkw{step} coercion that reduces a type by one step. It is
fiddly (and unenlightening) to calculate the precise number of steps
necessary to get from |plus 0 n| to |n|, so I have just written that this
takes $j$ steps. It is straightforward to calculate $j$ in practice.

The coercion manipulations in the |VCons| case are similar.

Also of note in this example is the interplay between relevant variables
and irrelevant ones. We see that the lengths |m| and |n| are irrelevant
throughout this function. Indeed, we do not need lengths at runtime
to append two vectors. Accordingly, we can see that all uses of |m| and
|n| (or |m'|) occur in irrelevant contexts, such as coercions or
irrelevant arguments to functions.

\subsection{|safeHead|}
\label{sec:pico-example-absurd}

With length-indexed vectors, we can write a safe |head| operation, allowed
only when we know that the vector has a non-zero length:
%
\begin{code}
safeHead :: Vec a (!Succ n) -> a
safeHead (VCons x _) = x
\end{code}
%
Note that |safeHead| contains a total pattern match; the |VNil| alternative
is impossible given the type signature of the function.
This function translates to \pico/ thusly:
\[
\begin{array}{r@@{\,}c@@{\,}l@@{}}
[[&safeHead]] &:& [[UPI (&&ax :Irrel Type{}), (&&nx :Irrel &Nat{}), (&&vx :Rel &Vec{} &&ax (&Succ{} &&nx)). &&ax]] \\
[[&safeHead]] &=& [[\ ]] [[(&&ax :Irrel Type{}), (&&nx :Irrel &Nat{}), (&&vx :Rel &Vec{} &&ax (&Succ{} &&nx))]]. \\
&& [[case_&&ax &&vx of blank]] \\
&& \quad
\begin{array}{@@{}l@@{\,}l}
[[&VNil]] &[[->]] [[\ (c : &Succ{} &&nx [&Nat{}]~[&Nat{}] &Zero{}), (c0 : &&vx [&Vec{} &&ax (&Succ{} &&nx)]~[&Vec{} &&ax (&Succ{} &&nx)] &VNil{a,&Succ{} &&nx} c). absurd c &&ax]] \\
[[&VCons]] &[[->]] 
\begin{array}[t]{@@{}l@@{}l}
[[\ ]] & [[(&&mx :Irrel &Nat{}), (c : &Succ{} &&nx [&Nat{}]~[&Nat{}] &Succ{} &&mx), (&&xx :Rel &&ax), (&&xsx :Rel &Vec{} &&ax &&mx)]], \\
& [[(c0 : &&vx [&Vec{} &&ax (&Succ{} &&nx)]~[&Vec{} &&ax (&Succ{} &&nx)] &VCons{&&ax, &Succ{} &&nx} {&&mx} c &&xx &&xsx)]]. \\
\multicolumn{2}{@@{}l}{[[ &&xx]]}
\end{array}
\end{array}
\end{array}
\]

The new feature demonstrated in this example is the \ottkw{absurd} operator,
which appears in the body of the |VNil| case.
In order to be sure that \ottkw{case} expressions do not get stuck,
the typing rules
require that all matches are exhaustive. However, in general, in can be
undecidable to determine whether the type of a scrutinee indicates that
a certain constructor can be excluded. In order to step around this
potential trap, \pico/ supports absurdity elmination through \ottkw{absurd}.
The coercion passed into \ottkw{absurd} ($[[c]]$, above) must prove that
one constant equals another. This is, of course, impossible, and so we
allow $[[absurd g t]]$ to have any type $[[t]]$.

\section{Types $[[t]]$}

Having gone through several examples explaining the flavor of \pico/ code,
let's now walk through the remaining typing rules of the system.
Recall that we have already seen the typing rules for variables,
\rul{Ty\_Var} in \pref{sec:ty-var}, and constants, \rul{Ty\_Con} in
\pref{sec:ty-con}.

\subsection{Abstractions}

The definition for types $[[t]]$ includes the usual productions for a pure
type system, including both a $[[PI]]$-form and a $[[\ ]]$-form:
\begin{gather*}
\ottdruleTyXXPi{}\\
\ottdruleTyXXLam{}
\end{gather*}
%
The only novel component of these rules is the use of $[[Rel(G)]]$ in the
premise to \rul{Ty\_Pi}. Resetting the context here is appropriate because
we still wish to use irrelevant variables in types. As an example, the
use of $[[Rel(G)]]$ here is necessary to allow
the type of Haskell's |undefined|: $[[UPI a:Irrel Type{}. a]]$.

\subsection{Applications}

Terms with a $[[PI]]$-type (either type constants or $[[\ ]]$-terms)
can be applied to arguments, via these rules:
\begin{gather*}
\ottdruleTyXXAppRel{}\\
\ottdruleTyXXAppIrrel{}\\
\ottdruleTyXXCApp{}
\end{gather*}
%
We see in these rules that the argument form for an abstraction over an
irrelevant binder requires braces. (See the conclusion of \rul{Ty\_AppIrrel}.)
The system would remain syntax-directed without marking off irrelevant
arguments, but type erasure (\pref{sec:type-erasure}) would then need to
be type-directed. It seems easier just to separate relevant arguments
from irrelevant arguments syntactically.

Note also the use of $[[Rel(G)]]$ in \rul{Ty\_AppIrrel} and \rul{Ty\_CApp};
resetting the context here happens because irrelevant arguments and coercions
are erased in the running program.

\subsection{Kind casts}

We can always use an equality to change the kind of a type:
\[
\ottdruleTyXXCast{}
\]
In this rule, a type of kind $[[k1]]$ is cast by $[[g]]$ to have a type
$[[k2]]$. As always, the coercion is checked in a reset context $[[Rel(G)]]$.
The final premise, $[[S;Rel(G) |-ty k2 : Type{}]]$ is implied by
the first premise (which is actually
$[[S;Rel(G) |-co g : k1 (Type{})~(Type{}) k2]]$) via proposition regularity
(\pref{sec:prop-reg}), but we must include it in order to prove
kind regularity (\pref{sec:kind-reg}) before we prove coercion regularity.

\subsection{\ottkw{fix}}

\Pico/ supports fixpoints via the following rule:
\[
\ottdruleTyXXFix{}
\]
The rule requires type $[[t]]$ to have an unmatchable $[[UPI]]$ so that
we can be sure that $[[t]]$'s canonical form is indeed a $[[\ ]]$; otherwise
the progress theorem (\pref{sec:progress}) would not hold.

\subsection{\ottkw{case}}
\label{sec:pico-case}

Unsurprisingly, the typing rules to support pattern matching are the most
involved, presented here with the rules to type-check \ottkw{case}
branches:
\[
\ottdruleTyXXCase{}
\]
\ottdefnAlt{}

Most of the premises of \rul{Ty\_Case} are easy enough to explain:
\begin{itemize}
\item The result kind of a \ottkw{case}, $[[k]]$ is given right in the
syntax; the first premise $[[S;Rel(G) |-ty k : Type{}]]$ ensures that
it is a valid result kind.
\item We also must check the kind of the scrutinee, $[[t]]$. This kind
must have the form $[[MPI D. H{} ss]]$ (note the matchable $[[MPI]]$),
where the $[[ss]]$ cannot mention any of the variables bound in $[[D]]$.
(The $[[S;Rel(G) |-ty H{} ss : Type{}]]$ premise checks this scoping
condition.) Note that the scrutinee's type may be a $[[MPI]]$-type
in order to support matching against partially applied type and data
constructors.
\item The alternatives must be exhaustive and distinct. Exhaustivity
is needed to prove that a well-typed \ottkw{case} cannot get stuck,
and distinctness is necessary to prove that the reduction relation is
deterministic.
\end{itemize}

We are left to consider type-checking the alternatives. This is done
via the judgment with schema $[[S;G;s;t |-alt alt : k]]$. When 
$[[S;G;s;t |-alt alt : k]]$ holds, we know that the expression in the
case alternative $[[alt]]$ produces a type of kind $[[k]]$ when 
considered with signature $[[S]]$ and typing context $[[G]]$ and when
matched against a scrutinee $[[t]]$ of type $[[s]]$. The premises
of \rul{Ty\_Case} indeed check that all alternatives satisfy this
judgment.

\subsubsection{Checking \ottkw{case} alternatives}

The rule \rul{Alt\_Match} is intricate. This rule assumes we have
a scrutinee $[[t0]]$ of type $[[MPI D'. H'{} ss]]$, and we are checking
a case alternative $[[H -> t]]$.

First, we must verify that the constant $[[H]]$ is classified by $[[H']]$---that
is, either $[[H]]$ is a data constructor of the datatype $[[H']]$ or
$[[H]]$ is a datatype and $[[H']]$ is $[[Type]]$. We say that $[[H']]$ is
the \emph{parent} of $[[H]]$. This check is done by the
$[[S |-tc H : D1;D2;H']]$ premise, which also extracts the
universals $[[D1]]$ and existentials $[[D2]]$.

The next premise (reading
to the right) uses $[[D2[ss/dom(D1)] ]]$ to instantiate
the existentials with the known choices for
the universals. These known choices $[[ss]]$ are obtained from
determining the type of the scrutinee; see the appearance of
$[[ss]]$ in the type appearing before the $[[|-alt]]$ in the
conclusion of the rule. The second premise also splits the
instantiated existentials into two telescopes, $[[D3]]$ and $[[D4]]$.

Note that $[[D']]$ is an input to this rule; it is extracted from
the type of the scrutinee.
Accordingly, the third premise $[[dom(D4) = dom(D')]]$ serves two roles:
it fixes
the length of $[[D4]]$ (and, hence, $[[D3]]$) and it also forces any
renaming of bound variables necessary to line up the telescopes $[[D']]$
and $[[D4]]$. Keeping the names of the bound variables consistent between
these telescopes simplifies this rule. Note that, in the event that the
scrutinee is a fully-saturated datatype or data constructor,
$[[D4 = D']] = [[empty]]$ and $[[D3 = D2[ss/dom(D1)] ]]$.

The next premise uses a unification algorithm to make sure that the bound
telescope in the scrutinee's type, $[[D']]$, matches the expected shape
$[[D4]]$. We will return to this in \pref{sec:alt-match-matching}, below.
In the common case of $[[D' = empty]]$ (that is, full saturation of
the scrutinee), this premise is trivially satisfied. Also note that we do
not use the output of this premise, $[[theta]]$, anywhere in the rule, so
skipping it on a first reading is appropriate.

Lastly, we must check that the body of the alternative, $[[t]]$, has the
right type. This type must bind (by any combination of matchable $[[MPI]]$
and unmatchable $[[UPI]]$) all of the existentials in $[[D3]]$, as well
as the coercion variable witnessing the equality between $[[t0]]$ (the
scrutinee) and the applied $[[H]]$. In this rule the use of
$[[dom(D3)]]$ as a list of arguments to $[[H{ss}]]$ is a small pun;
we must imagine braces surrounding any variable in $[[dom(D3)]]$ that is
irrelevantly bound. The return type of the abstraction in $[[t]]$ must
be $[[k]]$, the result kind of the overall match.

For examples of this in action---at least in the fully saturated case---see
the worked out examples above (\pref{sec:pico-examples}).

\subsubsection{Unification in \rul{Alt\_Match}}
\label{sec:alt-match-matching}
\label{sec:example-using-kind-co}

Let's examine the use of unification in \rul{Alt\_Match} more carefully.
We will proceed by examining two examples, a simple one where unification
is unnecessary and a more involved one showing why we need this.

Our first example was given above, when first describing unsaturated matching
(\pref{sec:unsaturated-match-example}):
%{
%if style == newcode
%format IsLeft = "IsLeft2"
%endif
\begin{code}
type family IsLeft x where
  IsLeft !Left   = !True
  IsLeft !Right  = !False
\end{code}
%}
The translation of |Either| into \pico/ appears in \pref{sec:pico-either}.
This type family translated into the following \pico/ function (rewritten
to be lowercase according to Haskell naming requirements):
\[
\begin{array}{r@@{\,}c@@{\,}l}
[[&isLeft]] &:& [[UPI (&&ax :Irrel Type{}), (&&xx :Rel MPI (&&yx :Rel &&ax). &Either{} &&ax &&ax). &Bool{}]] \\
[[&isLeft]] &=& [[\ ]] [[(&&ax :Irrel Type{}), (&&xx :Rel MPI (&&yx :Rel &&ax). &Either{} &&ax &&ax)]] . \\
&& [[case_&Bool{} &&xx of blank]] \\
&& \quad
\begin{array}{l@@{\,}l}
[[&Left]] &[[->]] [[\ (c0 : &&xx [MPI (&&yx :Rel &&ax). &Either{} &&ax &&ax]~[MPI (&&yx :Rel &&ax). &Either{} &&ax &&ax] &Left{&&ax,&&ax}). &True{}]] \\
[[&Right]] &[[->]] [[\ (c0 : &&xx [MPI (&&yx :Rel &&ax). &Either{} &&ax &&ax]~[MPI (&&yx :Rel &&ax). &Either{} &&ax &&ax] &Right{&&ax,&&ax}). &False{}]]
\end{array}
\end{array}
\]
Comparing the first alternative against \rul{Alt\_Match}, we see the following
concrete instantiations of metavariables:
\[
\begin{array}{c@@{\quad}c}
\begin{array}{r@@{\,}l}
[[H &= &Left]] \\
[[D1 &= &&sx :Irrel Type{}, &&tx :Irrel Type{}]] \\
[[D2 &= &&yx :Rel &&sx]] \\
[[H' &= &Either]] \\
[[t0 &= &&xx]] \\
[[D' &= &&yx :Rel &&ax]]
\end{array}
&
\begin{array}{r@@{\,}l}
[[ss &= &&ax, &&ax]] \\
[[D3 &= empty]] \\
[[D4 &= &&yx :Rel &&ax]] \\
[[theta &= empty]] \\
[[t &= \ (c0 : &&xx [MPI (&&yx :Rel &&ax). &Either{} &&ax &&ax]~[MPI (&&yx :Rel &&ax). &Either{} &&ax &&ax] &Left{&&ax,&&ax}). &True{}]] \\
[[k &= &Bool{}]]
\end{array}
\end{array}
\]

In this example, the constructor is not applied to any existential variables, and
so $[[D3]]$, the telescope of binders that are to be bound by the match, is empty.
The only variable bound in the match body is the $[[c0]]$ dependent-match coercion
variable. Also note that $[[D4]]$, the instantiated suffix of the telescope of
existential arguments to |Left|, and $[[D']]$, the telescope of binders in the type
of the scrutinee, coincide. Accordingly, the match operation succeeds with an empty
substitution $[[theta = empty]]$.

In contrast, the following example shows why we need unification in \rul{Alt\_Match}:
\begin{code}
data X where
  MkX :: a -> a -> X
    -- NB: |a| is existential; no universals here

type family UnX x :: Bool where
  UnX (!MkX y) = y
\end{code}

\noindent Note that we're extracting the first (visible) argument from
an unsaturated use of |MkX|. This Haskell code translates to the following \pico/:
\[
\begin{array}{@@{}l@@{}}
\begin{array}{r@@{\,}l}
[[S]] =
& [[&X : (empty)]], \\
& [[&MkX : (&&ax :Irrel Type{}, &&yx :Rel &&ax, &&zx :Rel &&ax; &X)]]
\end{array}
\\[4ex]
\begin{array}{r@@{\,}c@@{\,}l}
[[&unX]] &:& [[UPI (&&xx :Rel MPI (&&zx :Rel &Bool{}). &X{}). &Bool{}]] \\
[[&unX]] &=& [[\ ]] [[(&&xx :Rel MPI (&&zx :Rel &Bool{}). &X{})]] . \\
&& [[case_&Bool{} &&xx of blank]] \\
&& \quad
[[&MkX]] [[->]]
\begin{array}[t]{@@{}l}
[[ \ ]] [[(&&ax :Irrel Type{}), (&&yz :Rel &&ax), (c0 : &&xx (MPI (&&zx :Rel &Bool{}). &X{})~(MPI (&&zx :Rel &&ax). &X{}) &MkX{} &&ax &&yz)]]. \\
[[&&yx |> sym (argk (kind c0))]]
\end{array}
\end{array}
\end{array}
\]
Before we get into the minutiae of \rul{Alt\_Match}, let's dwell a moment
on the cast necessary in the last line. According to both the type of
|unX| and the return type provided in the \ottkw{case}, the match must return
something of type |Bool|. Yet the body of a match must bind precisely the
existential variables of a data constructor; according to the definition of
|MkX|, the variable |y| has type |a|, not |Bool|. We thus must cast |y| from
|a| to |Bool|. We do this by extracting out the right coercion from $[[c0]]$.
This $[[c0]]$ is heterogeneous; I have typeset the code above with the kinds
explicit to show this. The left-hand kind is the declared type of |x|, binding
|z| of type |Bool|. The right-hand kind is the kind of |MkX a y|, which binds
|z| of type |a|. By using \ottkw{kind} (which extracts a kind equality from
a heterogeneous coercion; see \pref{sec:pico-kind-coercion}), followed by
\ottkw{argk} (which extracts a coercion between the kinds of the arguments
of $\Pi$-types; see \pref{sec:pico-argk-coercion}), and then \ottkw{sym} (which
reverses the orientation of a coercion), we get the coercion needed, of
type $[[&&ax [Type{}]~[Type{}] &Bool{}]]$.

Now, we'll try to understand the matching in \rul{Alt\_Match}. Let's once
again examine the concrete instantiations of the metavariables in
the rule:
\[
\begin{array}{c@@{\quad}c}
\begin{array}{r@@{\,}l}
[[H &= &MkX]] \\
[[D1 &= empty]] \\
[[D2 &= &&ax :Irrel Type{}, &&yx :Rel &&ax, &&zx :Rel &&ax]] \\
[[H' &= &X]] \\
[[t0 &= &&xx]] \\
[[D' &= &&zx :Rel &Bool{} ]]
\end{array}
&
\begin{array}{r@@{\,}l}
[[ss &= empty]] \\
[[D3 &= &&ax :Irrel Type{}, &&yx :Rel &&ax]] \\
[[D4 &= &&zx :Rel &&ax]] \\
[[theta &= &Bool{}/&&ax]] \\
[[t]] &= \langle \text{as above} \rangle \\
[[k &= &Bool{}]]
\end{array}
\end{array}
\]
Recall that $[[D3]]$ and $[[D4]]$ are the prefix and suffix, respectively,
of the telescope of existentials $[[D2]]$, after this telescope has been
instantiated with the known arguments for the universals. However, with |MkX|,
there are no universals at all (the datatype |X| takes no arguments), and
so this instantiation is a no-op. (The lack of universals shows up in the
equations above via an empty $[[D1]]$ and an empty $[[ss]]$.)
We thus have $[[D3,D4 = D2]]$, where the length of $[[D4]]$ must match
the length of $[[D']]$, the telescope of variable bound in the type
of the scrutinee. We see that the scrutinee $[[&&xx]]$ has type
$[[MPI (&&zx :Rel &Bool{}). &X{}]]$ and so $[[D' = &&zx :Rel &Bool{}]]$.
Thus $[[D3]]$---the existentials bound by the pattern match---has two
elements (|a| and |y|) and $[[D4]]$ has one (|z|).

We now must make sure that the shape of the types in $[[D']]$ match the
template given by the types in $[[D4]]$. That is, $[[D']]$ must be some
instance of $[[D4]]$, as determined by a unification algorithm
(discussed in more depth in \pref{sec:unification}). In this case,
the unification succeeds, assigning the type variable |a| to be |Bool|,
as shown in the choice for $[[theta]]$, above. Accordingly, the match
is well-typed.

Requiring this unification simply reduces the set of well-typed programs. It
is thus important to understand why the restriction is necessary. What goes
wrong if we omit it? The problem comes up in the proof for progress, in the
case where the scrutinee has a top-level cast. We will use step rule
\rul{S\_KPush} (see \pref{sec:pico-kpush}); that rule has several typing
premises\footnote{These unexpected typing premises to a small-step reduction
  rule are addressed in \pref{sec:typing-premises-in-reduction}.} which can
be satisfied only when this match succeeds. The restriction is
quite technical in nature, but any alternative not ruled out by the type
of the scrutinee should be acceptable. See the proof of progress in
\pref{app:progress-proof} for the precise details.

\subsubsection{Default alternatives}

\Pico/ supports \emph{default alternatives} through the form
$[[_ -> t]]$. This is a catchall case, to be used only when no
other case matches. In a language with a simpler treatment for
\ottkw{case} statements, a default would be unnecessary; every 
\ottkw{case} could simply enumerate all possible constructors.
However, \pico/ has two features that makes defaults indispensable:
\begin{itemize}
\item When matching on a scrutinee of kind $[[Type]]$ (or, say,
a function returning a $[[Type]]$), it would be 
impossible to enumerate all possibilities of this open type. Such
matches must have a default alternative.
\item If a scrutinee is partially applied, the typing rules dictate
a delicate unification process to make sure alternatives are well-typed.
(See \pref{sec:alt-match-matching}.) Given the design of \rul{Alt\_Match},
it is possible some of the constructors of a datatype would be ill-typed
as patterns in an unsaturated match. It might therefore be challenging to
detect whether an unsaturated match is exhaustive. To avoid this problem,
unsaturated matches may use a default alternative in order to be
unimpeachably exhaustive.
\end{itemize}

Happily, the typing rule \rul{Alt\_Default} for default alternatives
could hardly be simpler.

\subsubsection{Absurdity}

We saw in |safeHead| example (\pref{sec:pico-example-absurd}) the need
for absurdity elimination via the \ottkw{absurd} operator. Here is the
typing rule:
\[
\ottdruleTyXXAbsurd{}
\]
This rule requires that the coercion argument to \ottkw{absurd},
$[[g]]$, relate two unequal type constants $[[H1]]$ and $[[H2]]$.
The type $[[absurd g t]]$ can have any well-formed kind,
as chosen by $[[t]]$. Because $[[t]]$ is needed only to choose
the overall kind of the type, it is checked a context reset by
$[[Rel]]$.

As explained with the example, absurdity eliminiation is sometimes
needed in the
body of case alternatives that can never be reached.

\section{Operational semantics}

Now that we have seen the static semantics of types, we are well-placed
to explore their dynamic semantics---how the types can reduce to values.
The dynamic semantics of types is expressed in \pico/ via a small-step
operational semantics, captured in the judgment
$[[S;G |-s t --> t']]$. Rules in this judgment are prefixed by
``\rul{S\_}''. It must be parameterized over typing environment because
of the push rules, as explained in \pref{sec:push-rules}.

The operational semantics obeys preservation and
progress theorems.

\begin{theorem*}[Preservation (\pref{thm:preservation})]
If $[[S;G |-ty t : k]]$ and $[[S;G |-s t --> t']]$, then
$[[S;G |-ty t' : k]]$.
\end{theorem*}

\begin{theorem*}[Progress (\pref{thm:progress})]
Assume $[[G]]$ has only irrelevant variable bindings.
If $[[S;G |-ty t : k]]$, then either $[[t]]$ is a value $[[v]]$, $[[t]]$
is a coerced value $[[v |> g]]$, or there exists $[[t']]$ such that
$[[S;G |-s t --> t']]$.
\end{theorem*}

The progress theorem is non-standard in two different ways:
\begin{itemize}
\item As discussed shortly (\pref{sec:reduction-under-irrel-abs}),
reduction can take place in a context with irrelevant variable
bindings.
\item The progress theorem guarantees that a stuck type is \emph{either}
a value $[[v]]$ or a coerced value $[[v |> g]]$. This statement of
the theorem follows previous work (such as \citet{nokinds}) and is
applicable in the right spot in the proof of type erasure
(\pref{sec:type-erasure}).
\end{itemize}

The operational semantics are also deterministic.

\begin{lemma*}[Determinacy (\pref{lem:determinacy})]
If $[[S;G |-s t --> s1]]$ and $[[S;G |-s t --> s2]]$, then
$[[s1 = s2]]$.
\end{lemma*}

\subsection{Values}
\label{sec:evaluation-under-irrel-abs}
A subset of the types $[[t]]$ are considered values, written with the
metavariable $[[v]]$:

\begin{definition*}[Values]
Let values $[[v]]$ be defined by the following subgrammar of $[[t]]$:
\[
[[v]] \bnfeq [[H{ts} ps]] \bnfor [[PI d. t]] \bnfor [[\a:Rel k. t]]
                          \bnfor [[\a:Irrel k. v]] \bnfor [[\c:phi.t]]
\]
\end{definition*}
As we can see, values include applied constants, $\Pi$-types, and some
$\lambda$-types. However, note a subtle but important part of this definition:
the production for irrelevant abstractions is recursive. An irrelevant
abstraction $[[\a:Irrel k.t]]$ is a value if and only if $[[t]]$, the body,
is also a value. This choice is important in order to prove type erasure.

During compilation, we wish to erase irrelevant components of an expression
completely. This includes irrelevant abstractions. Thus, the erasure operation,
written $[[ ||.|| ]]$ and further explored in \pref{sec:type-erasure},
includes this equation,
\[
[[ ||\a:Irrel k.t|| = ||t|| ]],
\]
erasing the abstraction entirely. 
Yet we must make sure to maintain the following lemma, referring to the
definition of values on erased expressions:

\begin{lemma*}[Expression redexes (\pref{lem:expr-redex})]
If $[[||t||]]$ is not an expression value, then $[[t]]$ is not a type
value.
\end{lemma*}

If we erase irrelevant abstractions but call all irrelevant abstractions
type values, then this lemma becomes false. We thus have a recursive
definition of values for irrelevant abstractions and, accordingly,
evaluate under irrelevant abstractions as well. See rule
\rul{S\_IrrelAbs\_Cong} in \pref{sec:step-congruence}.

\subsection{Reduction}

Several of the small-step rules perform actual reduction in a type:
\begin{gather*}
\ottdruleSXXBetaRel{}\\
\ottdruleSXXBetaIrrel{}\\
\ottdruleSXXCBeta{}\\
\ottdruleSXXMatch{}\\
\ottdruleSXXDefault{}\\
\ottdruleSXXDefaultCo{}\\
\ottdruleSXXUnroll{}
\end{gather*}
Note that \rul{S\_BetaIrrel} requires a value $[[v1]]$ in the body
of the abstraction in order to keep the rules deterministic. The only
other surprising feature in these rules is the way that \rul{S\_Match}
works, by applying the body of the alternative $[[t0]]$ to the actual
existential arguments to $[[H{ts}]]$ and a reflexive coercion. This
follows directly from my design of having \ottkw{case} alternatives
avoid a special binding form and use the existings forms in the language.

\subsection{Congruence forms}
\Pico/ has several uninteresting congruence forms,
\begin{gather*}
\ottdruleSXXAppXXCong{}\\
\ottdruleSXXCastXXCong{}\\
\ottdruleSXXCaseXXCong{}\\
\ottdruleSXXFixXXCong{}
\end{gather*}
and one more unusual one,
\[
\ottdruleSXXIrrelAbsXXCong{}
\]
This last rule allows for evaluation under irrelevant abstractions,
as described in \pref{sec:evaluation-under-irrel-abs}. It must add the
new irrelevant variable to the context, but is otherwise unexceptional.

\subsection{Push rules}

\begin{figure}[p]
\newlength{\pushrulespace}
\setlength{\pushrulespace}{3ex}
\begin{gather*}
\ottdruleSXXTrans{} \\[\pushrulespace]
\ottdruleSXXPushRel{} \\[\pushrulespace]
\ottdruleSXXPushIrrel{} \\[\pushrulespace]
\ottdruleSXXCPush{} \\[\pushrulespace]
\ottdruleSXXAPush{} \\[\pushrulespace]
\ottdruleSXXFPush{} \\[\pushrulespace]
\ottdruleSXXKPush{}
\end{gather*}
\caption{Push rules}
\label{fig:push-rules}
\end{figure}

A system with explicit coercions like \pico/ must deal with the possibility
that coercions get in the way of reduction. For example, what happens when
we try to reduce
\[
[[ ((\ &&xx :Rel &Bool{}. &&xx) |> <&Bool{}>) &True{} ]] \quad ?
\]
Casting by a reflexive coercion should hardly matter, and yet no rule
yet described applies here. In particular, \rul{S\_BetaRel} does not.

To deal with this and similar scenarios, \pico/ follows the System FC
tradition and contains so-called \emph{push rules}, as shown in
\pref{fig:push-rules}. These rules are fiddly
but---ignoring \rul{S\_KPush} for a moment---straightforward. They simply serve to
rephrase a type with a coercion in the ``wrong'' place to an equivalent
type with the coercion moved out of the way. The rules can be derived
simply by following the typing rules and a desire to push the coercion aside.
Compared to previous work, the novelty here is in rules \rul{S\_APush}
(which handles reduction under irrelevant abstractions and must take into
account the awkward substitution in \rul{Co\_PiTy}; see \pref{sec:pico-co-pity})
and \rul{S\_FPush} (which handles \ottkw{fix}, never before seen in System FC),
but these rules again pose no design challenge other than the need for
attention to detail.

Many of the push rules share an odd feature: they have typing judgment
premises. These premises are the reason that the stepping judgment
is parameterized on a typing context. In order to prove the progress
theorem, it is necessary to prove \emph{consistency} (\pref{sec:consistency}),
which basically says that no coercion (made without assumptions) can prove,
say, |Int ~ Bool|. Still ignoring \rul{S\_KPush}, the consistency lemma
is enough to admit the typing premises to the push rules. However,
using consistency here would mean that the preservation theorem depends
on the consistency lemma, while consistency is normally used only to
prove progress. In seems to lead to cleaner proofs to avoid the dependency
of preservation on consistency, and so these typing premises are necessary.

The \rul{S\_KPush} rule is very intricate and makes use of a variety of
coercions. Explicating this rule in its entirety is best saved until after
we have covered coercions in more depth.

\section{Coercions $[[g]]$}

\Pico/ comes with a very rich theory of equality, embodied in the large
number of coercion forms. We will examine these forms in terms of the
properties they imbue on the equality relation. Note that the coercion
language is far from orthogonal; it is often possible to prove one thing
in multiple ways. Indeed, GHC comes with a
\emph{coercion optimizer}~\cite{coercion-optimization} that transforms
a coercion proving a certain proposition into another, simpler one proving
the same proposition. Enhancing this optimizer is beyond the scope of
this dissertation, however. It is needed only has a optimization in the
speed of compilation and is not central to the theory or metatheory of
the language.

All coercions are erased before runtime. (\pref{sec:type-erasure}) Accordingly,
we check for well-typed coercions (via the judgment
$[[S;G |-co g : phi]]$) only in contexts reset by the $[[Rel]](\cdot)$ operator.

\subsection{Equality is heterogeneous}

The equality relation in \pico/ is heterogeneous, allowing |~| to relate
two types of different kinds. This is most clearly demonstrated in the
rule for the well-formedness of propositions:\footnote{This rule is the
entire judgment---there is no other form of proposition supported in
\pico/.} \\

\ottdefnProp{}

\noindent Note that the kinds $[[k1]]$ and $[[k2]]$ are allowed to differ.

The particular flavor of hetergeneous equality in \pico/ is so-called
``John Major'' equality~\cite{jmeq-mcbride-thesis}, where an equality between two
types implies the equality between the kinds:
\[
\ottdruleCoXXKind{}
\]
As we can see, the \ottkw{kind} coercion form extracts a kind coercion
from a type coercion.

It's worth pausing here for a moment to consider two other meanings of
heterogeneous equality:
\paragraph{Zombie equality} \rae{better name?}
The language Zombie~\cite{zombie}, of the Trellys project~\cite{trellys},
supports a heterogeneous equality with no equivalent of the \ottkw{kind}
coercion. That is, if we have a proof of $[[t1 (k1)~(k2) t2]]$, then there
is no way to prove $[[k1 [Type{}]~[Type{}] k2]]$ (absent other information).
Indeed, Zombie equality (that is, omitting the \rul{Co\_Kind} rule) would work
in \pico/; that coercion form is never needed in the metatheory. But it would
weaken \pico/'s equational theory; for example, it seems that the second
example in \pref{sec:example-using-kind-co} would be impossible without
\ottkw{kind}.

\paragraph{Flexible homogeneous equality}
Another possible meaning of heterogeneous equality is that $[[k1]]$ and $[[k2]]$
might not be definitionally equal, but they are provably equal.\footnote{I
am distinguishing here between \emph{definitional} equality and \emph{propositional} equality. The former, in \pico/, refers to $\alpha$-equivalence. Definitional
equality is the equality used implicitly in typing rules when we use the
same metavariable twice. If written explicitly, it is sometimes written
$\equiv$. Propositional equality, on the other hand, means an equality
that must be accompanied by a proof; in \pico/, |~| is the propositional
equality relation. Languages with a \rul{Conv} rule (\pref{sec:conv-rule})
import propositional equality into their definitional equality. \Pico/ does
not do this, requiring a cast to use a propositional equality.} Such
an equality would use this rule (not part of \pico/):
\[
\ottdrule{\ottpremise{[[S;G |-ty t1 : k1  //  S;G |-ty t2 : k2]]}%
\ottpremise{[[S;G |-co g : k1 [Type{}]~[Type{}] k2]]}}{[[S]];[[G]] [[|-prop]] [[t1]] \mathrel{{}^{[[k1]]}\sim_{[[g]]}^{[[k2]]}} [[t2]] \ok}{\rul{Prop\_Homogeneous}}
\]
Note how |~| is indexed by $[[g]]$, the proof that the kinds are equal.
I call this equality homogeneous, because even to form the equality |t1 ~ t2|,
we must know that the kinds are equal. Contrast to \rul{Prop_Equality}, where
the proposition itself is well-formed even when the kinds and/or types are
not provably equal.

\subsection{Equality is hypothetical}

A key property of equality in \pico/ is that programs can \emph{assume} an
equality proof. This is how GADTs are implemented, by packing an equality
proof into a nugget of data and then extracting it again on pattern match.
In the body of the pattern match, we can assume the packed equality. Here
is the typing rule:
\[
\ottdruleCoXXVar{}
\]
Coercion variables are brought into scope by $\Pi$ and $\lambda$ over 
coercion binders.

\subsection{Equality is an equivalence}

The equality relation |~| is explicitly an equivalence relation, via these
rules:
\[
\ottdruleCoXXRefl{}
\ottdruleCoXXSym{}
\ottdruleCoXXTrans{}
\]
Note the use of $[[<t>]]$ to denote a reflexive coercion over the type
$[[t]]$.\footnote{Reflexivity is actually admissible, given the coherence
  coercion form (\pref{sec:coherence}); it is retained here as it is
  exceedingly common in programs and conceptually simple.}

\subsection{Equality is (almost) congruent}

Given coercions between the component parts of two types, we often want to build
a coercion relating the types themselves. For example, if we know that
$[[S;G |-co g1 : t1 [PI a:Rel k1'.k1]~[PI a:Rel k2'.k2] s1]]$
and $[[S;G |-co g2 : t2 [k1']~[k2'] s2]]$, then we can build
$[[S;G |-co g1 g2 : t1 t2 [k1[t2/a] ]~[k2[s2/a] ] s1 s2]]$.
The congruence rules follow:
\[
\ottdrule

If we know that two corresponding parts of two types are equal (and the rest
of the types are the same), then the types themse
In other words:

\begin{theorem*}[Congruence (\pref{thm:congruence})]
If $[[S;G |-co g : s1 (k)~(k) s2]]$ and $[[S;G,a:Irrel k |-ty t : k0]]$,
then there exists $[[h]]$ such that $[[S;G |-co h : t[s1/a] (k0[s1/a])~(k0[s2/a]) t[s2/a] ]]$.
\end{theorem*}

If we know that $[[g]]$ proves $[[ s1 [k1]~[k2] s2]]$, then we can make a
proof from $[[t[s1/a] [k[s1/a] ]~[k[s2/a] ] t[s2/a] ]]$.

\subsection{The \rul{S\_KPush} rule}

The \rul{S\_KPush} rule handles the case where the scrutinee of a \ottkw{case}
expression is headed by a cast. As in all previous work on System FC, this
push rule is the most intricate. However, in this dissertation, I have taken
a new approach to \rul{S\_KPush} that does not require the so-called ``lifting
lemma'' of previous work.\footnote{See for example, \citet{nokinds}, which
contains a good, detailed explication of the lifting lemma.} Instead,
I rely on instantiating the type of a type constant, and on the fact that
type constant types are always closed. As the computation content of the
\rul{S\_KPush} rule must actually be implemented as part of a compiler that
uses \pico/, this (slightly) simpler statement of \rul{S\_KPush}
may prove to be a
measurable optimization
in practice.

A few examples can demonstrate the general idea. First off, note that in
\rul{S\_KPush}, only the scrutinee matters; the alternatives remain
the same before and after the reduction. With that in mind, we can see
scrutinees before and after pushing in \pref{tab:kpush-examples}.

\begin{table}
\newcommand{\pushrow}[1]{\multicolumn{3}{l}{#1}}
\begin{center}
\rowcolors{1}{white}{gray!25}
\setlength{\arrayrulewidth}{.1em}
\begin{tabular}{llc}
Original scrutinee & Assumptions / Notes \\
\pushrow{Pushed scrutinee} \\ \hline
$[[&True{} |> <&Bool{}>]]$ & simple case; no universals & (1)\\
\pushrow{$[[&True{}]]$} \\[2ex]
$[[&&Justx{&Int{}} #3{} |> g]]$ &
$\begin{array}[t]{@@{}l@@{}}
[[S;G |-co g : &Maybe{} &Int{} [Type{}]~[Type{}] &Maybe{} &&bx]] \\
[[&&bx :Irrel Type{} \in G]]
\end{array}$ & (2)\\
\pushrow{$
[[&&Justx{&&bx} (#3{} |> argk (<MPI &&ax :Irrel Type{}, &&xx :Rel &&ax. &Maybe{} &&ax>@(nth 1 g)))]]$} \\[2ex]
%
$[[&MkG{&Bool{}} <&Bool{}> |> g]]$ &
$\begin{array}[t]{@@{}l@@{}}
[[S;G |-co g : &&Gx{} &Bool{} [Type{}]~[Type{}] &&Gx{} &&bx]] \\
[[&&bx :Irrel Type{} \in G]]
\end{array}$  & (3) \\
\pushrow{
$\begin{array}[t]{@@{}l@@{}}
[[&MkG{&&bx} (sym (argk 1 h) ;; <&Bool{}> ;; argk 2 h)]] \text{, where} \\
\quad [[h = <MPI (&&ax :Irrel Type{}), (c : &&ax [Type{}]~[Type{}] &Bool{}). &&Gx{} &&ax>@(nth 1 g)]] \\[2ex]
\end{array}$} \\[2ex]
%
$[[(&Pack{&Bool{}} &True{} &MkP{&Bool{},&True{}}) |> g]]$ &
$\begin{array}[t]{@@{}l@@{}}
[[S;G |-co g : MPI d1. &Ex{} &Bool{} [Type{}]~[Type{}] MPI d2. &Ex{} &&bx]] \\
[[d1 = &&yx :Rel &Proxy{} &Bool{} &True{}]]\\
[[d2 = &&yx :Rel &Proxy{} &&bx (&True{} |> g2)]]\\
[[S;G |-co g2 : &Bool{} [Type{}]~[Type{}] &&bx]] \\
[[&&bx :Irrel Type{} \in G]]
\end{array}$ & (4) \\
\pushrow{
$\begin{array}[t]{@@{}l@@{}}
[[&Pack{&&bx} {&True{} |> h0'} (&MkP{&Bool{},&True{}} |> h1')]] \text{, where} \\
\quad [[k = MPI (&&kx :Irrel Type{}), (&&ax :Irrel &&kx), (&&xx :Rel &Proxy{} &&kx &&ax), (&&yx :Rel &Proxy{} &&kx &&ax). &Ex{} &&kx]] \\
\quad [[h0 = <k>@(nth 1 (res^1 g))]] \\
\quad [[h0' = argk h0]] \\
\quad [[h1 = h0@(&True{} ~={h0'} &True{} |> h0')]] \\
\quad [[h1' = argk h1]] \\
\end{array}$} \\
%
\end{tabular}
\end{center}

The reductions above assume the following datatypes:
%{
%if style == newcode
%format Ex = "Ex2"
%format Bool = "Bool2"
%format True = "True2"
%format False = "False2"
%format Maybe = "Maybe2"
%format Just = "Just2"
%format Nothing = "Nothing2"
%endif
\begin{code}
data Bool = False | True
data Maybe a = Just a | Nothing
data G a where
  MkG :: G Bool
data Proxy (a :: k) = MkP
data Ex k where
  Pack :: forall (a :: k). Proxy a -> Proxy a -> Ex k
\end{code}
%}
And in \pico/:
\[
\begin{array}{r@@{\,}l}
[[S]] = &
[[&Bool : (empty), &False : (empty; &Bool), &True : (empty; &Bool)]] \\
& [[&Maybe : (&&ax : Type{}), &&Justx : (&&xx :Rel &&ax; &Maybe), &&Nothingx : (empty; &Maybe)]] \\
& [[&&Gx : (&&ax : Type{}), &MkG : (c : &&ax [Type{}]~[Type{}] &Bool{}; &&Gx)]] \\
& [[&Proxy : (&&kx : Type{}, &&ax : &&kx), &MkP : (empty; &Proxy)]] \\
& [[&Ex : (&&kx : Type{}), &Pack : (&&ax :Irrel &&kx, &&xx :Rel &Proxy{} &&kx &&ax, &&yx :Rel &Proxy{} &&kx &&ax; &Ex)]]
\end{array}
\]
\caption{Examples of \rul{S\_KPush}}
\label{tab:kpush-examples}
\end{table}

\paragraph{Example (1)}
In this example, there are no universals of the type in question (|Bool|), and
so ``pushing'' is extraordinarily simple: just drop the coercion. We can see
this in terms of \rul{S\_KPush} in that both $[[ts]]$ and $[[ps]]$ are empty.
Note that if we had a non-reflexive coercion in the scrutinee---that is, if
the scrutinee were, say, $[[&True{} |> g]]$ with $[[S;G |-co g : &Bool{} [Type{}]~[Type{}] &&ax]]$---the \ottkw{case} expression would not be well-typed.
Rule \rul{Ty\_Case} requires the type of a scrutinee to be of the form
$[[MPI D.H{} ss]]$. The type |a| does not have this form, and so such a
scrutinee is disallowed.
Also note that we cannot have $[[&True{} |> g]]$ with $[[S;G |-co g : &Bool{} [Type{}]~[Type{}] &Int{}]]$ due to the consistency lemma (\pref{sec:consistency}).

\paragraph{Example (2)}
This is the simplest non-trivial example. We need to push a coercion
$[[g]]$ proving |Maybe Int ~ Maybe b| into $[[&&Justx{&Int{}} #3{}]]$.
This casted scrutinee has type |Maybe b|; the pushed scrutinee must have the
same type. We thus know it must start with $[[&&Justx{&&bx}]]$.
The only challenge left is to cast the argument, |3|, with a coercion
that proves |Int ~ b|. We will always be able to extract this coercion
from the coercion casting the scrutinee, $[[g]]$. But how, in general?

The coercion needed to cast each (existential) argument to a constructor
must surely depend on the type of the constructor. Previous versions of
System FC did a transformation on this type to produce the coercion. 
In this work, I instantiate the type using the $[[@]]$ operator 

\rae{Must introduce $[[ee]]$ when appropriate.}

\rae{Extensions: split, |Equals|, representation polymorphism, |(->)|, compression (\ottkw{step} becoming $\ottkw{step}^n$).}
