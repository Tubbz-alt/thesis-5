%% -*- mode: LaTeX; compile-command: "cd ..; make compile" -*-

%if style == newcode
%include rae.fmt

\begin{code}

import Data.Kind

\end{code}

%endif

\chapter{Related and future work}
\label{cha:related}

There is a great deal of work related to this dissertation, looking at
designs of similar surface languages, designs of similar
intermediate languages, and similar type inference algorithms. This chapter
reviews this related work, starting with a thorough comparison with
the work of \citet{gundry-thesis}, which covers all of the areas above.

\section{Comparison to Gundry's thesis}
\label{sec:gundry}

The most apt comparison of my work is to that of \citet{gundry-thesis}.
His dissertation
is devoted to much the same goal as mine: adding dependent types to Haskell.
I have tried to compare my work to his as this has been topical throughout
this work. Here I summarize some of the key points of difference and explain
how my work expands upon what he has done.

\subsection{Unsaturated functions in types}

Gundry's intermediate language uses one element of the grammar to represent
both terms and types. But he offers separate typing judgments, as controlled
by his use of a phase modality. In Gundry's type system, every typing judgment
holds at one of three \emph{phases}:\footnote{Actually, one of four, but both
Gundry and I keep coercion typing so separate from other typing judgments
that I am excluding it here.} runtime, compile time, or shared (Gundry's 
Section 6.2). Gundry
describes an \emph{access policy} (Gundry's Section 6.2.1) whereby an
expression well-typed at the shared phase can also be used in either the
runtime or compile-time phases. Gundry's use of phases is not unlike my
use of relevance, where an expression well-typed at
Gundry's compile-time phase would be irrelevant in my formulation.

The big difference between my treatment and Gundry's is that I essentially
combine the shared and runtime phases. That is, anything that is allowed
at runtime is also allowed in types. Gundry prevents
$\lambda$-expressions and unsaturated functions from being used in types.
These constructs can be typed only at the runtime phase, never the shared
or compile-time phases. Because of this restriction around
unsaturated functions, Gundry's system must carefully track where unsaturated
functions appear and prevent any expression containing one from being used
in a type or a dependent context.

I avoid Gundry's restriction by tracking matchable functions separate
from unmatchable ones (Sections~\ref{sec:matchability} and~\ref{sec:matchable-pico}).
This innovation permits me to allow unsaturated functions while
retaining the useful \ottkw{left} and \ottkw{right} coercions.
As a part of this aspect of my work, I also lift the matchable/unmatchable
distinction into surface Dependent Haskell, giving the user access to the
|!->|, |!pi|, and |!forall| quantifiers.

\subsection{Support for type families}

Both Gundry's and my treatments favor $\lambda$-abstractions and \ottkw{case}
expressions over type families. In my case, I would support type families
via compilation into those more primitive forms. Gundry's work, however,
explicitly does not support type families (Gundry's Section 6.7.4).
This lack of support is revealed
in two missing features:
\paragraph{Matching on |Type|} 
Through the way I have constructed my \ottkw{case} expressions---specifically,
treating |Type| as just another type constant---I allow
pattern-matching on elements of |Type|. Gundry's treatment requires a
scrutinee to be a member of a closed algebraic datatype.
\paragraph{Unsaturated matching}
Haskell type families can match on unsaturated uses of data and type
constructors, something not supported in Gundry's work but is supported
in \pico/.


\subsection{Axioms}

Gundry's \emph{evidence} language includes support for axioms. While the
notion of type-level axioms has been used in much prior work to represent
type families, Gundry uses them to represent notions beyond those possible
in type families, such as the commutativity of some primitive addition
operation. In order to set up his consistency proof, he needs to establish
that the axioms are \emph{good}, as defined in Gundry's Definition 6.4 of
his Section 6.5.1. Gundry does not provide an algorithm for determining
whether a set of axioms are \emph{good}, however.

\Pico/, in contrast, has no built-in support for axioms. One could try
adding axioms as global coercion variables available in every context, but
that would interfere with the current consistency proof (\pref{sec:consistency})
which severely limits the use of coercion variables. It is conceivable
that adding axioms to \pico/ is possible by establishing some condition,
like Gundry's \emph{good}, that claims that the axioms do not interfere
with consistency. This remains as future work, however.


\subsection{Type erasure}
\label{sec:gundry-type-erasure}

Gundry proves a type erasure property similar to mine. However, there is
one key difference: my type erasure erases irrelevant abstractions (as does
today's implementation of System FC in GHC), while
Gundry's does not. It is not clear, however, that this change is significant,
in that it might easily be possible to tweak Gundry's system to allow erasure
of irrelevant abstractions, too.

\paragraph{}
See also \pref{sec:gundry-consistency-wrong} and \pref{sec:gundry-type-inference}
for further comments comparing my work to Gundry's.

\section{Comparison to Idris}

Of the available dependently typed language implementations, Idris is the most
like Dependent Haskell. Idris was designed explicitly to answer the question
``What if Haskell had \emph{full} dependent
types?''~\cite[Introduction]{idris} 
The Idris implementation is available\footnote{\url{http://www.idris-lang.org/}}
and is actively developed. So, how does Idris compare with Dependent Haskell?
I review the main points of difference, below.

\subsection{Backward compatibility}

From a practical standpoint, the biggest difference between Dependent Haskell
and Idris is that the former joins an already existing ecosystem of Haskell
libraries and developers. Dependent Haskell is a conservative extension over
existing implementations of Haskell, and all legacy programs will continue
to work under Dependent Haskell. Although Idris is certainly Haskell-like
(and has a foreign-function interface available to call Haskell code
from Idris and vice versa) it is still not Haskell.

Pushing on this idea a bit more, for a project to be started in Idris,
the programmers must decide, at the outset, that they wish to use dependent
types, as its type system is Idris's most distinctive feature. With
Dependent Haskell, on the other hand, developers can choose to take a part of
larger Haskell application and rewrite just that part with dependent types.
This allows for gradual adoption, something that is much easier for the
general public to swallow.

\subsection{Type erasure}
\label{sec:idris-type-erasure}

Dependent Haskell and Idris take different approaches to type erasure.
Idris's approach is explained by \citet{practical-erasure} as a whole-program
analysis, seeking out places where an expression is needed and ensuring
that all such expressions are available at runtime. Naturally, such an
approach hinders separate compilation, which the authors admit is important
future work (Teji\v{s}\v{c}\'{a}k and Brady's Section 8.1).

By contrast, Dependent Haskell depends on user-written choices---specifically,
whether to use |pi| or |forall| when writing a type.

Which approach is better? It is hard to say at this point. The Idris approach
has the advantage of automation. It may be hard for a user to know what
expressions (especially those stored in datatypes) will be necessary at
runtime. The choice between |pi| and |forall| may also motivate library-writers
to duplicate their data structures providing both options. This is much
like the fact that many current libraries provide both strict and lazy
implementations of core data structures, as the better choice depends
on a client's usage. Perhaps the option for library-writers to provide
multiple versions of a datatype is an advantage, however: in Idris,
a datatype's parameter may be marked as relevant even if it is used only
once. In that case, the Idris programmer is perhaps better served by using
one data structure (with the field irrelevant) in most places and the other
data structure (with the field relevant) just where necessary. Time will
tell whether the Dependent Haskell approach or the Idris approach is
better.

\subsection{Type inference}

All Idris top-level definitions must be accompanied with type annotations.
Even local definitions must have type annotations, sometimes requiring 
scoped type variables to provide. One might say, then, that Idris does
no type inference, only type checking. For this reason, studying the
type inference properties of the language might be less compelling.
Indeed, Brady claims~\cite[Section 6]{idris} that Idris ``avoid[s] such
difficulties since, in general, type inference is undecidable for
full dependent types. Indeed, it is not clear that type inference is even
desirable in many cases...''

While I admit that considering a principal-types property is much less
compelling when all bindings are annotated, I still believe that writing
a type inference algorithm or specification is helpful. I am unaware
of a description in the literature of Idris's algorithm beyond
\citet[Section 4]{idris}, describing the elaboration of an Idris program
in terms of the tactics that generate code in Idris's intermediate language,
\textsf{TT}. Accordingly, it is hard to predict when an Idris program
will be accepted. I tested the following program against the latest version
of Idris (0.12.1):
\begin{spec}
ty : Bool -> Type
ty x = case x of True => Integer; False => Char

f : (x : Bool) -> ty x
f x = case x of True => 5; False => 'x'

g : (x : Bool) -> ty x
g x = the  (ty x)
           (case x of True => 5; False => 'x')

h : (x : Bool) -> ty x
h x = the  (case x of True => Integer; False => Char)
           (case x of True => 5; False => 'x')
\end{spec}
Idris's |the| is its form of type annotation, with |the : (a : Type) -> a -> a|.
Both |f| and |g| are accepted, while |h| is rejected. Note that
the only difference between |g| and |h| is that the body of |ty| is expanded
in |h|. Is this a bug or the correct behavior? It is hard to know.

In contrast, \pref{cha:type-inference} describes a bidirectional inference
algorithm that details how to treat such expressions. (All of |f|, |g|,
and |h| are accepted in Dependent Haskell and today's approximation thereof
using \package{singletons}.) 

Beyond just having a specification, Dependent Haskell also retains
Hindley-Milner |let|-generalization for top-level expressions (as implemented
by the \rul{IDecl\_Syn\-the\-size} rule of \bake/). This means that simply typed
functions and local declarations need not have type ascriptions. Indeed, in
translating Idris's \package{Effects} library to Dependent Haskell
(\pref{sec:algebraic-effects}), I was able to eliminate several type
annotations, needed in Idris but redundant in Haskell. Having
|let|-generalization also powers examples like inferring the schema from the
use of a dependently typed database access library
(\pref{sec:dependent-db-example}), the equivalent of which would be impossible
in Idris.

\subsection{Editor integration}
\label{sec:idris-error-msgs}

One arena where Idris is clearly out ahead is in its user interface. Indeed,
despite the fact that Idris is considerably younger, GHC has been clamoring
to catch up to Idris's user interface for some time now. Its emacs
integration means that users can interactively peruse error messages,
expanding out the parts of interest and easily ignoring the unhelpful
parts~\cite{idris-pretty-printer}. Dependent Haskell and GHC have much
to learn from Idris in this respect; dependently typed programming in Haskell
will demand improvement.

\section{Comparison to Cayenne}
\label{sec:cayenne}

Beyond Idris, there are many other languages one might want a comparison
against. The most frequent comparison I have been asked for, however,
is to compare against Cayenne~\cite{cayenne}, which I shall do here.

Cayenne is a language introduced in 1998 by Augustsson essentially as a
dependently typed variant of Haskell. Of particular interest,
it shares Dependent Haskell's
cavalier attitude toward termination: Cayenne supports general recursion
and all types are thus inhabited by $\bot$. As such, Augustsson admits
that Cayenne is not useful as a proof assistant. However, he also argues
that this admission does not mean it is useless as a programming language.
My argument in support of allowing general recursion in a dependently typed
language (\pref{sec:running-proofs}) broadly echoes Augustsson's Section 5,
claiming that a verification of partial correctness is better than no
verification at all.

Despite the similarities between my work here and Augustsson's, there are
a number of key differences:

\subsection{Type erasure}
\label{sec:cayenne-type-erasure}
Augustsson's approach to type erasure is much simpler than mine. Cayenne
erases all expressions of type |Type|---that's the full description
of type erasure in Cayenne. This simplistic view has two shortcomings,
however:
\begin{description}
\item[Cayenne erases too much] Because every expression of type |Type|
is lost, Cayenne must restrict its pattern-match facility not to work
over scrutinees of type |Type|. Dependent Haskell allows matching on |Type|,
in contrast.
\item[Cayenne erases too little] Sometimes expressions of a type other
than |Type| can be erased. For example, consider this function over length-indexed
vectors (\pref{sec:length-indexed-vectors}):
%if style == newcode
\begin{code}
data Nat = Zero | Succ Nat
data Vec :: Type -> Nat -> Type where
  Nil :: Vec a !Zero
  (:>) :: a -> Vec a n -> Vec a (!Succ n)
infixr 5 :>
\end{code}
%endif
\begin{code}
safeHead :: Vec a (!Succ n) -> a
safeHead (x :> _) = x
\end{code}
The |n| parameter to |safeHead| has type |Nat| and yet it can be erased in
the call to |safeHead|. Cayenne would have no way of erasing this parameter.
\end{description}

\subsection{Coercion assumptions}

Cayenne has no support for equality assumptions. This means that it does
not support GADTs (\pref{sec:gadts} or dependent pattern matching (\pref{sec:dependent-pattern-match}). Lacking these features significantly simplifies the
design of the language and implementation, meaning that many of the 
type inference issues (specifically, untouchability of type variables)
described by \citet{outsidein} are avoided. The lack of equality assumptions
also severely weakens Cayenne's ability to support intrinsic proofs---that
is, types whose structure ensure that all values of those types are valid
(like |Vec|, which ensures that the vector is of the given length). Cayenne
thus truly supports only extrinsic proofs: proofs written separately from
the functions and data structures they reason about. These proofs must be
written explicitly (intrinsic proofs are often encoded into the structure
of a function) and offer more opportunity to accidentally use a non-terminating
proof.

\subsection{A hierarchy of sorts}

Cayenne uses an infinite hierarchy of sorts, similar to many other
dependently typed languages, but in contrast to Dependent Haskell, with
its |Type : Type| axiom. Augustsson describes this design decision as
working in support of Cayenne's treatment as logical framework (if the
user takes on the burden of termination checking) as well as to support
Cayenne's implementation of type erasure.

\subsection{Metatheory}

While Augustsson presents typing rules for Cayenne, he offers no metatheory
analysis for Cayenne beyond proving that the evaluation of a type-erased
program simulates the evaluation of the original. Similarly, Augustsson
does not describe any type inference properties in detail. The language
requires top-level type annotations on all definitions, but inference is
still necessary to check a dependently typed expression. Instead, Augustsson
claims that ``Type signatures can be omitted in many places'' but does
not elaborate~\cite[fourth-to-last bullet in Section 3.2]{cayenne}.
Cayenne does syntactically require all function arguments to be annotated,
however.

\subsection{Modules}

Cayenne has a robust module system, more advanced than Haskell's. As such,
its module system is more advanced also than Dependent Haskell's. Cayenne
uses dependent records as its modules, as a dependent record can store
types as easily as other expressions. It remains as future work to see
whether or not Dependent Haskell can incorporate these ideas and use
records as modules.

\subsection{Conclusion}

As an early attempt to bring dependent types to Haskell, Cayenne deserves
much credit. Despite being declared dead in 2005\footnote{\url{http://lambda-the-ultimate.org/node/802}}, Haskellers still discuss this language. It may
have been the first thought-out vision of what a Haskell-like dependently
typed language would look like and thus serves as an inspiration for both
Agda and Idris.

\section{Comparison to Liquid Haskell}
\label{sec:liquid-haskell}

Liquid Haskell~\cite{bounded-refinement-types,liquid-haskell-experience,liquid-haskell} is an ongoing project seeking to add \emph{refinement types}
to Haskell. A refinement type specifies a head type and a condition; any
value of that type is asserted to meet the condition. For example, we might
write the type of the |length| function thus:
\begin{spec}
length :: [a] -> { n : Int | n >= 0 }
\end{spec}
The return type tells us that the return value will always be non-negative.

The Liquid Haskell implementation works by reading in such annotations
with a Haskell file and checking that the refinements are satisfied. The
check is done via an SMT solver. No user intervention---other than writing
the refinements in the first place---is required.

Liquid Haskell and Dependent Haskell are, in some ways, two different solutions
to (nearly) the same problem: the desire to rule out erroneous programs.
By specifying tight refinements on our function types, we can have Liquid
Haskell check the correctness of our programs. And doing so is easy, thanks
to the power of the SMT solver working in the background.

However, the refinement types of Liquid Haskell exist outside of the type system
proper: it is not possible to write a type-level program that can manipulate
refinements, and it is also not possible to write refinements that can
reason about Haskell's type classes or other advanced type-level features.
Along similar lines, it is not possible to use refinement types to write
a program inadmissible in regular Haskell; for example, refinement types
are not powerful enough to encode something like Idris's algebraic effects
library (\pref{sec:algebraic-effects}).

The beauty of Liquid Haskell is in its user interface. Proving that a program
matches its specification is fully automatic---something very much not
true of Dependent Haskell programs. The project has shown without a doubt
that using an SMT solver to help type-checking will lessen users' proof
burden. (Liquid Haskell is hardly the only tool that uses an SMT solver
for type-checking. See also, for example, \citet{dafny,dependent-f-star},
among others.) 

It is my hope that, someday, Dependent Haskell can aspire to be the
backend for Liquid Haskell. The merged language would have the type
refinement syntax much like Liquid Haskell's current syntax, but it would
desugar to proper dependent types under the hood. An SMT solver would remain
as part of the system, possibly as a type-checker plugin.
For function arguments, supporting refinement types
is already possible: a type like |{n : Int || n >= 0}| can be encoded
as a dependent parameter |n| and a Haskell constraint. Much more problematic
is a refined return type. For that same refinement, we would need a
existential package, saying that a function returns \emph{some} |n| with
|n >= 0|. While Dependent Haskell support existentials, naturally, packing
and unpacking these must be done manually. In practice, this packing
and unpacking clutters the code considerably and makes the refinement
approach distasteful. Perhaps worse, the packing and unpacking would be
performed at runtime, making end users pay a cost for this compile-time
checking. Overcoming these barriers---coming up with a lightweight syntax
for existentials as well as zero runtime overhead---is important future work,
perhaps my highest priority new research direction.

\section{Comparison to Trellys}

The Trellys project~\cite{trellys,programming-up-to-congruence,combining-proofs-and-programs} aims toward a similar goal to my work here: including
dependent types in a language with non-termination. However, the Trellys
approach is quite different to what I have done here, in that the language
is formed of two fragments: a logical fragment and a programmatic fragment.
The two halves share a syntax, but some constructs (such as general recursion)
are allowed only in the programmatic fragment. Proofs in the logical fragment
can be trusted (and never have to be run) but can still mention definitions
in the programmatic fragment in limited ways.

The Zombie language~\cite{programming-up-to-congruence}, one of the languages
of the Trellys project, allows potentially non-terminating functions in
types but retains decidable type-checking by forcing the user to indicate
how much to $\beta$-reduce the types. This stands in contract to Dependent
Haskell, where type-checking is undecidable and might not terminate.

\section{Invisibility in other languages}
\label{sec:vis-other-lang}

\pref{sec:visibility} describes how Dependent Haskell deals with
both visible and invisible function arguments. Here, I review how
this feature is handled in several other dependently typed languages.

\paragraph{Agda}
%{
%format dbo = "\{\!\{"
%format dbc = "\}\!\}"
In Agda, an argument in single braces |{ ... }| is invisible and is
instantiated via unification. An argument in double braces |dbo ... dbc| is
invisible and is instantiated by looking for an in-scope variable of the
right type. One Agda encoding of, say, the |Show| class and its |Show Bool|
instance would be to make |Show| a record containing a |show| field (much
like GHC's dictionary for |Show|) and a top-level variable of type |Show Bool|.
The lookup process for |dbo ... dbc| arguments would then find this top-level
variable.

Thus, |show|'s type in Agda might look like |forall {a} -> dbo Show a dbc -> a ->
String|.
%}
%{
%format proof = "\keyword{proof}"
%format trivial = "\keyword{trivial}"
%format auto = "\keyword{auto}"
\paragraph{Idris}
 Idris supports type classes in much the same way as Haskell. A constraint
listed before a |(=>)| is solved just like a Haskell type class is. However,
other invisible arguments can also have custom solving tactics. An Idris
argument in single braces |{ ... }| is solved via unification, just like in
Agda. But a programmer may insert a proof script in the braces as well to
trigger that proof script whenever the invisible parameter needs to be
instantiated. For example, a type signature like
|func : {default proof { trivial } pf : tau } -> ...| names a (possibly-dependent)
parameter |pf|, of type |tau|. When |func| is called, Idris will run the
|trivial| tactic to solve for a value of type |tau|. This value will then
be inserted in for |pf|. Because a default proof script of |trivial| is so
common, Idris offers an abbreviation |auto| which means |default proof { trivial }|.
%}
\paragraph{Coq}
Coq has quite a different view of invisible arguments than do Dependent Haskell,
Agda, or Idris. In all three of those languages, the visibility of an argument
is part of a type. In Coq, top-level directives allow the programmer to change
the visibility of arguments to already-defined functions. For example, if we
have the definition
%{
%format Definition = "\keyword{Definition}"
%format Arguments = "\keyword{Arguments}"
%format Set = "\keyword{Set}"
%format Implicit = "\keyword{Implicit}"
%format mytrue1
%format mytrue2
%format forall = "\keyword{forall}"
\begin{spec}
Definition id A (x : A) := x.
\end{spec}
(without having used |Set Implicit Arguments|) both the |A| and |x| parameters
are visible. Thus the following line is accepted:
\begin{spec}
Definition mytrue1 := id bool true.
\end{spec}
However, we can now change the visibility of the arguments to |id| with the
directive
\begin{spec}
Arguments id {A} x.
\end{spec}
allowing the following to be accepted:
\begin{spec}
Definition mytrue2 := id true.
\end{spec}

Although Coq does not allow the programmer to specify an instantiation technique
for invisible arguments, it does allow the programmer to specify whether or
not invisible arguments should be \emph{maximally inserted}. A maximally
inserted invisible argument is instantiated whenever possible; a non-maximally
inserted argument is only instantiated when needed. For example, if the |A|
argument to |id| were invisible and maximally inserted, then any use of |id|
would immediately try to solve for |A|; if this were not possible, Coq would
report a type error. If |A| were not maximally inserted, than a use of |id|
would simply have the type |forall A, A -> A|, with no worry about invisible
argument instantiation.

The issue of maximal insertion in Dependent Haskell is solved via its
bidirectional type system (\pref{sec:bidirectional}). The subsumption relation
effectively ensures that the correct number of invisible parameters are provided,
depending on the context.
%}

\section{Type erasure and relevance in other languages}
\label{sec:related-type-erasure}

\Pico/'s approach to relevance and type erasure is distinctive and
pervasive in its definition. Here I review several other approaches
to type erasure in other languages and calculi.

\paragraph{Gundry's \emph{evidence} language, Idris, and Cayenne}
See Sections \ref{sec:gundry-type-erasure}, \ref{sec:idris-type-erasure},
and \ref{sec:cayenne-type-erasure}, respectively.

\paragraph{Agda}
The Agda wiki contains a comprehensive page on Agda's support for irrelevance
annotations.\footnote{\url{http://wiki.portal.chalmers.se/agda/pmwiki.php?n=ReferenceManual.Irrelevance}} The user can annotate certain definitions
and parameters as irrelevant, by preceding them with a |.| prefix. Irrelevant
values can be used in irrelevant contexts only, much like how \pico/ treats
irrelevantly-bound variables. Irrelevant fields to a data constructor are
ignored in an equality check, a feature that \pico/ does not currently support.
For example, consider the following Agda program:
%format AgdaNat = "\mathbb{N}"
%format dot = ".\!\!"
\begin{spec}
data T : Set where
  mkT : ^^ dot (n : AgdaNat) -> T
data S : T -> Set where
  mkS : ^^ dot (n : AgdaNat) -> S (mkT n)

x : S (mkT 3)
x = mkS 3

y : S (mkT 4)
y = x
\end{spec}
This program is accepted despite the fact that |x| and |y| have manifestly
different types. Yet because the parameter to |mkT| is denoted as irrelevant,
the types are considered equal. Note that, due to the restrictions around
irrelevant contexts, if we remove the |.| prefix to the parameter to
|mkT|, the constructor type for |mkS| would fail to type-check, because it
uses its irrelevant argument |n| in a relevant context (as the argument
to the now-relevant |mkT| constructor). Conversely, dropping the |.| in
the type of |mkS| would not affect type-checking.

It would be interesting future work to see how using relevance in this way
might affect Dependent Haskell.

Despite having support for these irrelevance annotations, it seems that Agda
does not have any principles behind its type erasure, instead depending on
the extraction mechanism used to run Agda code.

\paragraph{Coq}
%{
%format Set = "\ottkw{Set}"
%format Prop = "\ottkw{Prop}"
Coq uses an altogether different approach to relevance and erasure. Coq
has two primary sorts, |Prop| and |Set|. (I am ignoring the infinite
hierarchy of |Type|s that exist above |Prop| and |Set|.) All inhabitants
of |Prop| are considered irrelevant and are erased during extraction.
Coq thus enforces restrictions on the use of elements of types in |Prop|:
chiefly,
in the definition of an element of a type in |Set|, a program may not
pattern-match on an element of a type in |Prop| unless that type has exactly
0 or 1 constructors. In other words, the choice of a value of a
type in |Set| may not depend on any information from a type in |Prop|.
This is sensible, because that information will disappear during extraction.

Because of Coq's separation between |Set| and |Prop|, it is sometimes necessary
to have duplicate data structures, some with |Set| types and some with
|Prop| types. (For example, the Coq standard library has three different
variants of an existential package---|ex|, |sig| and |sigT|---depending on
which parts are in |Prop| vs.~|Set|.) Such duplication might also appear
in Dependent Haskell, as I argue in \pref{sec:idris-type-erasure}.
%}

\def\iccstar/{ICC${}^*$}
\paragraph{\iccstar/}
\citet{icc-star} introduce \iccstar/ as a variant of Miquel's Implicit Calculus of
Constructions~\cite{miquel-icc}. \iccstar/ contains two forms of $\Pi$-type
as well as two forms of $\lambda$-extraction, in much the same way as
\pico/. The ICC literature uses ``implicit'' and ``explicit'' to refer
to the concepts I call ``irrelevant'' and ``relevant'', respectively; I will
continue to use my own terminology here. (Further muddying these waters, the
original ICC also makes irrelevant arguments invisible. I have endeavored
to keep visibility and relevance quite separate in this dissertation.)
\iccstar/ includes an erasure operation that converts \iccstar/ expressions
to ICC expressions by erasing irrelevant arguments. In order to enforce
appropriate use of irrelevant arguments,
irrelevantly bound variables are forbidden from appearing in the erased, ICC-form
of body of an abstraction. This restriction is enforced by a simple
check for free variables in the typing rule of the irrelevant
$\lambda$-abstraction, in contrast to \pico/'s approach of tracking
relevance in contexts. The \pico/ equivalent to \iccstar/'s approach would
resemble this rule:
\[
\ottdrule{\ottpremise{[[S;G,a:NOREL s |-ty t : k  // a \notin fv(||t||)]]}}%
{[[S;G |-ty \ a:Irrel s. t : UPI a:Irrel s. k]]}{\rul{Ty\_Lam'}}
\]
It is possible that such a rule would simplify the statement of \pico/,
but I imagine it would complicate the proofs---especially of type erasure---as
there would have to be
a way of propagating the information about where irrelevant variables can
appear.

\section{Future directions}

With the design for Dependent Haskell laid out here, what work is left
to do? First and foremost, I must tackle the remainder of the implementation
as sketched in \pref{sec:impl-todo}. However, beyond that, there are many
more research questions left unanswered:

\begin{itemize}
\item With the added complexity of dependent types, type error messages
will surely become even harder to read and act on. How can these be improved?
Idris's technique of displaying interactive error messages (\pref{sec:idris-error-msgs}) may be a step
in the right direction, but it would be even better to have some theory
of error messages to use as a guiding principle in solving this problem.

\item Relatedly, dependent types work wonders for authors who wish to
write an embedded domain-specific language. Programs might be written
in such an EDSL by practitioners who do not know much type theory or Haskell.
How can we expose a way for the DSL writer to customize the type error
messages?

\item What editor support is necessary to make dependent types in Haskell
practical? Leading dependently typed languages (specifically, Coq, Agda,
and Idris) all have quite advanced editor integration in order to make
development more interactive. Haskell has some integration, but likely
not enough to make dependently typed programming comfortable. What is missing
here?

\item Some dependently typed languages have found \emph{tactics} a useful
way of constructing proofs. Would such a technique be feasible in Dependent
Haskell? What would such a facility look like?

\item One of GHC's chief strengths is its optimizer. Once we have dependent
types, can type-level information inform optimization in any meaningful way?
In particular, using dependent types, an author might be able to write
down ``proofs'' that a |Monad| instance is lawful. Can the optimizer take
advantage of these proofs? Will we have to trust that they terminate to do so?

\item How will dependent types interact with type-checker
  plugins? How can we use an SMT solver to make working
  with dependent types easier?

\item Dependent types will allow for proper dependent pairs ($\Sigma$-types).
  Is it worth introducing new syntax to support these useful constructs directly?
Would this new syntax also pave the way for better integration with
Liquid Haskell (\pref{sec:liquid-haskell})?

\item This dissertation has proved that the output of the \bake/ algorithm
is a type-correct \pico/ program. It has not rigorously established, however,
a principal types property or conservativity over today's Haskell. What
steps are missing before we can prove these?

\item One might reasonably ask whether all the fancy type-level bells and
whistles affect parametricity. I do not believe they do, but it would be
informative to try to prove this directly.
\end{itemize}

\section{Conclusion}

This chapter has really only scraped the surface of related work. There
are simply too many dependently typed languages and calculi available
to compare against all of them. In this crowd, however, Dependent Haskell
stands out chiefly for its unapologetic embrace of non-termination and
partial correctness. Dependent Haskell is, first and foremost, a programming
language, and many valuable programs are indeed non-terminating or hard
to prove to be total. These programs are welcome as first-class citizens
in Dependent Haskell.

%%  LocalWords:  gundry newtype SMT newcode rae fmt endif FC datatype's Succ

%%  LocalWords:  Augustsson Augustsson's Vec infixr safeHead untouchability
%%  LocalWords:  Cayenne's Trellys dbo dbc func mytrue bool AgdaNat mkT mkS
%%  LocalWords:  sig sigT Miquel's EDSL DSL
