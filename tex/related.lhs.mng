%% -*- mode: LaTeX; compile-command: "cd ..; make compile" -*-

%if style == newcode
%include rae.fmt

\begin{code}

import Data.Kind

\end{code}

%endif

\chapter{Related work}
\label{cha:related}

There is a great deal of work related to this dissertation, looking at
designs of similar surface languages, designs of similar
intermediate languages, and similar type inference algorithms. This chapter
reviews this related work, starting with a thorough comparison with
the work of \citet{gundry-thesis}, which covers all of the areas above.

\section{Comparison to \citet{gundry-thesis}}

The most apt comparison of my work is to that of Gundry. His dissertation
is devoted to much the same goal as mine: adding dependent types to Haskell.
I have tried to compare my work to his as this has been topical throughout
this work. Here I summarize some of the key points of difference and explain
how my work expands upon what he has done.

\subsection{Unsaturated functions in types}

Gundry's intermediate language uses one element of the grammar to represent
both terms and types. But he offers separate typing judgments, as controlled
by his use of a phase modality. In Gundry's type system, every typing judgment
holds at one of three \emph{phases}:\footnote{Actually, one of four, but both
Gundry and I keep coercion typing so separate from other typing judgments
that I am excluding it here.} runtime, compile time, or shared (Gundry's 
Section 6.2). Gundry
describes an \emph{access policy} (Gundry's Section 6.2.1) whereby an
expression well-typed at the shared phase can also be used in either the
runtime or compile-time phases. Gundry's use of phases is not unlike my
use of relevance, where an expression well-typed at
Gundry's compile-time phase would be irrelevant in my formulation.

The big difference between my treatment and Gundry's is that I essentially
combine the shared and runtime phases. That is, anything that is allowed
at runtime is also allowed in types. Gundry prevents
$\lambda$-expressions and unsaturated functions from being used in types.
These constructs can be typed only at the runtime phase, never the shared
or compile-time phases. Because of this restriction around
unsaturated functions, Gundry's system must carefully track where unsaturated
functions appear and prevent any expression containing one from being used
in a type or a dependent context.

I avoid Gundry's restriction by tracking matchable functions separate
from unmatchable ones (Sections~\ref{sec:matchability} and~\ref{matchable-pico}).
This innovation permits me to allow unsaturated functions while
retaining the useful \ottkw{left} and \ottkw{right} coercions.
As a part of this aspect of my work, I also lift the matchable/unmatchable
distinction into surface Dependent Haskell, giving the user access to the
|!->|, |!pi|, and |!forall| quantifiers.

\subsection{Support for type families}

Both Gundry's and my treatments favor $\lambda$-abstractions and \ottkw{case}
expressions over type families. In my case, I would support type families
via compilation into those more primitive forms. Gundry's work, however,
explicitly does not support type families (Gundry's Section 6.7.4).
This lack of support is revealed
in two missing features:
\paragraph{Matching on |Type|} 
Through the way I have constructed my \ottkw{case} expressions---specifically,
treating |Type| as just another type constant---I allow
pattern-matching on elements of |Type|. Gundry's treatment requires a
scrutinee to be a member of a closed algebraic datatype.
\paragraph{Unsaturated matching}
Haskell type families can match on unsaturated uses of data and type
constructors, something not supported in Gundry's work but is supported
in \pico/.


\subsection{Axioms}

Gundry's \emph{evidence} language includes support for axioms. While the
notion of type-level axioms has been used in much prior work to represent
type families, Gundry uses them to represent notions beyond those possible
in type families, such as the commutativity of some primitive addition
operation. In order to set up his consistency proof, he needs to establish
that the axioms are \emph{good}, as defined in Gundry's Definition 6.4 of
his Section 6.5.1. Gundry does not provide an algorithm for determining
whether a set of axioms are \emph{good}, however.

\Pico/, in contrast, has no built-in support for axioms. One could try
adding axioms as global coercion variables available in every context, but
that would interfere with the current consistency proof (\pref{sec:consistency})
which severely limits the use of coercion variables. It is conceivable
that adding axioms to \pico/ is possible by establishing some condition,
like Gundry's \emph{good}, that claims that the axioms do not interfere
with consistency. This remains as future work, however.


\subsection{Type erasure}

Gundry proves a type erasure property similar to mine. However, there is
one key difference: my type erasure erases irrelevant abstractions (as does
today's implementation of System FC in GHC), while
Gundry's does not. It is not clear, however, that this change is significant,
in that it might easily be possible to tweak Gundry's system to allow erasure
of irrelevant abstractions, too.

\paragraph{}
See also \pref{sec:gundry-consistency-wrong} and \pref{sec:gundry-type-inference}
for further comments comparing my work to Gundry's.

\section{Comparison to Idris}

Of the available dependently typed language implementations, Idris is the most
like Dependent Haskell. Idris was designed explicitly to answer the question
``What if Haskell had \emph{full} dependent
types?''~\cite[Introduction]{idris} 
The Idris implementation is available\footnote{\url{http://www.idris-lang.org/}}
and is actively developed. So, how does Idris compare with Dependent Haskell?
I review the main points of difference, below.

\subsection{Backward compatibility}

From a practical standpoint, the biggest difference between Dependent Haskell
and Idris is that the former joins an already existing ecosystem of Haskell
libraries and developers. Dependent Haskell is a conservative extension over
existing implementations of Haskell, and all legacy programs will continue
to work under Dependent Haskell. Although Idris is certainly Haskell-like
(and has a foreign-function interface available to call Haskell code
from Idris and vice versa) it is still not Haskell.

Pushing on this idea a bit more, for a project to be started in Idris,
the programmers must decide, at the outset, that they wish to use dependent
types, as its type system is Idris's most distinctive feature. With
Dependent Haskell, on the other hand, developers can choose to take a part of
larger Haskell application and rewrite just that part with dependent types.
This allows for gradual adoption, something that is much easier for the
general public to swallow.

\subsection{Type erasure}

Dependent Haskell and Idris take different approaches to type erasure.
Idris's approach is explained by \citet{practical-erasure} as a whole-program
analysis, seeking out places where an expression is needed and ensuring
that all such expressions are available at runtime. Naturally, such an
approach hinders separate compilation, which the authors admit is important
future work (Teji\v{s}\v{c}\'{a}k and Brady's Section 8.1).

By contrast, Dependent Haskell depends on user-written choices---specifically,
whether to use |pi| or |forall| when writing a type.

Which approach is better? It is hard to say at this point. The Idris approach
has the advantage of automation. It may be hard for a user to know what
expressions (especially those stored in datatypes) will be necessary at
runtime. The choice between |pi| and |forall| may also motivate library-writers
to duplicate their data structures providing both options. This is much
like the fact that many current libraries provide both strict and lazy
implementations of core data structures, as the better choice depends
on a client's usage. Perhaps the option for library-writers to provide
multiple versions of a datatype is an advantage, however: in Idris,
a datatype's parameter may be marked as relevant even if it is used only
once. In that case, the Idris programmer is perhaps better served by using
one data structure (with the field irrelevant) in most places and the other
data structure (with the field relevant) just where necesary. Time will
tell whether the Dependent Haskell approach or the Idris approach is
better.

\subsection{Type inference}

All Idris top-level definitions must be accompanied with type annotations.
Even local definitions must have type annotations, sometimes requiring 
scoped type variables to provide. One might say, then, that Idris does
no type inference, only type checking. For this reason, studying the
type inference properties of the language might be less compelling.
Indeed, Brady claims~\cite[Section 6]{idris} that Idris ``avoid[s] such
difficulties since, in general, type inference is undecidable for
full dependent types. Indeed, it is not clear that type inference is even
desirable in many cases...''

While I admit that considering a principal-types property is much less
compelling when all bindings are annotated, I still believe that writing
a type inference algorithm or specification is helpful. I am unaware
of a description in the literature of Idris's algorithm beyond
\citet[Section 4]{idris}, describing the elaboration of an Idris program
in terms of the tactics that generate code in Idris's intermediate language,
\textsf{TT}. Accordingly, it is hard to predict when an Idris program
will be accepted. I tested the following program against the latest version
of Idris (0.12.1):
\begin{spec}
ty : Bool -> Type
ty x = case x of True => Integer; False => Char

f : (x : Bool) -> ty x
f x = case x of True => 5; False => 'x'

g : (x : Bool) -> ty x
g x = the  (ty x)
           (case x of True => 5; False => 'x')

h : (x : Bool) -> ty x
h x = the  (case x of True => Integer; False => Char)
           (case x of True => 5; False => 'x')
\end{spec}
Idris's |the| is its form of type annotation, with |the : (a : Type) -> a -> a|.
Both |f| and |g| are accepted, while |h| is rejected. Note that
the only difference between |g| and |h| is that the body of |ty| is expanded
in |h|. Is this a bug or the correct behavior? It is hard to know.

In contrast, \pref{cha:type-inference} describes a bidirectional inference
algorithm that details how to treat such expressions. (All of |f|, |g|,
and |h| are accepted in Dependent Haskell and today's approximation thereof
using \package{singletons}.) 

Beyond just having a specification, Dependent Haskell also retains
Hindley-Milner |let|-generalization for top-level expressions (as implemented
by the \rul{IDecl\_Synthesize} rule of \bake/). This means that simply typed
functions and local declarations need not have type ascriptions. Indeed, in
translating Idris's \package{Effects} library to Dependent Haskell
(\pref{sec:algebraic-effects}), I was able to eliminate several type
annotations, needed in Idris but redundant in Haskell. Having
|let|-generalization also powers examples like inferring the schema from the
use of a dependently typed database access library
(\pref{sec:dependent-db-example}), the equivalent of which would be impossible
in Idris.

\subsection{Editor integration}

One arena where Idris is clearly out ahead is in its user interface. Indeed,
despite the fact that Idris is considerably younger, GHC has been clamoring
to catch up to Idris's user interface for some time now. Its emacs
integration means that users can interactively peruse error messages,
expanding out the parts of interest and easily ignoring the unhelpful
parts~\cite{idris-pretty-printer}. Dependent Haskell and GHC have much
to learn from Idris in this respect; dependently typed programming in Haskell
will demand improvement.

\section{Comparison to Cayenne}
\label{sec:cayenne}

Beyond Idris, there are many other languages one might want a comparison
against. The most frequent comparison I have been asked for, however,
is to compare against Cayenne~\cite{cayenne}, which I shall do here.

Cayenne is a language introduced in 1998 by Augustsson essentially as a
dependently typed variant of Haskell. Of particular interest,
it shares Dependent Haskell's
cavalier attitude toward termination: Cayenne supports general recursion
and all types are thus inhabited by $\bot$. As such, Augustsson admits
that Cayenne is not useful as a proof assistant. However, he also argues
that this admission does not mean it is useless as a programming language.
My argument in support of allowing general recursion in a dependently typed
language (\pref{sec:running-proofs}) broadly echoes Augustsson's Section 5,
claiming that a verification of partial correctness is better than no
verification at all.

Despite the similarities between my work here and Augustsson's, there are
a number of key differences:

\subsection{Type erasure}
Augustsson's approach to type erasure is much simpler than mine. Cayenne
erases all expressions of type |Type|---that's the full description
of type erasure in Cayenne. This simplistic view has two shortcomings,
however:
\begin{description}
\item[Cayenne erases too much] Because every expression of type |Type|
is lost, Cayenne must restrict its pattern-match facility not to work
over scrutinees of type |Type|. Dependent Haskell allows matching on |Type|,
in contrast.
\item[Cayenne erases too little] Sometimes expressions of a type other
than |Type| can be erased. For example, consider this function over length-indexed
vectors (\pref{sec:length-indexed-vectors}):
%if style == newcode
\begin{code}
data Nat = Zero | Succ Nat
data Vec :: Type -> Nat -> Type where
  Nil :: Vec a !Zero
  (:>) :: a -> Vec a n -> Vec a (!Succ n)
infixr 5 :>
\end{code}
%endif
\begin{code}
safeHead :: Vec a (!Succ n) -> a
safeHead (x :> _) = x
\end{code}
The |n| parameter to |safeHead| has type |Nat| and yet it can be erased in
the call to |safeHead|. Cayenne would have no way of erasing this parameter.
\end{description}

\subsection{Coercion assumptions}

Cayenne has no support for equality assumptions. This means that it does
not support GADTs (\pref{sec:gadts} or dependent pattern matching (\pref{sec:dependent-pattern-match}). Lacking these features significantly simplifies the
design of the language and implementation, meaning that many of the 
type inference issues (specifically, untouchability of type variables)
described by \citet{outsidein} are avoided. The lack of equality assumptions
also severely weakens Cayenne's ability to support intrinsic proofs---that
is, types whose structure ensure that all values of those types are valid
(like |Vec|, which ensures that the vector is of the given length). Cayenne
thus truly supports only extrinsic proofs: proofs written separately from
the functions and data structures they reason about. These proofs must be
written explicitly (intrinsic proofs are often encoded into the structure
of a function) and offer more opportunity to accidentally use a non-terminating
proof.

\subsection{A hierarchy of sorts}

Cayenne uses an infinite hierarchy of sorts, similar to many other
dependently typed languages, but in contrast to Dependent Haskell, with
its |Type : Type| axiom. Augustsson describes this design decision as
working in support of Cayenne's treatment as logical framework (if the
user takes on the burden of termination checking) as well as to support
Cayenne's implementation of type erasure.

\subsection{Metatheory}

While Augustsson presents typing rules for Cayenne, he offers no metatheory
analysis for Cayenne beyond proving that the evaluation of a type-erased
program simulates the evaluation of the original. Similarly, Augustsson
does not describe any type inference properties in detail. The language
requires top-level type annotations on all definitions, but inference is
still necessary to check a dependently typed expression. Instead, Augustsson
claims that ``Type signatures can be omitted in many places'' but does
not elaborate~\cite[fourth-to-last bullet in Section 3.2]{cayenne}.
Cayenne does syntactically require all function arguments to be annotated,
however.

\subsection{Modules}

Cayenne as a robust module system, more advanced than Haskell's. As such,
its module system is more advanced also than Dependent Haskell's. Cayenne
uses dependent records as its modules, as a dependent record can store
types as easily as other expressions. It remains as future work to see
whether or not Dependent Haskell can incorporate these ideas and use
records as modules.

\subsection{Conclusion}

As an early attempt to bring dependent types to Haskell, Cayenne deserves
much credit. Despite being declared dead in 2005\footnote{\url{http://lambda-the-ultimate.org/node/802}}, Haskellers still discuss this language. It may
have been the first thought-out vision of what a Haskell-like dependently
typed language would look like and thus serves as an inspiration for both
Agda and Idris.

\section{Comparison to Liquid Haskell}

Liquid Haskell~\cite{bounded-refinement-types,liquid-haskell-experience,liquid-haskell} is an ongoing project seeking to add \emph{refinement types}
to Haskell. A refinement type specifies a head type and a condition; any
value of that type is asserted to meet the condition. For example, we might
write the type of the |length| function thus:
\begin{spec}
length :: [a] -> { n : Int | n >= 0 }
\end{spec}
The return type tells us that the return value will always be non-negative.

The Liquid Haskell implementation works by reading in such annotations
with a Haskell file and checking that the refinements are satisfied. The
check is done via an SMT solver. No user intervention---other than writing
the refinements in the first place---is required.

Liquid Haskell and Dependent Haskell are, in some ways, two different solutions
to (nearly) the same problem: the desire to rule out erroneous programs.
By specifying tight refinements on our function types, we can have Liquid
Haskell check the correctness of our programs. And doing so is easy, thanks
to the power of the SMT solver working in the background.

However, the refinement types of Liquid Haskell exist outside of the type system
proper: it is not possible to write a type-level program that can manipulate
refinements, and it is also not possible to write refinements that can
reason about Haskell's type classes or other advanced type-level features.
Along similar lines, it is not possible to use refinement types to write
a program inadmissible in regular Haskell; for example, refinement types
are not powerful enough to encode something like Idris's algebraic effects
library (\pref{sec:algebraic-effects}).

The beauty of Liquid Haskell is in its user interface. Proving that a program
matches its specification is fully automatic---something very much not
true of Dependent Haskell programs. The project has shown without a doubt
that using an SMT solver to help typechecking will lessen users' proof
burden. (Liquid Haskell is hardly the only tool that uses an SMT solver
for typechecking. See also, for example, \citet{dafny,dependent-f-star},
among others.) 

It is my hope that, someday, Dependent Haskell can aspire to be the
backend for Liquid Haskell. The merged language would have the type
refinement syntax much like Liquid Haskell's current syntax, but it would
desugar to proper dependent types under the hood. An SMT solver would remain
as part of the system, possibly as a typechecker plugin.
For function arguments, supporting refinement types
is already possible: a type like |{n : Int | n >= 0}| can be encoded
as a dependent parameter |n| and a Haskell constraint. Much more problematic
is a refined return type. For that same refinement, we would need a
existential package, saying that a function returns \emph{some} |n| with
|n >= 0|. While Dependent Haskell support existentials, naturally, packing
and unpacking these must be done manually. In practice, this packing
and unpacking clutters the code considerably and makes the refinement
approach distasteful. Perhaps worse, the packing and unpacking would be
performed at runtime, making end users pay a cost for this compile-time
checking. Overcoming these barriers---coming up with a lightweight syntax
for existentials as well as zero runtime overhead---is important future work,
perhaps my highest priority new research direction.

\section{Invisibility in other languages}
\label{sec:vis-other-lang}

\begin{itemize}
%{
%format dbo = "\{\!\{"
%format dbc = "\}\!\}"
\item In Agda, an argument in single braces |{ ... }| is invisible and is
instantiated via unification. An argument in double braces |dbo ... dbc| is
invisible and is instantiated by looking for an in-scope variable of the
right type. One Agda encoding of, say, the |Show| class and its |Show Bool|
instance would be to make |Show| a record containing a |show| field (much
like GHC's dictionary for |Show|) and a top-level variable of type |Show Bool|.
The lookup process for |dbo ... dbc| arguments would then find this top-level
variable.

Thus, |show|'s type in Agda might look like |forall {a} -> dbo Show a dbc -> a ->
String|.
%}
%{
%format proof = "\keyword{proof}"
%format trivial = "\keyword{trivial}"
%format auto = "\keyword{auto}"
\item Idris supports type classes in much the same way as Haskell. A constraint
listed before a |(=>)| is solved just like a Haskell type class is. However,
other invisible arguments can also have custom solving tactics. An Idris
argument in single braces |{ ... }| is solved via unification, just like in
Agda. But a programmer may insert a proof script in the braces as well to
trigger that proof script whenever the invisible parameter needs to be
instantiated. For example, a type signature like
|func : {default proof { trivial } pf : tau } -> ...| names a (possibly-dependent)
parameter |pf|, of type |tau|. When |func| is called, Idris will run the
|trivial| tactic to solve for a value of type |tau|. This value will then
be inserted in for |pf|. Because a default proof script of |trivial| is so
common, Idris offers an abbreviation |auto| which means |default proof { trivial }|.
%}
\item
Coq has quite a different view of invisible arguments than do Dependent Haskell,
Agda, or Idris. In all three of those languages, the visibility of an argument
is part of a type. In Coq, top-level directives allow the programmer to change
the visibility of arguments to already-defined functions. For example, if we
have the definition
%{
%format Definition = "\keyword{Definition}"
%format Arguments = "\keyword{Arguments}"
%format Set = "\keyword{Set}"
%format Implicit = "\keyword{Implicit}"
%format mytrue1
%format mytrue2
%format forall = "\keyword{forall}"
\begin{spec}
Definition id A (x : A) := x.
\end{spec}
(without having used |Set Implicit Arguments|) both the |A| and |x| parameters
are visible. Thus the following line is accepted:
\begin{spec}
Definition mytrue1 := id bool true.
\end{spec}
However, we can now change the visibility of the arguments to |id| with the
directive
\begin{spec}
Arguments id {A} x.
\end{spec}
allowing the following to be accepted:
\begin{spec}
Definition mytrue2 := id true.
\end{spec}

Although Coq does not allow the programmer to specify an instantiation technique
for invisible arguments, it does allow the programmer to specify whether or
not invisible arguments should be \emph{maximally inserted}. A maximally
inserted invisible argument is instantiated whenever possible; a non-maximally
inserted argument is only instantiated when needed. For example, if the |A|
argument to |id| were invisible and maximally inserted, then any use of |id|
would immediately try to solve for |A|; if this were not possible, Coq would
report a type error. If |A| were not maximally inserted, than a use of |id|
would simply have the type |forall A, A -> A|, with no worry about invisible
argument instantiation.

The issue of maximal insertion in Dependent Haskell is solved via its
bidirectional type system (\pref{sec:bidirectional}). The subsumption relation
effectively ensures that the correct number of invisible parameters are provided,
depending on the context.
%}

\end{itemize}

\section{Applicability beyond Haskell}

\begin{proposal}
The knowledge gained in adding dependent types to Haskell will translate
to other environments as well. A key example will be the thought of adding
dependent types to a variant of ML. Going the other way, I will examine
adding more programmatic features to existing dependently typed languages
(in particular, Haskell's \keyword{newtype} construct).
\end{proposal}

\section{Future work}

\begin{proposal}
Though this dissertation will deliver $\Pi$, that's not the end of the story.
Here are some questions I have that I do not expect will be answered in the
course of writing this work.
\begin{itemize}
\item How to improve error messages? While my work will strive hard not to
degrade error messages for non-dependently-typed programs, I offer no
guarantee about the quality of error messages in programs with lots of
dependent types. How can these be improved? More generally, how can error
messages be customized by programmers to fit their domain?

\item What editor support is necessary to make dependent types in Haskell
practical?

\item Are there constructs that I have been unable to promote? How can these
be made to work in types?

\item How do we optimize a dependently typed program? Ideally, a program should
be optimized to the same level whether an argument is dependent or not. However,
optimizing $\Pi$-quantified arguments will amount to proving the optimizations
correct! How do we retain runtime performance in the face of dependent types?

\item How will dependent types interact with type-checker
  plugins~\cite{type-checker-plugins}? Can we use an SMT solver to make working
  with dependent types easier?

\item Dependent types will allow for proper dependent pairs ($\Sigma$-types).
  Is it worth introducing new syntax to support these useful constructs directly?

\item \rae{Pretty-printer plugin?}
\end{itemize}
\end{proposal}

\section{Type erasure in other languages}
\label{sec:related-type-erasure}

\rae{Make sure I have Xi's work and Trellys}

%%  LocalWords:  gundry newtype SMT
